Dec 26 07:02:42 2016 90536 3 10.1 NIOS_DEBUG: stdin_fd set to -1
Dec 26 07:02:42 2016 90536 3 10.1 NIOS_DEBUG: fds[0] has a value of -1
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1226 07:02:45.898777 89377 mpiutil.cpp:166] Process rank 1 from number of 9 processes running on knl-node038
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1226 07:02:45.897872 51587 mpiutil.cpp:166] Process rank 5 from number of 9 processes running on knl-node017
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1226 07:02:45.894312 96083 mpiutil.cpp:166] Process rank 8 from number of 9 processes running on knl-node016
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1226 07:02:45.902762 89165 mpiutil.cpp:166] Process rank 4 from number of 9 processes running on knl-node076
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1226 07:02:45.900857 90546 mpiutil.cpp:166] Process rank 0 from number of 9 processes running on knl-node062
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1226 07:02:45.898030 93507 mpiutil.cpp:166] Process rank 7 from number of 9 processes running on knl-node079
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1226 07:02:45.897044 89170 mpiutil.cpp:166] Process rank 3 from number of 9 processes running on knl-node047
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1226 07:02:45.901674 88126 mpiutil.cpp:166] Process rank 6 from number of 9 processes running on knl-node054
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1226 07:02:45.905014 89451 mpiutil.cpp:166] Process rank 2 from number of 9 processes running on knl-node025
I1226 07:02:45.912395 51587 caffe.cpp:316] Use CPU.
I1226 07:02:45.912402 93507 caffe.cpp:316] Use CPU.
I1226 07:02:45.909343 96083 caffe.cpp:316] Use CPU.
I1226 07:02:45.918071 89165 caffe.cpp:316] Use CPU.
I1226 07:02:45.920295 89451 caffe.cpp:316] Use CPU.
I1226 07:02:45.913586 51587 solver.cpp:105] Initializing solver from parameters: 
train_net: "/export/data1/stanford/hazy/gordon_bell/caffenet_knl/split_prototxt/8_nodes_lmdb_config_1/train-val/train_val_lmdb_6.prototxt"
base_lr: 0.0003
display: 1
max_iter: 200000
lr_policy: "step"
gamma: 0.1
momentum: 0
weight_decay: 0.0005
stepsize: 100000
snapshot: 5000
snapshot_prefix: "/export/data1/stanford/hazy/gordon_bell/caffenet_knl/snapshot/caffenet_MN8_B1024_25000/"
solver_mode: CPU
train_state {
  level: 0
  stage: ""
}
I1226 07:02:45.914592 51587 solver.cpp:140] Creating training net from train_net file: /export/data1/stanford/hazy/gordon_bell/caffenet_knl/split_prototxt/8_nodes_lmdb_config_1/train-val/train_val_lmdb_6.prototxt
I1226 07:02:45.910508 96083 solver.cpp:105] Initializing solver from parameters: 
train_net: "/export/data1/stanford/hazy/gordon_bell/caffenet_knl/split_prototxt/8_nodes_lmdb_config_1/train-val/train_val_lmdb_dummy.prototxt"
base_lr: 0.0003
display: 1
max_iter: 200000
lr_policy: "step"
gamma: 0.1
momentum: 0
weight_decay: 0.0005
stepsize: 100000
snapshot: 5000
snapshot_prefix: "/export/data1/stanford/hazy/gordon_bell/caffenet_knl/snapshot/caffenet_MN8_B1024_25000/"
solver_mode: CPU
train_state {
  level: 0
  stage: ""
}
I1226 07:02:45.917343 90546 caffe.cpp:316] Use CPU.
I1226 07:02:45.913832 93507 solver.cpp:105] Initializing solver from parameters: 
train_net: "/export/data1/stanford/hazy/gordon_bell/caffenet_knl/split_prototxt/8_nodes_lmdb_config_1/train-val/train_val_lmdb_8.prototxt"
base_lr: 0.0003
display: 1
max_iter: 200000
lr_policy: "step"
gamma: 0.1
momentum: 0
weight_decay: 0.0005
stepsize: 100000
snapshot: 5000
snapshot_prefix: "/export/data1/stanford/hazy/gordon_bell/caffenet_knl/snapshot/caffenet_MN8_B1024_25000/"
solver_mode: CPU
train_state {
  level: 0
  stage: ""
}
I1226 07:02:45.911499 96083 solver.cpp:140] Creating training net from train_net file: /export/data1/stanford/hazy/gordon_bell/caffenet_knl/split_prototxt/8_nodes_lmdb_config_1/train-val/train_val_lmdb_dummy.prototxt
I1226 07:02:45.921437 89451 solver.cpp:105] Initializing solver from parameters: 
train_net: "/export/data1/stanford/hazy/gordon_bell/caffenet_knl/split_prototxt/8_nodes_lmdb_config_1/train-val/train_val_lmdb_3.prototxt"
base_lr: 0.0003
display: 1
max_iter: 200000
lr_policy: "step"
gamma: 0.1
momentum: 0
weight_decay: 0.0005
stepsize: 100000
snapshot: 5000
snapshot_prefix: "/export/data1/stanford/hazy/gordon_bell/caffenet_knl/snapshot/caffenet_MN8_B1024_25000/"
solver_mode: CPU
train_state {
  level: 0
  stage: ""
}
I1226 07:02:45.914893 93507 solver.cpp:140] Creating training net from train_net file: /export/data1/stanford/hazy/gordon_bell/caffenet_knl/split_prototxt/8_nodes_lmdb_config_1/train-val/train_val_lmdb_8.prototxt
I1226 07:02:45.919312 89165 solver.cpp:105] Initializing solver from parameters: 
train_net: "/export/data1/stanford/hazy/gordon_bell/caffenet_knl/split_prototxt/8_nodes_lmdb_config_1/train-val/train_val_lmdb_5.prototxt"
base_lr: 0.0003
display: 1
max_iter: 200000
lr_policy: "step"
gamma: 0.1
momentum: 0
weight_decay: 0.0005
stepsize: 100000
snapshot: 5000
snapshot_prefix: "/export/data1/stanford/hazy/gordon_bell/caffenet_knl/snapshot/caffenet_MN8_B1024_25000/"
solver_mode: CPU
train_state {
  level: 0
  stage: ""
}
I1226 07:02:45.922358 89451 solver.cpp:140] Creating training net from train_net file: /export/data1/stanford/hazy/gordon_bell/caffenet_knl/split_prototxt/8_nodes_lmdb_config_1/train-val/train_val_lmdb_3.prototxt
I1226 07:02:45.915741 89377 caffe.cpp:316] Use CPU.
I1226 07:02:45.920269 89165 solver.cpp:140] Creating training net from train_net file: /export/data1/stanford/hazy/gordon_bell/caffenet_knl/split_prototxt/8_nodes_lmdb_config_1/train-val/train_val_lmdb_5.prototxt
I1226 07:02:45.918478 90546 solver.cpp:105] Initializing solver from parameters: 
train_net: "/export/data1/stanford/hazy/gordon_bell/caffenet_knl/split_prototxt/8_nodes_lmdb_config_1/train-val/train_val_lmdb_1.prototxt"
base_lr: 0.0003
display: 1
max_iter: 200000
lr_policy: "step"
gamma: 0.1
momentum: 0
weight_decay: 0.0005
stepsize: 100000
snapshot: 5000
snapshot_prefix: "/export/data1/stanford/hazy/gordon_bell/caffenet_knl/snapshot/caffenet_MN8_B1024_25000/"
solver_mode: CPU
train_state {
  level: 0
  stage: ""
}
I1226 07:02:45.919396 90546 solver.cpp:140] Creating training net from train_net file: /export/data1/stanford/hazy/gordon_bell/caffenet_knl/split_prototxt/8_nodes_lmdb_config_1/train-val/train_val_lmdb_1.prototxt
I1226 07:02:45.916872 89377 solver.cpp:105] Initializing solver from parameters: 
train_net: "/export/data1/stanford/hazy/gordon_bell/caffenet_knl/split_prototxt/8_nodes_lmdb_config_1/train-val/train_val_lmdb_2.prototxt"
base_lr: 0.0003
display: 1
max_iter: 200000
lr_policy: "step"
gamma: 0.1
momentum: 0
weight_decay: 0.0005
stepsize: 100000
snapshot: 5000
snapshot_prefix: "/export/data1/stanford/hazy/gordon_bell/caffenet_knl/snapshot/caffenet_MN8_B1024_25000/"
solver_mode: CPU
train_state {
  level: 0
  stage: ""
}
I1226 07:02:45.915177 89170 caffe.cpp:316] Use CPU.
I1226 07:02:45.917783 89377 solver.cpp:140] Creating training net from train_net file: /export/data1/stanford/hazy/gordon_bell/caffenet_knl/split_prototxt/8_nodes_lmdb_config_1/train-val/train_val_lmdb_2.prototxt
I1226 07:02:45.916299 89170 solver.cpp:105] Initializing solver from parameters: 
train_net: "/export/data1/stanford/hazy/gordon_bell/caffenet_knl/split_prototxt/8_nodes_lmdb_config_1/train-val/train_val_lmdb_4.prototxt"
base_lr: 0.0003
display: 1
max_iter: 200000
lr_policy: "step"
gamma: 0.1
momentum: 0
weight_decay: 0.0005
stepsize: 100000
snapshot: 5000
snapshot_prefix: "/export/data1/stanford/hazy/gordon_bell/caffenet_knl/snapshot/caffenet_MN8_B1024_25000/"
solver_mode: CPU
train_state {
  level: 0
  stage: ""
}
I1226 07:02:45.917086 89170 solver.cpp:140] Creating training net from train_net file: /export/data1/stanford/hazy/gordon_bell/caffenet_knl/split_prototxt/8_nodes_lmdb_config_1/train-val/train_val_lmdb_4.prototxt
I1226 07:02:45.924790 88126 caffe.cpp:316] Use CPU.
I1226 07:02:45.926049 88126 solver.cpp:105] Initializing solver from parameters: 
train_net: "/export/data1/stanford/hazy/gordon_bell/caffenet_knl/split_prototxt/8_nodes_lmdb_config_1/train-val/train_val_lmdb_7.prototxt"
base_lr: 0.0003
display: 1
max_iter: 200000
lr_policy: "step"
gamma: 0.1
momentum: 0
weight_decay: 0.0005
stepsize: 100000
snapshot: 5000
snapshot_prefix: "/export/data1/stanford/hazy/gordon_bell/caffenet_knl/snapshot/caffenet_MN8_B1024_25000/"
solver_mode: CPU
train_state {
  level: 0
  stage: ""
}
I1226 07:02:45.927248 88126 solver.cpp:140] Creating training net from train_net file: /export/data1/stanford/hazy/gordon_bell/caffenet_knl/split_prototxt/8_nodes_lmdb_config_1/train-val/train_val_lmdb_7.prototxt
I1226 07:02:45.948035 89377 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1226 07:02:45.948109 89377 cpu_info.cpp:455] Total number of sockets: 1
I1226 07:02:45.954133 89451 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1226 07:02:45.954205 89451 cpu_info.cpp:455] Total number of sockets: 1
I1226 07:02:45.948133 89377 cpu_info.cpp:458] Total number of CPU cores: 68
I1226 07:02:45.948153 89377 cpu_info.cpp:461] Total number of processors: 272
I1226 07:02:45.948173 89377 cpu_info.cpp:464] GPU is used: no
I1226 07:02:45.954226 89451 cpu_info.cpp:458] Total number of CPU cores: 68
I1226 07:02:45.954246 89451 cpu_info.cpp:461] Total number of processors: 272
I1226 07:02:45.954264 89451 cpu_info.cpp:464] GPU is used: no
I1226 07:02:45.954283 89451 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1226 07:02:45.948194 89377 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1226 07:02:45.952147 89165 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1226 07:02:45.952221 89165 cpu_info.cpp:455] Total number of sockets: 1
I1226 07:02:45.954330 89451 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1226 07:02:45.948213 89377 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1226 07:02:45.952244 89165 cpu_info.cpp:458] Total number of CPU cores: 68
I1226 07:02:45.952309 89165 cpu_info.cpp:461] Total number of processors: 272
I1226 07:02:45.952330 89165 cpu_info.cpp:464] GPU is used: no
I1226 07:02:45.952350 89165 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1226 07:02:45.950389 90546 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1226 07:02:45.950465 90546 cpu_info.cpp:455] Total number of sockets: 1
I1226 07:02:45.952370 89165 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1226 07:02:45.950495 90546 cpu_info.cpp:458] Total number of CPU cores: 68
I1226 07:02:45.950520 90546 cpu_info.cpp:461] Total number of processors: 272
I1226 07:02:45.950546 90546 cpu_info.cpp:464] GPU is used: no
I1226 07:02:45.950574 90546 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1226 07:02:45.950603 90546 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1226 07:02:45.944557 96083 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1226 07:02:45.944635 96083 cpu_info.cpp:455] Total number of sockets: 1
I1226 07:02:45.944658 96083 cpu_info.cpp:458] Total number of CPU cores: 68
I1226 07:02:45.944679 96083 cpu_info.cpp:461] Total number of processors: 272
I1226 07:02:45.944726 96083 cpu_info.cpp:464] GPU is used: no
I1226 07:02:45.944774 96083 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1226 07:02:45.944795 96083 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1226 07:02:45.949255 93507 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1226 07:02:45.949347 93507 cpu_info.cpp:455] Total number of sockets: 1
I1226 07:02:45.949376 93507 cpu_info.cpp:458] Total number of CPU cores: 68
I1226 07:02:45.949399 93507 cpu_info.cpp:461] Total number of processors: 272
I1226 07:02:45.949421 93507 cpu_info.cpp:464] GPU is used: no
I1226 07:02:45.949443 93507 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1226 07:02:45.949465 93507 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1226 07:02:45.950285 89170 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1226 07:02:45.950363 89170 cpu_info.cpp:455] Total number of sockets: 1
I1226 07:02:45.950390 89170 cpu_info.cpp:458] Total number of CPU cores: 68
I1226 07:02:45.950413 89170 cpu_info.cpp:461] Total number of processors: 272
I1226 07:02:45.950438 89170 cpu_info.cpp:464] GPU is used: no
I1226 07:02:45.950494 89170 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1226 07:02:45.950520 89170 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1226 07:02:45.958055 88126 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1226 07:02:45.958132 88126 cpu_info.cpp:455] Total number of sockets: 1
I1226 07:02:45.958154 88126 cpu_info.cpp:458] Total number of CPU cores: 68
I1226 07:02:45.958174 88126 cpu_info.cpp:461] Total number of processors: 272
I1226 07:02:45.958194 88126 cpu_info.cpp:464] GPU is used: no
I1226 07:02:45.958214 88126 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1226 07:02:45.958235 88126 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1226 07:02:45.958231 51587 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1226 07:02:45.958309 51587 cpu_info.cpp:455] Total number of sockets: 1
I1226 07:02:45.958340 51587 cpu_info.cpp:458] Total number of CPU cores: 68
I1226 07:02:45.958365 51587 cpu_info.cpp:461] Total number of processors: 272
I1226 07:02:45.958394 51587 cpu_info.cpp:464] GPU is used: no
I1226 07:02:45.958421 51587 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1226 07:02:45.958448 51587 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1226 07:02:45.983472 90546 cpu_info.cpp:473] Number of OpenMP threads: 66
I1226 07:02:45.983772 90546 net.cpp:500] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1226 07:02:45.985760 90546 net.cpp:136] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
engine: "MKL2017"
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/export/data1/stanford/hazy/zjian/gorden_bell/ILSVRC2012_lmdb/db_8/ilsvrc12_train_lmdb_0"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "label_data_1_split"
  type: "Split"
  bottom: "label"
  top: "label_data_1_split_0"
  top: "label_data_1_split_1"
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc8_fc8_0_split"
  type: "Split"
  bottom: "fc8"
  top: "fc8_fc8_0_split_0"
  top: "fc8_fc8_0_split_1"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_fc8_0_split_0"
  bottom: "label_data_1_split_0"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_fc8_0_split_1"
  bottom: "label_data_1_split_1"
  top: "loss"
}
I1226 07:02:45.985199 93507 cpu_info.cpp:473] Number of OpenMP threads: 66
I1226 07:02:45.985548 93507 net.cpp:500] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1226 07:02:45.987639 93507 net.cpp:136] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
engine: "MKL2017"
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/export/data1/stanford/hazy/zjian/gorden_bell/ILSVRC2012_lmdb/db_8/ilsvrc12_train_lmdb_7"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "label_data_1_split"
  type: "Split"
  bottom: "label"
  top: "label_data_1_split_0"
  top: "label_data_1_split_1"
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc8_fc8_0_split"
  type: "Split"
  bottom: "fc8"
  top: "fc8_fc8_0_split_0"
  top: "fc8_fc8_0_split_1"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_fc8_0_split_0"
  bottom: "label_data_1_split_0"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_fc8_0_split_1"
  bottom: "label_data_1_split_1"
  top: "loss"
}
I1226 07:02:45.988492 96083 cpu_info.cpp:473] Number of OpenMP threads: 66
I1226 07:02:45.988953 96083 net.cpp:500] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1226 07:02:45.991035 96083 net.cpp:136] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
engine: "MKL2017"
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 64
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 64
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "label_data_1_split"
  type: "Split"
  bottom: "label"
  top: "label_data_1_split_0"
  top: "label_data_1_split_1"
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc8_fc8_0_split"
  type: "Split"
  bottom: "fc8"
  top: "fc8_fc8_0_split_0"
  top: "fc8_fc8_0_split_1"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_fc8_0_split_0"
  bottom: "label_data_1_split_0"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_fc8_0_split_1"
  bottom: "label_data_1_split_1"
  top: "loss"
}
I1226 07:02:46.011874 88126 cpu_info.cpp:473] Number of OpenMP threads: 66
I1226 07:02:46.007959 93507 layer_factory.hpp:114] Creating layer data
I1226 07:02:46.012164 88126 net.cpp:500] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1226 07:02:46.013773 88126 net.cpp:136] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
engine: "MKL2017"
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/export/data1/stanford/hazy/zjian/gorden_bell/ILSVRC2012_lmdb/db_8/ilsvrc12_train_lmdb_6"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "label_data_1_split"
  type: "Split"
  bottom: "label"
  top: "label_data_1_split_0"
  top: "label_data_1_split_1"
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc8_fc8_0_split"
  type: "Split"
  bottom: "fc8"
  top: "fc8_fc8_0_split_0"
  top: "fc8_fc8_0_split_1"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_fc8_0_split_0"
  bottom: "label_data_1_split_0"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_fc8_0_split_1"
  bottom: "label_data_1_split_1"
  top: "loss"
}
I1226 07:02:46.009851 89170 cpu_info.cpp:473] Number of OpenMP threads: 66
I1226 07:02:46.010279 89170 net.cpp:500] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1226 07:02:46.011972 89170 net.cpp:136] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
engine: "MKL2017"
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/export/data1/stanford/hazy/zjian/gorden_bell/ILSVRC2012_lmdb/db_8/ilsvrc12_train_lmdb_3"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "label_data_1_split"
  type: "Split"
  bottom: "label"
  top: "label_data_1_split_0"
  top: "label_data_1_split_1"
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc8_fc8_0_split"
  type: "Split"
  bottom: "fc8"
  top: "fc8_fc8_0_split_0"
  top: "fc8_fc8_0_split_1"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_fc8_0_split_0"
  bottom: "label_data_1_split_0"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_fc8_0_split_1"
  bottom: "label_data_1_split_1"
  top: "loss"
}
I1226 07:02:46.013489 51587 cpu_info.cpp:473] Number of OpenMP threads: 66
I1226 07:02:46.013842 51587 net.cpp:500] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1226 07:02:46.015554 51587 net.cpp:136] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
engine: "MKL2017"
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/export/data1/stanford/hazy/zjian/gorden_bell/ILSVRC2012_lmdb/db_8/ilsvrc12_train_lmdb_5"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "label_data_1_split"
  type: "Split"
  bottom: "label"
  top: "label_data_1_split_0"
  top: "label_data_1_split_1"
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc8_fc8_0_split"
  type: "Split"
  bottom: "fc8"
  top: "fc8_fc8_0_split_0"
  top: "fc8_fc8_0_split_1"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_fc8_0_split_0"
  bottom: "label_data_1_split_0"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_fc8_0_split_1"
  bottom: "label_data_1_split_1"
  top: "loss"
}
I1226 07:02:46.020583 90546 layer_factory.hpp:114] Creating layer data
I1226 07:02:46.023721 89165 cpu_info.cpp:473] Number of OpenMP threads: 66
I1226 07:02:46.024081 89165 net.cpp:500] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1226 07:02:46.019434 93507 net.cpp:178] Creating Layer data
I1226 07:02:46.019562 93507 net.cpp:586] data -> data
I1226 07:02:46.019757 93507 net.cpp:586] data -> label
I1226 07:02:46.026602 89165 net.cpp:136] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
engine: "MKL2017"
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/export/data1/stanford/hazy/zjian/gorden_bell/ILSVRC2012_lmdb/db_8/ilsvrc12_train_lmdb_4"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "label_data_1_split"
  type: "Split"
  bottom: "label"
  top: "label_data_1_split_0"
  top: "label_data_1_split_1"
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc8_fc8_0_split"
  type: "Split"
  bottom: "fc8"
  top: "fc8_fc8_0_split_0"
  top: "fc8_fc8_0_split_1"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_fc8_0_split_0"
  bottom: "label_data_1_split_0"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_fc8_0_split_1"
  bottom: "label_data_1_split_1"
  top: "loss"
}
I1226 07:02:46.023919 89377 cpu_info.cpp:473] Number of OpenMP threads: 66
I1226 07:02:46.024262 89377 net.cpp:500] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1226 07:02:46.019726 96083 layer_factory.hpp:114] Creating layer data
I1226 07:02:46.019871 96083 net.cpp:178] Creating Layer data
I1226 07:02:46.019919 96083 net.cpp:586] data -> data
I1226 07:02:46.020009 96083 net.cpp:586] data -> label
I1226 07:02:46.026186 89377 net.cpp:136] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
engine: "MKL2017"
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/export/data1/stanford/hazy/zjian/gorden_bell/ILSVRC2012_lmdb/db_8/ilsvrc12_train_lmdb_1"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "label_data_1_split"
  type: "Split"
  bottom: "label"
  top: "label_data_1_split_0"
  top: "label_data_1_split_1"
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc8_fc8_0_split"
  type: "Split"
  bottom: "fc8"
  top: "fc8_fc8_0_split_0"
  top: "fc8_fc8_0_split_1"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_fc8_0_split_0"
  bottom: "label_data_1_split_0"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_fc8_0_split_1"
  bottom: "label_data_1_split_1"
  top: "loss"
}
I1226 07:02:46.044180 88126 layer_factory.hpp:114] Creating layer data
I1226 07:02:46.044819 90546 net.cpp:178] Creating Layer data
I1226 07:02:46.044926 90546 net.cpp:586] data -> data
I1226 07:02:46.045011 90546 net.cpp:586] data -> label
I1226 07:02:46.050832 89165 layer_factory.hpp:114] Creating layer data
I1226 07:02:46.054865 89451 cpu_info.cpp:473] Number of OpenMP threads: 66
I1226 07:02:46.055210 89451 net.cpp:500] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1226 07:02:46.056879 89451 net.cpp:136] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
engine: "MKL2017"
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/export/data1/stanford/hazy/zjian/gorden_bell/ILSVRC2012_lmdb/db_8/ilsvrc12_train_lmdb_2"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "label_data_1_split"
  type: "Split"
  bottom: "label"
  top: "label_data_1_split_0"
  top: "label_data_1_split_1"
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc8_fc8_0_split"
  type: "Split"
  bottom: "fc8"
  top: "fc8_fc8_0_split_0"
  top: "fc8_fc8_0_split_1"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_fc8_0_split_0"
  bottom: "label_data_1_split_0"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_fc8_0_split_1"
  bottom: "label_data_1_split_1"
  top: "loss"
}
I1226 07:02:46.060396 88126 net.cpp:178] Creating Layer data
I1226 07:02:46.060487 88126 net.cpp:586] data -> data
I1226 07:02:46.060607 88126 net.cpp:586] data -> label
I1226 07:02:46.059483 89170 layer_factory.hpp:114] Creating layer data
I1226 07:02:46.061329 93509 db_lmdb.cpp:72] Opened lmdb /export/data1/stanford/hazy/zjian/gorden_bell/ILSVRC2012_lmdb/db_8/ilsvrc12_train_lmdb_7
I1226 07:02:46.066445 89165 net.cpp:178] Creating Layer data
I1226 07:02:46.066541 89165 net.cpp:586] data -> data
I1226 07:02:46.066619 89165 net.cpp:586] data -> label
I1226 07:02:46.065289 89377 layer_factory.hpp:114] Creating layer data
I1226 07:02:46.064649 51587 layer_factory.hpp:114] Creating layer data
I1226 07:02:46.068727 93507 data_layer.cpp:80] output data size: 64,3,227,227
I1226 07:02:46.079874 89170 net.cpp:178] Creating Layer data
I1226 07:02:46.081848 89377 net.cpp:178] Creating Layer data
I1226 07:02:46.081946 89377 net.cpp:586] data -> data
I1226 07:02:46.079972 89170 net.cpp:586] data -> data
I1226 07:02:46.082029 89377 net.cpp:586] data -> label
I1226 07:02:46.080045 89170 net.cpp:586] data -> label
I1226 07:02:46.077922 96083 net.cpp:228] Setting up data
I1226 07:02:46.078027 96083 net.cpp:235] Top shape: 64 3 227 227 (9893568)
I1226 07:02:46.078059 96083 net.cpp:235] Top shape: 64 1 1 1 (64)
I1226 07:02:46.078137 96083 net.cpp:243] Memory required for data: 39574528
I1226 07:02:46.078174 96083 layer_factory.hpp:114] Creating layer label_data_1_split
I1226 07:02:46.078263 96083 net.cpp:178] Creating Layer label_data_1_split
I1226 07:02:46.078294 96083 net.cpp:612] label_data_1_split <- label
I1226 07:02:46.078472 96083 net.cpp:586] label_data_1_split -> label_data_1_split_0
I1226 07:02:46.078519 96083 net.cpp:586] label_data_1_split -> label_data_1_split_1
I1226 07:02:46.085840 51587 net.cpp:178] Creating Layer data
I1226 07:02:46.085925 51587 net.cpp:586] data -> data
I1226 07:02:46.086021 51587 net.cpp:586] data -> label
I1226 07:02:46.090270 90550 db_lmdb.cpp:72] Opened lmdb /export/data1/stanford/hazy/zjian/gorden_bell/ILSVRC2012_lmdb/db_8/ilsvrc12_train_lmdb_0
I1226 07:02:46.096140 89451 layer_factory.hpp:114] Creating layer data
I1226 07:02:46.089284 96083 net.cpp:228] Setting up label_data_1_split
I1226 07:02:46.089411 96083 net.cpp:235] Top shape: 64 1 1 1 (64)
I1226 07:02:46.089442 96083 net.cpp:235] Top shape: 64 1 1 1 (64)
I1226 07:02:46.089462 96083 net.cpp:243] Memory required for data: 39575040
I1226 07:02:46.089524 96083 layer_factory.hpp:114] Creating layer conv1
I1226 07:02:46.089612 96083 net.cpp:178] Creating Layer conv1
I1226 07:02:46.089644 96083 net.cpp:612] conv1 <- data
I1226 07:02:46.089691 96083 net.cpp:586] conv1 -> conv1
I1226 07:02:46.104967 89451 net.cpp:178] Creating Layer data
I1226 07:02:46.105057 89451 net.cpp:586] data -> data
I1226 07:02:46.105154 89451 net.cpp:586] data -> label
I1226 07:02:46.110826 90546 data_layer.cpp:80] output data size: 64,3,227,227
I1226 07:02:46.118083 88128 db_lmdb.cpp:72] Opened lmdb /export/data1/stanford/hazy/zjian/gorden_bell/ILSVRC2012_lmdb/db_8/ilsvrc12_train_lmdb_6
I1226 07:02:46.121348 89167 db_lmdb.cpp:72] Opened lmdb /export/data1/stanford/hazy/zjian/gorden_bell/ILSVRC2012_lmdb/db_8/ilsvrc12_train_lmdb_4
I1226 07:02:46.124012 89380 db_lmdb.cpp:72] Opened lmdb /export/data1/stanford/hazy/zjian/gorden_bell/ILSVRC2012_lmdb/db_8/ilsvrc12_train_lmdb_1
I1226 07:02:46.130722 89165 data_layer.cpp:80] output data size: 64,3,227,227
I1226 07:02:46.132419 89172 db_lmdb.cpp:72] Opened lmdb /export/data1/stanford/hazy/zjian/gorden_bell/ILSVRC2012_lmdb/db_8/ilsvrc12_train_lmdb_3
I1226 07:02:46.139780 51589 db_lmdb.cpp:72] Opened lmdb /export/data1/stanford/hazy/zjian/gorden_bell/ILSVRC2012_lmdb/db_8/ilsvrc12_train_lmdb_5
I1226 07:02:46.144481 88126 data_layer.cpp:80] output data size: 64,3,227,227
I1226 07:02:46.152760 89453 db_lmdb.cpp:72] Opened lmdb /export/data1/stanford/hazy/zjian/gorden_bell/ILSVRC2012_lmdb/db_8/ilsvrc12_train_lmdb_2
I1226 07:02:46.154047 89377 data_layer.cpp:80] output data size: 64,3,227,227
I1226 07:02:46.167791 51587 data_layer.cpp:80] output data size: 64,3,227,227
I1226 07:02:46.172063 89170 data_layer.cpp:80] output data size: 64,3,227,227
I1226 07:02:46.183464 89451 data_layer.cpp:80] output data size: 64,3,227,227
I1226 07:02:46.208315 90546 net.cpp:228] Setting up data
I1226 07:02:46.208745 90546 net.cpp:235] Top shape: 64 3 227 227 (9893568)
I1226 07:02:46.208827 90546 net.cpp:235] Top shape: 64 (64)
I1226 07:02:46.208861 90546 net.cpp:243] Memory required for data: 39574528
I1226 07:02:46.208906 90546 layer_factory.hpp:114] Creating layer label_data_1_split
I1226 07:02:46.209048 90546 net.cpp:178] Creating Layer label_data_1_split
I1226 07:02:46.209236 90546 net.cpp:612] label_data_1_split <- label
I1226 07:02:46.209300 90546 net.cpp:586] label_data_1_split -> label_data_1_split_0
I1226 07:02:46.209359 90546 net.cpp:586] label_data_1_split -> label_data_1_split_1
I1226 07:02:46.223906 90546 net.cpp:228] Setting up label_data_1_split
I1226 07:02:46.224015 90546 net.cpp:235] Top shape: 64 (64)
I1226 07:02:46.224053 90546 net.cpp:235] Top shape: 64 (64)
I1226 07:02:46.224078 90546 net.cpp:243] Memory required for data: 39575040
I1226 07:02:46.224114 90546 layer_factory.hpp:114] Creating layer conv1
I1226 07:02:46.224236 90546 net.cpp:178] Creating Layer conv1
I1226 07:02:46.224292 90546 net.cpp:612] conv1 <- data
I1226 07:02:46.224341 90546 net.cpp:586] conv1 -> conv1
I1226 07:02:46.227145 89165 net.cpp:228] Setting up data
I1226 07:02:46.227279 89165 net.cpp:235] Top shape: 64 3 227 227 (9893568)
I1226 07:02:46.227319 89165 net.cpp:235] Top shape: 64 (64)
I1226 07:02:46.227344 89165 net.cpp:243] Memory required for data: 39574528
I1226 07:02:46.227382 89165 layer_factory.hpp:114] Creating layer label_data_1_split
I1226 07:02:46.227463 89165 net.cpp:178] Creating Layer label_data_1_split
I1226 07:02:46.227586 89165 net.cpp:612] label_data_1_split <- label
I1226 07:02:46.227638 89165 net.cpp:586] label_data_1_split -> label_data_1_split_0
I1226 07:02:46.227685 89165 net.cpp:586] label_data_1_split -> label_data_1_split_1
I1226 07:02:46.239141 89165 net.cpp:228] Setting up label_data_1_split
I1226 07:02:46.239269 89165 net.cpp:235] Top shape: 64 (64)
I1226 07:02:46.239302 89165 net.cpp:235] Top shape: 64 (64)
I1226 07:02:46.239326 89165 net.cpp:243] Memory required for data: 39575040
I1226 07:02:46.239362 89165 layer_factory.hpp:114] Creating layer conv1
I1226 07:02:46.239491 89165 net.cpp:178] Creating Layer conv1
I1226 07:02:46.239549 89165 net.cpp:612] conv1 <- data
I1226 07:02:46.239593 89165 net.cpp:586] conv1 -> conv1
I1226 07:02:46.250471 88126 net.cpp:228] Setting up data
I1226 07:02:46.250615 88126 net.cpp:235] Top shape: 64 3 227 227 (9893568)
I1226 07:02:46.250658 88126 net.cpp:235] Top shape: 64 (64)
I1226 07:02:46.243719 96083 net.cpp:228] Setting up conv1
I1226 07:02:46.250684 88126 net.cpp:243] Memory required for data: 39574528
I1226 07:02:46.243832 96083 net.cpp:235] Top shape: 64 96 55 55 (18585600)
I1226 07:02:46.243857 96083 net.cpp:243] Memory required for data: 113917440
I1226 07:02:46.250722 88126 layer_factory.hpp:114] Creating layer label_data_1_split
I1226 07:02:46.244010 96083 layer_factory.hpp:114] Creating layer relu1
I1226 07:02:46.250816 88126 net.cpp:178] Creating Layer label_data_1_split
I1226 07:02:46.244112 96083 net.cpp:178] Creating Layer relu1
I1226 07:02:46.250955 88126 net.cpp:612] label_data_1_split <- label
I1226 07:02:46.244153 96083 net.cpp:612] relu1 <- conv1
I1226 07:02:46.244190 96083 net.cpp:573] relu1 -> conv1 (in-place)
I1226 07:02:46.251014 88126 net.cpp:586] label_data_1_split -> label_data_1_split_0
I1226 07:02:46.244283 96083 net.cpp:228] Setting up relu1
I1226 07:02:46.251160 88126 net.cpp:586] label_data_1_split -> label_data_1_split_1
I1226 07:02:46.244324 96083 net.cpp:235] Top shape: 64 96 55 55 (18585600)
I1226 07:02:46.244346 96083 net.cpp:243] Memory required for data: 188259840
I1226 07:02:46.244374 96083 layer_factory.hpp:114] Creating layer norm1
I1226 07:02:46.244439 96083 net.cpp:178] Creating Layer norm1
I1226 07:02:46.244470 96083 net.cpp:612] norm1 <- conv1
I1226 07:02:46.244503 96083 net.cpp:586] norm1 -> norm1
I1226 07:02:46.244580 96083 net.cpp:228] Setting up norm1
I1226 07:02:46.244613 96083 net.cpp:235] Top shape: 64 96 55 55 (18585600)
I1226 07:02:46.244635 96083 net.cpp:243] Memory required for data: 262602240
I1226 07:02:46.244662 96083 layer_factory.hpp:114] Creating layer pool1
I1226 07:02:46.244714 96083 net.cpp:178] Creating Layer pool1
I1226 07:02:46.244738 96083 net.cpp:612] pool1 <- norm1
I1226 07:02:46.244773 96083 net.cpp:586] pool1 -> pool1
I1226 07:02:46.244851 96083 net.cpp:228] Setting up pool1
I1226 07:02:46.244889 96083 net.cpp:235] Top shape: 64 96 27 27 (4478976)
I1226 07:02:46.244910 96083 net.cpp:243] Memory required for data: 280518144
I1226 07:02:46.244935 96083 layer_factory.hpp:114] Creating layer conv2
I1226 07:02:46.245003 96083 net.cpp:178] Creating Layer conv2
I1226 07:02:46.245038 96083 net.cpp:612] conv2 <- pool1
I1226 07:02:46.245102 96083 net.cpp:586] conv2 -> conv2
I1226 07:02:46.251533 89377 net.cpp:228] Setting up data
I1226 07:02:46.251680 89377 net.cpp:235] Top shape: 64 3 227 227 (9893568)
I1226 07:02:46.251723 89377 net.cpp:235] Top shape: 64 (64)
I1226 07:02:46.251863 89377 net.cpp:243] Memory required for data: 39574528
I1226 07:02:46.251925 89377 layer_factory.hpp:114] Creating layer label_data_1_split
I1226 07:02:46.252096 89377 net.cpp:178] Creating Layer label_data_1_split
I1226 07:02:46.252249 89377 net.cpp:612] label_data_1_split <- label
I1226 07:02:46.252300 89377 net.cpp:586] label_data_1_split -> label_data_1_split_0
I1226 07:02:46.252497 89377 net.cpp:586] label_data_1_split -> label_data_1_split_1
I1226 07:02:46.265877 88126 net.cpp:228] Setting up label_data_1_split
I1226 07:02:46.265987 88126 net.cpp:235] Top shape: 64 (64)
I1226 07:02:46.266022 88126 net.cpp:235] Top shape: 64 (64)
I1226 07:02:46.266047 88126 net.cpp:243] Memory required for data: 39575040
I1226 07:02:46.266083 88126 layer_factory.hpp:114] Creating layer conv1
I1226 07:02:46.266186 88126 net.cpp:178] Creating Layer conv1
I1226 07:02:46.266225 88126 net.cpp:612] conv1 <- data
I1226 07:02:46.266280 88126 net.cpp:586] conv1 -> conv1
I1226 07:02:46.270041 51587 net.cpp:228] Setting up data
I1226 07:02:46.270632 51587 net.cpp:235] Top shape: 64 3 227 227 (9893568)
I1226 07:02:46.270735 51587 net.cpp:235] Top shape: 64 (64)
I1226 07:02:46.270792 51587 net.cpp:243] Memory required for data: 39574528
I1226 07:02:46.270917 51587 layer_factory.hpp:114] Creating layer label_data_1_split
I1226 07:02:46.271884 89377 net.cpp:228] Setting up label_data_1_split
I1226 07:02:46.271986 89377 net.cpp:235] Top shape: 64 (64)
I1226 07:02:46.272019 89377 net.cpp:235] Top shape: 64 (64)
I1226 07:02:46.271162 51587 net.cpp:178] Creating Layer label_data_1_split
I1226 07:02:46.272068 89377 net.cpp:243] Memory required for data: 39575040
I1226 07:02:46.271327 51587 net.cpp:612] label_data_1_split <- label
I1226 07:02:46.272202 89377 layer_factory.hpp:114] Creating layer conv1
I1226 07:02:46.272318 89377 net.cpp:178] Creating Layer conv1
I1226 07:02:46.271410 51587 net.cpp:586] label_data_1_split -> label_data_1_split_0
I1226 07:02:46.272399 89377 net.cpp:612] conv1 <- data
I1226 07:02:46.271572 51587 net.cpp:586] label_data_1_split -> label_data_1_split_1
I1226 07:02:46.272464 89377 net.cpp:586] conv1 -> conv1
I1226 07:02:46.283179 89451 net.cpp:228] Setting up data
I1226 07:02:46.283293 89451 net.cpp:235] Top shape: 64 3 227 227 (9893568)
I1226 07:02:46.283326 89451 net.cpp:235] Top shape: 64 (64)
I1226 07:02:46.283377 89451 net.cpp:243] Memory required for data: 39574528
I1226 07:02:46.283416 89451 layer_factory.hpp:114] Creating layer label_data_1_split
I1226 07:02:46.283553 89451 net.cpp:178] Creating Layer label_data_1_split
I1226 07:02:46.283699 89451 net.cpp:612] label_data_1_split <- label
I1226 07:02:46.283782 89451 net.cpp:586] label_data_1_split -> label_data_1_split_0
I1226 07:02:46.283912 89451 net.cpp:586] label_data_1_split -> label_data_1_split_1
I1226 07:02:46.278635 89170 net.cpp:228] Setting up data
I1226 07:02:46.278748 89170 net.cpp:235] Top shape: 64 3 227 227 (9893568)
I1226 07:02:46.278784 89170 net.cpp:235] Top shape: 64 (64)
I1226 07:02:46.278808 89170 net.cpp:243] Memory required for data: 39574528
I1226 07:02:46.278846 89170 layer_factory.hpp:114] Creating layer label_data_1_split
I1226 07:02:46.279199 89170 net.cpp:178] Creating Layer label_data_1_split
I1226 07:02:46.279361 89170 net.cpp:612] label_data_1_split <- label
I1226 07:02:46.279454 89170 net.cpp:586] label_data_1_split -> label_data_1_split_0
I1226 07:02:46.279515 89170 net.cpp:586] label_data_1_split -> label_data_1_split_1
I1226 07:02:46.298207 89451 net.cpp:228] Setting up label_data_1_split
I1226 07:02:46.298313 89451 net.cpp:235] Top shape: 64 (64)
I1226 07:02:46.298346 89451 net.cpp:235] Top shape: 64 (64)
I1226 07:02:46.298367 89451 net.cpp:243] Memory required for data: 39575040
I1226 07:02:46.298429 89451 layer_factory.hpp:114] Creating layer conv1
I1226 07:02:46.298699 89451 net.cpp:178] Creating Layer conv1
I1226 07:02:46.298741 89451 net.cpp:612] conv1 <- data
I1226 07:02:46.298785 89451 net.cpp:586] conv1 -> conv1
I1226 07:02:46.292006 51587 net.cpp:228] Setting up label_data_1_split
I1226 07:02:46.292165 51587 net.cpp:235] Top shape: 64 (64)
I1226 07:02:46.292207 51587 net.cpp:235] Top shape: 64 (64)
I1226 07:02:46.292263 51587 net.cpp:243] Memory required for data: 39575040
I1226 07:02:46.292306 51587 layer_factory.hpp:114] Creating layer conv1
I1226 07:02:46.292421 51587 net.cpp:178] Creating Layer conv1
I1226 07:02:46.292459 51587 net.cpp:612] conv1 <- data
I1226 07:02:46.292505 51587 net.cpp:586] conv1 -> conv1
I1226 07:02:46.300861 89170 net.cpp:228] Setting up label_data_1_split
I1226 07:02:46.300992 89170 net.cpp:235] Top shape: 64 (64)
I1226 07:02:46.301048 89170 net.cpp:235] Top shape: 64 (64)
I1226 07:02:46.301074 89170 net.cpp:243] Memory required for data: 39575040
I1226 07:02:46.301110 89170 layer_factory.hpp:114] Creating layer conv1
I1226 07:02:46.301270 89170 net.cpp:178] Creating Layer conv1
I1226 07:02:46.301326 89170 net.cpp:612] conv1 <- data
I1226 07:02:46.301389 89170 net.cpp:586] conv1 -> conv1
I1226 07:02:46.309237 93507 net.cpp:228] Setting up data
I1226 07:02:46.309365 93507 net.cpp:235] Top shape: 64 3 227 227 (9893568)
I1226 07:02:46.309417 93507 net.cpp:235] Top shape: 64 (64)
I1226 07:02:46.309448 93507 net.cpp:243] Memory required for data: 39574528
I1226 07:02:46.309502 93507 layer_factory.hpp:114] Creating layer label_data_1_split
I1226 07:02:46.309607 93507 net.cpp:178] Creating Layer label_data_1_split
I1226 07:02:46.309756 93507 net.cpp:612] label_data_1_split <- label
I1226 07:02:46.309859 93507 net.cpp:586] label_data_1_split -> label_data_1_split_0
I1226 07:02:46.309924 93507 net.cpp:586] label_data_1_split -> label_data_1_split_1
I1226 07:02:46.336416 93507 net.cpp:228] Setting up label_data_1_split
I1226 07:02:46.336534 93507 net.cpp:235] Top shape: 64 (64)
I1226 07:02:46.336572 93507 net.cpp:235] Top shape: 64 (64)
I1226 07:02:46.336638 93507 net.cpp:243] Memory required for data: 39575040
I1226 07:02:46.336828 93507 layer_factory.hpp:114] Creating layer conv1
I1226 07:02:46.336943 93507 net.cpp:178] Creating Layer conv1
I1226 07:02:46.336992 93507 net.cpp:612] conv1 <- data
I1226 07:02:46.337043 93507 net.cpp:586] conv1 -> conv1
I1226 07:02:46.422866 90546 net.cpp:228] Setting up conv1
I1226 07:02:46.422982 90546 net.cpp:235] Top shape: 64 96 55 55 (18585600)
I1226 07:02:46.423010 90546 net.cpp:243] Memory required for data: 113917440
I1226 07:02:46.423120 90546 layer_factory.hpp:114] Creating layer relu1
I1226 07:02:46.423239 90546 net.cpp:178] Creating Layer relu1
I1226 07:02:46.423283 90546 net.cpp:612] relu1 <- conv1
I1226 07:02:46.423327 90546 net.cpp:573] relu1 -> conv1 (in-place)
I1226 07:02:46.423439 90546 net.cpp:228] Setting up relu1
I1226 07:02:46.423499 90546 net.cpp:235] Top shape: 64 96 55 55 (18585600)
I1226 07:02:46.423527 90546 net.cpp:243] Memory required for data: 188259840
I1226 07:02:46.423557 90546 layer_factory.hpp:114] Creating layer norm1
I1226 07:02:46.423633 90546 net.cpp:178] Creating Layer norm1
I1226 07:02:46.423668 90546 net.cpp:612] norm1 <- conv1
I1226 07:02:46.423707 90546 net.cpp:586] norm1 -> norm1
I1226 07:02:46.423805 90546 net.cpp:228] Setting up norm1
I1226 07:02:46.423863 90546 net.cpp:235] Top shape: 64 96 55 55 (18585600)
I1226 07:02:46.423888 90546 net.cpp:243] Memory required for data: 262602240
I1226 07:02:46.423915 90546 layer_factory.hpp:114] Creating layer pool1
I1226 07:02:46.423979 90546 net.cpp:178] Creating Layer pool1
I1226 07:02:46.424011 90546 net.cpp:612] pool1 <- norm1
I1226 07:02:46.424054 90546 net.cpp:586] pool1 -> pool1
I1226 07:02:46.424149 90546 net.cpp:228] Setting up pool1
I1226 07:02:46.424216 90546 net.cpp:235] Top shape: 64 96 27 27 (4478976)
I1226 07:02:46.424238 90546 net.cpp:243] Memory required for data: 280518144
I1226 07:02:46.424266 90546 layer_factory.hpp:114] Creating layer conv2
I1226 07:02:46.424352 90546 net.cpp:178] Creating Layer conv2
I1226 07:02:46.424381 90546 net.cpp:612] conv2 <- pool1
I1226 07:02:46.424420 90546 net.cpp:586] conv2 -> conv2
I1226 07:02:46.443200 89165 net.cpp:228] Setting up conv1
I1226 07:02:46.443338 89165 net.cpp:235] Top shape: 64 96 55 55 (18585600)
I1226 07:02:46.443369 89165 net.cpp:243] Memory required for data: 113917440
I1226 07:02:46.443478 89165 layer_factory.hpp:114] Creating layer relu1
I1226 07:02:46.443600 89165 net.cpp:178] Creating Layer relu1
I1226 07:02:46.443707 89165 net.cpp:612] relu1 <- conv1
I1226 07:02:46.443768 89165 net.cpp:573] relu1 -> conv1 (in-place)
I1226 07:02:46.443907 89165 net.cpp:228] Setting up relu1
I1226 07:02:46.443976 89165 net.cpp:235] Top shape: 64 96 55 55 (18585600)
I1226 07:02:46.444002 89165 net.cpp:243] Memory required for data: 188259840
I1226 07:02:46.444265 89165 layer_factory.hpp:114] Creating layer norm1
I1226 07:02:46.444352 89165 net.cpp:178] Creating Layer norm1
I1226 07:02:46.444392 89165 net.cpp:612] norm1 <- conv1
I1226 07:02:46.444916 89165 net.cpp:586] norm1 -> norm1
I1226 07:02:46.445124 89165 net.cpp:228] Setting up norm1
I1226 07:02:46.445191 89165 net.cpp:235] Top shape: 64 96 55 55 (18585600)
I1226 07:02:46.445215 89165 net.cpp:243] Memory required for data: 262602240
I1226 07:02:46.445292 89165 layer_factory.hpp:114] Creating layer pool1
I1226 07:02:46.445374 89165 net.cpp:178] Creating Layer pool1
I1226 07:02:46.445412 89165 net.cpp:612] pool1 <- norm1
I1226 07:02:46.445459 89165 net.cpp:586] pool1 -> pool1
I1226 07:02:46.445564 89165 net.cpp:228] Setting up pool1
I1226 07:02:46.445628 89165 net.cpp:235] Top shape: 64 96 27 27 (4478976)
I1226 07:02:46.445662 89165 net.cpp:243] Memory required for data: 280518144
I1226 07:02:46.445699 89165 layer_factory.hpp:114] Creating layer conv2
I1226 07:02:46.445775 89165 net.cpp:178] Creating Layer conv2
I1226 07:02:46.445821 89165 net.cpp:612] conv2 <- pool1
I1226 07:02:46.445870 89165 net.cpp:586] conv2 -> conv2
I1226 07:02:46.460150 96083 net.cpp:228] Setting up conv2
I1226 07:02:46.460264 96083 net.cpp:235] Top shape: 64 256 27 27 (11943936)
I1226 07:02:46.460294 96083 net.cpp:243] Memory required for data: 328293888
I1226 07:02:46.460367 96083 layer_factory.hpp:114] Creating layer relu2
I1226 07:02:46.460459 96083 net.cpp:178] Creating Layer relu2
I1226 07:02:46.460499 96083 net.cpp:612] relu2 <- conv2
I1226 07:02:46.460539 96083 net.cpp:573] relu2 -> conv2 (in-place)
I1226 07:02:46.460631 96083 net.cpp:228] Setting up relu2
I1226 07:02:46.460675 96083 net.cpp:235] Top shape: 64 256 27 27 (11943936)
I1226 07:02:46.460698 96083 net.cpp:243] Memory required for data: 376069632
I1226 07:02:46.460727 96083 layer_factory.hpp:114] Creating layer norm2
I1226 07:02:46.460786 96083 net.cpp:178] Creating Layer norm2
I1226 07:02:46.460819 96083 net.cpp:612] norm2 <- conv2
I1226 07:02:46.460853 96083 net.cpp:586] norm2 -> norm2
I1226 07:02:46.460945 96083 net.cpp:228] Setting up norm2
I1226 07:02:46.460993 96083 net.cpp:235] Top shape: 64 256 27 27 (11943936)
I1226 07:02:46.461016 96083 net.cpp:243] Memory required for data: 423845376
I1226 07:02:46.461045 96083 layer_factory.hpp:114] Creating layer pool2
I1226 07:02:46.461133 96083 net.cpp:178] Creating Layer pool2
I1226 07:02:46.461165 96083 net.cpp:612] pool2 <- norm2
I1226 07:02:46.461223 96083 net.cpp:586] pool2 -> pool2
I1226 07:02:46.461319 96083 net.cpp:228] Setting up pool2
I1226 07:02:46.461359 96083 net.cpp:235] Top shape: 64 256 13 13 (2768896)
I1226 07:02:46.461478 96083 net.cpp:243] Memory required for data: 434920960
I1226 07:02:46.461514 96083 layer_factory.hpp:114] Creating layer conv3
I1226 07:02:46.461592 96083 net.cpp:178] Creating Layer conv3
I1226 07:02:46.461621 96083 net.cpp:612] conv3 <- pool2
I1226 07:02:46.461659 96083 net.cpp:586] conv3 -> conv3
I1226 07:02:46.489970 88126 net.cpp:228] Setting up conv1
I1226 07:02:46.490100 88126 net.cpp:235] Top shape: 64 96 55 55 (18585600)
I1226 07:02:46.490135 88126 net.cpp:243] Memory required for data: 113917440
I1226 07:02:46.490500 88126 layer_factory.hpp:114] Creating layer relu1
I1226 07:02:46.490720 88126 net.cpp:178] Creating Layer relu1
I1226 07:02:46.491155 88126 net.cpp:612] relu1 <- conv1
I1226 07:02:46.491261 88126 net.cpp:573] relu1 -> conv1 (in-place)
I1226 07:02:46.491490 88126 net.cpp:228] Setting up relu1
I1226 07:02:46.491649 88126 net.cpp:235] Top shape: 64 96 55 55 (18585600)
I1226 07:02:46.491680 88126 net.cpp:243] Memory required for data: 188259840
I1226 07:02:46.491715 88126 layer_factory.hpp:114] Creating layer norm1
I1226 07:02:46.491821 88126 net.cpp:178] Creating Layer norm1
I1226 07:02:46.492019 88126 net.cpp:612] norm1 <- conv1
I1226 07:02:46.492077 88126 net.cpp:586] norm1 -> norm1
I1226 07:02:46.492209 88126 net.cpp:228] Setting up norm1
I1226 07:02:46.492262 88126 net.cpp:235] Top shape: 64 96 55 55 (18585600)
I1226 07:02:46.492290 88126 net.cpp:243] Memory required for data: 262602240
I1226 07:02:46.492321 88126 layer_factory.hpp:114] Creating layer pool1
I1226 07:02:46.492748 88126 net.cpp:178] Creating Layer pool1
I1226 07:02:46.492815 88126 net.cpp:612] pool1 <- norm1
I1226 07:02:46.492871 88126 net.cpp:586] pool1 -> pool1
I1226 07:02:46.493041 88126 net.cpp:228] Setting up pool1
I1226 07:02:46.493127 88126 net.cpp:235] Top shape: 64 96 27 27 (4478976)
I1226 07:02:46.493152 88126 net.cpp:243] Memory required for data: 280518144
I1226 07:02:46.493182 88126 layer_factory.hpp:114] Creating layer conv2
I1226 07:02:46.493291 88126 net.cpp:178] Creating Layer conv2
I1226 07:02:46.493322 88126 net.cpp:612] conv2 <- pool1
I1226 07:02:46.493378 88126 net.cpp:586] conv2 -> conv2
I1226 07:02:46.491390 51587 net.cpp:228] Setting up conv1
I1226 07:02:46.492038 51587 net.cpp:235] Top shape: 64 96 55 55 (18585600)
I1226 07:02:46.492108 51587 net.cpp:243] Memory required for data: 113917440
I1226 07:02:46.492249 51587 layer_factory.hpp:114] Creating layer relu1
I1226 07:02:46.492383 51587 net.cpp:178] Creating Layer relu1
I1226 07:02:46.492525 51587 net.cpp:612] relu1 <- conv1
I1226 07:02:46.492571 51587 net.cpp:573] relu1 -> conv1 (in-place)
I1226 07:02:46.492712 51587 net.cpp:228] Setting up relu1
I1226 07:02:46.492782 51587 net.cpp:235] Top shape: 64 96 55 55 (18585600)
I1226 07:02:46.492807 51587 net.cpp:243] Memory required for data: 188259840
I1226 07:02:46.492853 51587 layer_factory.hpp:114] Creating layer norm1
I1226 07:02:46.493028 51587 net.cpp:178] Creating Layer norm1
I1226 07:02:46.493072 51587 net.cpp:612] norm1 <- conv1
I1226 07:02:46.493113 51587 net.cpp:586] norm1 -> norm1
I1226 07:02:46.493542 51587 net.cpp:228] Setting up norm1
I1226 07:02:46.493613 51587 net.cpp:235] Top shape: 64 96 55 55 (18585600)
I1226 07:02:46.493638 51587 net.cpp:243] Memory required for data: 262602240
I1226 07:02:46.493706 51587 layer_factory.hpp:114] Creating layer pool1
I1226 07:02:46.493791 51587 net.cpp:178] Creating Layer pool1
I1226 07:02:46.493849 51587 net.cpp:612] pool1 <- norm1
I1226 07:02:46.493904 51587 net.cpp:586] pool1 -> pool1
I1226 07:02:46.494007 51587 net.cpp:228] Setting up pool1
I1226 07:02:46.494051 51587 net.cpp:235] Top shape: 64 96 27 27 (4478976)
I1226 07:02:46.494074 51587 net.cpp:243] Memory required for data: 280518144
I1226 07:02:46.494102 51587 layer_factory.hpp:114] Creating layer conv2
I1226 07:02:46.494213 51587 net.cpp:178] Creating Layer conv2
I1226 07:02:46.494243 51587 net.cpp:612] conv2 <- pool1
I1226 07:02:46.494282 51587 net.cpp:586] conv2 -> conv2
I1226 07:02:46.513818 89451 net.cpp:228] Setting up conv1
I1226 07:02:46.513962 89451 net.cpp:235] Top shape: 64 96 55 55 (18585600)
I1226 07:02:46.513991 89451 net.cpp:243] Memory required for data: 113917440
I1226 07:02:46.514142 89451 layer_factory.hpp:114] Creating layer relu1
I1226 07:02:46.514266 89451 net.cpp:178] Creating Layer relu1
I1226 07:02:46.514406 89451 net.cpp:612] relu1 <- conv1
I1226 07:02:46.514447 89451 net.cpp:573] relu1 -> conv1 (in-place)
I1226 07:02:46.514955 89451 net.cpp:228] Setting up relu1
I1226 07:02:46.515019 89451 net.cpp:235] Top shape: 64 96 55 55 (18585600)
I1226 07:02:46.515069 89451 net.cpp:243] Memory required for data: 188259840
I1226 07:02:46.515180 89451 layer_factory.hpp:114] Creating layer norm1
I1226 07:02:46.515296 89451 net.cpp:178] Creating Layer norm1
I1226 07:02:46.515333 89451 net.cpp:612] norm1 <- conv1
I1226 07:02:46.515388 89451 net.cpp:586] norm1 -> norm1
I1226 07:02:46.515621 89451 net.cpp:228] Setting up norm1
I1226 07:02:46.515668 89451 net.cpp:235] Top shape: 64 96 55 55 (18585600)
I1226 07:02:46.515691 89451 net.cpp:243] Memory required for data: 262602240
I1226 07:02:46.515718 89451 layer_factory.hpp:114] Creating layer pool1
I1226 07:02:46.516049 89451 net.cpp:178] Creating Layer pool1
I1226 07:02:46.516108 89451 net.cpp:612] pool1 <- norm1
I1226 07:02:46.516171 89451 net.cpp:586] pool1 -> pool1
I1226 07:02:46.516347 89451 net.cpp:228] Setting up pool1
I1226 07:02:46.516422 89451 net.cpp:235] Top shape: 64 96 27 27 (4478976)
I1226 07:02:46.516451 89451 net.cpp:243] Memory required for data: 280518144
I1226 07:02:46.516542 89451 layer_factory.hpp:114] Creating layer conv2
I1226 07:02:46.516619 89451 net.cpp:178] Creating Layer conv2
I1226 07:02:46.516652 89451 net.cpp:612] conv2 <- pool1
I1226 07:02:46.516712 89451 net.cpp:586] conv2 -> conv2
I1226 07:02:46.511487 89377 net.cpp:228] Setting up conv1
I1226 07:02:46.511603 89377 net.cpp:235] Top shape: 64 96 55 55 (18585600)
I1226 07:02:46.511631 89377 net.cpp:243] Memory required for data: 113917440
I1226 07:02:46.511739 89377 layer_factory.hpp:114] Creating layer relu1
I1226 07:02:46.511929 89377 net.cpp:178] Creating Layer relu1
I1226 07:02:46.512048 89377 net.cpp:612] relu1 <- conv1
I1226 07:02:46.512092 89377 net.cpp:573] relu1 -> conv1 (in-place)
I1226 07:02:46.512200 89377 net.cpp:228] Setting up relu1
I1226 07:02:46.512250 89377 net.cpp:235] Top shape: 64 96 55 55 (18585600)
I1226 07:02:46.512274 89377 net.cpp:243] Memory required for data: 188259840
I1226 07:02:46.512305 89377 layer_factory.hpp:114] Creating layer norm1
I1226 07:02:46.512447 89377 net.cpp:178] Creating Layer norm1
I1226 07:02:46.512476 89377 net.cpp:612] norm1 <- conv1
I1226 07:02:46.512591 89377 net.cpp:586] norm1 -> norm1
I1226 07:02:46.512681 89377 net.cpp:228] Setting up norm1
I1226 07:02:46.512738 89377 net.cpp:235] Top shape: 64 96 55 55 (18585600)
I1226 07:02:46.512761 89377 net.cpp:243] Memory required for data: 262602240
I1226 07:02:46.512790 89377 layer_factory.hpp:114] Creating layer pool1
I1226 07:02:46.512878 89377 net.cpp:178] Creating Layer pool1
I1226 07:02:46.512991 89377 net.cpp:612] pool1 <- norm1
I1226 07:02:46.513037 89377 net.cpp:586] pool1 -> pool1
I1226 07:02:46.513133 89377 net.cpp:228] Setting up pool1
I1226 07:02:46.513177 89377 net.cpp:235] Top shape: 64 96 27 27 (4478976)
I1226 07:02:46.513200 89377 net.cpp:243] Memory required for data: 280518144
I1226 07:02:46.513227 89377 layer_factory.hpp:114] Creating layer conv2
I1226 07:02:46.513305 89377 net.cpp:178] Creating Layer conv2
I1226 07:02:46.513336 89377 net.cpp:612] conv2 <- pool1
I1226 07:02:46.513375 89377 net.cpp:586] conv2 -> conv2
I1226 07:02:46.530541 89170 net.cpp:228] Setting up conv1
I1226 07:02:46.530656 89170 net.cpp:235] Top shape: 64 96 55 55 (18585600)
I1226 07:02:46.530684 89170 net.cpp:243] Memory required for data: 113917440
I1226 07:02:46.530791 89170 layer_factory.hpp:114] Creating layer relu1
I1226 07:02:46.530882 89170 net.cpp:178] Creating Layer relu1
I1226 07:02:46.530920 89170 net.cpp:612] relu1 <- conv1
I1226 07:02:46.530961 89170 net.cpp:573] relu1 -> conv1 (in-place)
I1226 07:02:46.531062 89170 net.cpp:228] Setting up relu1
I1226 07:02:46.531100 89170 net.cpp:235] Top shape: 64 96 55 55 (18585600)
I1226 07:02:46.531124 89170 net.cpp:243] Memory required for data: 188259840
I1226 07:02:46.531162 89170 layer_factory.hpp:114] Creating layer norm1
I1226 07:02:46.531251 89170 net.cpp:178] Creating Layer norm1
I1226 07:02:46.531289 89170 net.cpp:612] norm1 <- conv1
I1226 07:02:46.531339 89170 net.cpp:586] norm1 -> norm1
I1226 07:02:46.531435 89170 net.cpp:228] Setting up norm1
I1226 07:02:46.531481 89170 net.cpp:235] Top shape: 64 96 55 55 (18585600)
I1226 07:02:46.531505 89170 net.cpp:243] Memory required for data: 262602240
I1226 07:02:46.531534 89170 layer_factory.hpp:114] Creating layer pool1
I1226 07:02:46.531597 89170 net.cpp:178] Creating Layer pool1
I1226 07:02:46.531625 89170 net.cpp:612] pool1 <- norm1
I1226 07:02:46.531673 89170 net.cpp:586] pool1 -> pool1
I1226 07:02:46.531774 89170 net.cpp:228] Setting up pool1
I1226 07:02:46.531816 89170 net.cpp:235] Top shape: 64 96 27 27 (4478976)
I1226 07:02:46.531841 89170 net.cpp:243] Memory required for data: 280518144
I1226 07:02:46.531869 89170 layer_factory.hpp:114] Creating layer conv2
I1226 07:02:46.531983 89170 net.cpp:178] Creating Layer conv2
I1226 07:02:46.532016 89170 net.cpp:612] conv2 <- pool1
I1226 07:02:46.532054 89170 net.cpp:586] conv2 -> conv2
I1226 07:02:46.690424 96083 net.cpp:228] Setting up conv3
I1226 07:02:46.690537 96083 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:46.690565 96083 net.cpp:243] Memory required for data: 451534336
I1226 07:02:46.690639 96083 layer_factory.hpp:114] Creating layer relu3
I1226 07:02:46.690727 96083 net.cpp:178] Creating Layer relu3
I1226 07:02:46.690771 96083 net.cpp:612] relu3 <- conv3
I1226 07:02:46.690824 96083 net.cpp:573] relu3 -> conv3 (in-place)
I1226 07:02:46.690913 96083 net.cpp:228] Setting up relu3
I1226 07:02:46.690963 96083 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:46.690986 96083 net.cpp:243] Memory required for data: 468147712
I1226 07:02:46.691015 96083 layer_factory.hpp:114] Creating layer conv4
I1226 07:02:46.691113 96083 net.cpp:178] Creating Layer conv4
I1226 07:02:46.691154 96083 net.cpp:612] conv4 <- conv3
I1226 07:02:46.691195 96083 net.cpp:586] conv4 -> conv4
I1226 07:02:46.743043 90546 net.cpp:228] Setting up conv2
I1226 07:02:46.743157 90546 net.cpp:235] Top shape: 64 256 27 27 (11943936)
I1226 07:02:46.743214 90546 net.cpp:243] Memory required for data: 328293888
I1226 07:02:46.743293 90546 layer_factory.hpp:114] Creating layer relu2
I1226 07:02:46.743382 90546 net.cpp:178] Creating Layer relu2
I1226 07:02:46.743422 90546 net.cpp:612] relu2 <- conv2
I1226 07:02:46.743463 90546 net.cpp:573] relu2 -> conv2 (in-place)
I1226 07:02:46.743562 90546 net.cpp:228] Setting up relu2
I1226 07:02:46.743624 90546 net.cpp:235] Top shape: 64 256 27 27 (11943936)
I1226 07:02:46.743651 90546 net.cpp:243] Memory required for data: 376069632
I1226 07:02:46.743681 90546 layer_factory.hpp:114] Creating layer norm2
I1226 07:02:46.743748 90546 net.cpp:178] Creating Layer norm2
I1226 07:02:46.743782 90546 net.cpp:612] norm2 <- conv2
I1226 07:02:46.743819 90546 net.cpp:586] norm2 -> norm2
I1226 07:02:46.743916 90546 net.cpp:228] Setting up norm2
I1226 07:02:46.743970 90546 net.cpp:235] Top shape: 64 256 27 27 (11943936)
I1226 07:02:46.743993 90546 net.cpp:243] Memory required for data: 423845376
I1226 07:02:46.744022 90546 layer_factory.hpp:114] Creating layer pool2
I1226 07:02:46.744068 90546 net.cpp:178] Creating Layer pool2
I1226 07:02:46.744093 90546 net.cpp:612] pool2 <- norm2
I1226 07:02:46.744137 90546 net.cpp:586] pool2 -> pool2
I1226 07:02:46.744254 90546 net.cpp:228] Setting up pool2
I1226 07:02:46.744299 90546 net.cpp:235] Top shape: 64 256 13 13 (2768896)
I1226 07:02:46.744420 90546 net.cpp:243] Memory required for data: 434920960
I1226 07:02:46.744457 90546 layer_factory.hpp:114] Creating layer conv3
I1226 07:02:46.744544 90546 net.cpp:178] Creating Layer conv3
I1226 07:02:46.744582 90546 net.cpp:612] conv3 <- pool2
I1226 07:02:46.744637 90546 net.cpp:586] conv3 -> conv3
I1226 07:02:46.788786 89165 net.cpp:228] Setting up conv2
I1226 07:02:46.788897 89165 net.cpp:235] Top shape: 64 256 27 27 (11943936)
I1226 07:02:46.788924 89165 net.cpp:243] Memory required for data: 328293888
I1226 07:02:46.788997 89165 layer_factory.hpp:114] Creating layer relu2
I1226 07:02:46.789080 89165 net.cpp:178] Creating Layer relu2
I1226 07:02:46.789116 89165 net.cpp:612] relu2 <- conv2
I1226 07:02:46.789155 89165 net.cpp:573] relu2 -> conv2 (in-place)
I1226 07:02:46.789270 89165 net.cpp:228] Setting up relu2
I1226 07:02:46.789315 89165 net.cpp:235] Top shape: 64 256 27 27 (11943936)
I1226 07:02:46.789338 89165 net.cpp:243] Memory required for data: 376069632
I1226 07:02:46.789366 89165 layer_factory.hpp:114] Creating layer norm2
I1226 07:02:46.789429 89165 net.cpp:178] Creating Layer norm2
I1226 07:02:46.789461 89165 net.cpp:612] norm2 <- conv2
I1226 07:02:46.789497 89165 net.cpp:586] norm2 -> norm2
I1226 07:02:46.789579 89165 net.cpp:228] Setting up norm2
I1226 07:02:46.789635 89165 net.cpp:235] Top shape: 64 256 27 27 (11943936)
I1226 07:02:46.789664 89165 net.cpp:243] Memory required for data: 423845376
I1226 07:02:46.789703 89165 layer_factory.hpp:114] Creating layer pool2
I1226 07:02:46.789757 89165 net.cpp:178] Creating Layer pool2
I1226 07:02:46.789784 89165 net.cpp:612] pool2 <- norm2
I1226 07:02:46.789824 89165 net.cpp:586] pool2 -> pool2
I1226 07:02:46.789907 89165 net.cpp:228] Setting up pool2
I1226 07:02:46.789948 89165 net.cpp:235] Top shape: 64 256 13 13 (2768896)
I1226 07:02:46.790066 89165 net.cpp:243] Memory required for data: 434920960
I1226 07:02:46.790109 89165 layer_factory.hpp:114] Creating layer conv3
I1226 07:02:46.790189 89165 net.cpp:178] Creating Layer conv3
I1226 07:02:46.790222 89165 net.cpp:612] conv3 <- pool2
I1226 07:02:46.790297 89165 net.cpp:586] conv3 -> conv3
I1226 07:02:46.852205 88126 net.cpp:228] Setting up conv2
I1226 07:02:46.855849 89451 net.cpp:228] Setting up conv2
I1226 07:02:46.852322 88126 net.cpp:235] Top shape: 64 256 27 27 (11943936)
I1226 07:02:46.852354 88126 net.cpp:243] Memory required for data: 328293888
I1226 07:02:46.855958 89451 net.cpp:235] Top shape: 64 256 27 27 (11943936)
I1226 07:02:46.855985 89451 net.cpp:243] Memory required for data: 328293888
I1226 07:02:46.852427 88126 layer_factory.hpp:114] Creating layer relu2
I1226 07:02:46.856056 89451 layer_factory.hpp:114] Creating layer relu2
I1226 07:02:46.852519 88126 net.cpp:178] Creating Layer relu2
I1226 07:02:46.852566 88126 net.cpp:612] relu2 <- conv2
I1226 07:02:46.852641 88126 net.cpp:573] relu2 -> conv2 (in-place)
I1226 07:02:46.852746 88126 net.cpp:228] Setting up relu2
I1226 07:02:46.852803 88126 net.cpp:235] Top shape: 64 256 27 27 (11943936)
I1226 07:02:46.852828 88126 net.cpp:243] Memory required for data: 376069632
I1226 07:02:46.852859 88126 layer_factory.hpp:114] Creating layer norm2
I1226 07:02:46.852924 88126 net.cpp:178] Creating Layer norm2
I1226 07:02:46.852962 88126 net.cpp:612] norm2 <- conv2
I1226 07:02:46.853001 88126 net.cpp:586] norm2 -> norm2
I1226 07:02:46.853103 88126 net.cpp:228] Setting up norm2
I1226 07:02:46.856142 89451 net.cpp:178] Creating Layer relu2
I1226 07:02:46.853153 88126 net.cpp:235] Top shape: 64 256 27 27 (11943936)
I1226 07:02:46.853178 88126 net.cpp:243] Memory required for data: 423845376
I1226 07:02:46.853207 88126 layer_factory.hpp:114] Creating layer pool2
I1226 07:02:46.856732 89451 net.cpp:612] relu2 <- conv2
I1226 07:02:46.853265 88126 net.cpp:178] Creating Layer pool2
I1226 07:02:46.856806 89451 net.cpp:573] relu2 -> conv2 (in-place)
I1226 07:02:46.853301 88126 net.cpp:612] pool2 <- norm2
I1226 07:02:46.853338 88126 net.cpp:586] pool2 -> pool2
I1226 07:02:46.856942 89451 net.cpp:228] Setting up relu2
I1226 07:02:46.853423 88126 net.cpp:228] Setting up pool2
I1226 07:02:46.857028 89451 net.cpp:235] Top shape: 64 256 27 27 (11943936)
I1226 07:02:46.853476 88126 net.cpp:235] Top shape: 64 256 13 13 (2768896)
I1226 07:02:46.857053 89451 net.cpp:243] Memory required for data: 376069632
I1226 07:02:46.853647 88126 net.cpp:243] Memory required for data: 434920960
I1226 07:02:46.857084 89451 layer_factory.hpp:114] Creating layer norm2
I1226 07:02:46.853689 88126 layer_factory.hpp:114] Creating layer conv3
I1226 07:02:46.857174 89451 net.cpp:178] Creating Layer norm2
I1226 07:02:46.857203 89451 net.cpp:612] norm2 <- conv2
I1226 07:02:46.853777 88126 net.cpp:178] Creating Layer conv3
I1226 07:02:46.857240 89451 net.cpp:586] norm2 -> norm2
I1226 07:02:46.853816 88126 net.cpp:612] conv3 <- pool2
I1226 07:02:46.857353 89451 net.cpp:228] Setting up norm2
I1226 07:02:46.853869 88126 net.cpp:586] conv3 -> conv3
I1226 07:02:46.857403 89451 net.cpp:235] Top shape: 64 256 27 27 (11943936)
I1226 07:02:46.857441 89451 net.cpp:243] Memory required for data: 423845376
I1226 07:02:46.857471 89451 layer_factory.hpp:114] Creating layer pool2
I1226 07:02:46.857563 89451 net.cpp:178] Creating Layer pool2
I1226 07:02:46.857681 89451 net.cpp:612] pool2 <- norm2
I1226 07:02:46.857719 89451 net.cpp:586] pool2 -> pool2
I1226 07:02:46.857834 89451 net.cpp:228] Setting up pool2
I1226 07:02:46.857883 89451 net.cpp:235] Top shape: 64 256 13 13 (2768896)
I1226 07:02:46.858008 89451 net.cpp:243] Memory required for data: 434920960
I1226 07:02:46.858047 89451 layer_factory.hpp:114] Creating layer conv3
I1226 07:02:46.858439 89451 net.cpp:178] Creating Layer conv3
I1226 07:02:46.858530 89451 net.cpp:612] conv3 <- pool2
I1226 07:02:46.858597 89451 net.cpp:586] conv3 -> conv3
I1226 07:02:46.858582 89377 net.cpp:228] Setting up conv2
I1226 07:02:46.858690 89377 net.cpp:235] Top shape: 64 256 27 27 (11943936)
I1226 07:02:46.858716 89377 net.cpp:243] Memory required for data: 328293888
I1226 07:02:46.858842 89377 layer_factory.hpp:114] Creating layer relu2
I1226 07:02:46.858912 89377 net.cpp:178] Creating Layer relu2
I1226 07:02:46.858944 89377 net.cpp:612] relu2 <- conv2
I1226 07:02:46.859200 89377 net.cpp:573] relu2 -> conv2 (in-place)
I1226 07:02:46.859372 89377 net.cpp:228] Setting up relu2
I1226 07:02:46.859483 89377 net.cpp:235] Top shape: 64 256 27 27 (11943936)
I1226 07:02:46.859508 89377 net.cpp:243] Memory required for data: 376069632
I1226 07:02:46.859535 89377 layer_factory.hpp:114] Creating layer norm2
I1226 07:02:46.859583 89377 net.cpp:178] Creating Layer norm2
I1226 07:02:46.859684 89377 net.cpp:612] norm2 <- conv2
I1226 07:02:46.859735 89377 net.cpp:586] norm2 -> norm2
I1226 07:02:46.859858 89377 net.cpp:228] Setting up norm2
I1226 07:02:46.859915 89377 net.cpp:235] Top shape: 64 256 27 27 (11943936)
I1226 07:02:46.859940 89377 net.cpp:243] Memory required for data: 423845376
I1226 07:02:46.859969 89377 layer_factory.hpp:114] Creating layer pool2
I1226 07:02:46.860034 89377 net.cpp:178] Creating Layer pool2
I1226 07:02:46.860062 89377 net.cpp:612] pool2 <- norm2
I1226 07:02:46.860098 89377 net.cpp:586] pool2 -> pool2
I1226 07:02:46.860189 89377 net.cpp:228] Setting up pool2
I1226 07:02:46.860232 89377 net.cpp:235] Top shape: 64 256 13 13 (2768896)
I1226 07:02:46.860348 89377 net.cpp:243] Memory required for data: 434920960
I1226 07:02:46.860381 89377 layer_factory.hpp:114] Creating layer conv3
I1226 07:02:46.860457 89377 net.cpp:178] Creating Layer conv3
I1226 07:02:46.860492 89377 net.cpp:612] conv3 <- pool2
I1226 07:02:46.860534 89377 net.cpp:586] conv3 -> conv3
I1226 07:02:46.882721 51587 net.cpp:228] Setting up conv2
I1226 07:02:46.882834 51587 net.cpp:235] Top shape: 64 256 27 27 (11943936)
I1226 07:02:46.882860 51587 net.cpp:243] Memory required for data: 328293888
I1226 07:02:46.882931 51587 layer_factory.hpp:114] Creating layer relu2
I1226 07:02:46.883018 51587 net.cpp:178] Creating Layer relu2
I1226 07:02:46.883054 51587 net.cpp:612] relu2 <- conv2
I1226 07:02:46.883103 51587 net.cpp:573] relu2 -> conv2 (in-place)
I1226 07:02:46.883220 51587 net.cpp:228] Setting up relu2
I1226 07:02:46.883271 51587 net.cpp:235] Top shape: 64 256 27 27 (11943936)
I1226 07:02:46.883296 51587 net.cpp:243] Memory required for data: 376069632
I1226 07:02:46.883324 51587 layer_factory.hpp:114] Creating layer norm2
I1226 07:02:46.883371 51587 net.cpp:178] Creating Layer norm2
I1226 07:02:46.883419 51587 net.cpp:612] norm2 <- conv2
I1226 07:02:46.883457 51587 net.cpp:586] norm2 -> norm2
I1226 07:02:46.883551 51587 net.cpp:228] Setting up norm2
I1226 07:02:46.883601 51587 net.cpp:235] Top shape: 64 256 27 27 (11943936)
I1226 07:02:46.883626 51587 net.cpp:243] Memory required for data: 423845376
I1226 07:02:46.883653 51587 layer_factory.hpp:114] Creating layer pool2
I1226 07:02:46.883705 51587 net.cpp:178] Creating Layer pool2
I1226 07:02:46.883738 51587 net.cpp:612] pool2 <- norm2
I1226 07:02:46.883772 51587 net.cpp:586] pool2 -> pool2
I1226 07:02:46.883848 51587 net.cpp:228] Setting up pool2
I1226 07:02:46.883889 51587 net.cpp:235] Top shape: 64 256 13 13 (2768896)
I1226 07:02:46.884006 51587 net.cpp:243] Memory required for data: 434920960
I1226 07:02:46.884039 51587 layer_factory.hpp:114] Creating layer conv3
I1226 07:02:46.882979 89170 net.cpp:228] Setting up conv2
I1226 07:02:46.884157 51587 net.cpp:178] Creating Layer conv3
I1226 07:02:46.883088 89170 net.cpp:235] Top shape: 64 256 27 27 (11943936)
I1226 07:02:46.883116 89170 net.cpp:243] Memory required for data: 328293888
I1226 07:02:46.884196 51587 net.cpp:612] conv3 <- pool2
I1226 07:02:46.884237 51587 net.cpp:586] conv3 -> conv3
I1226 07:02:46.883186 89170 layer_factory.hpp:114] Creating layer relu2
I1226 07:02:46.883268 89170 net.cpp:178] Creating Layer relu2
I1226 07:02:46.883307 89170 net.cpp:612] relu2 <- conv2
I1226 07:02:46.883375 89170 net.cpp:573] relu2 -> conv2 (in-place)
I1226 07:02:46.883471 89170 net.cpp:228] Setting up relu2
I1226 07:02:46.883514 89170 net.cpp:235] Top shape: 64 256 27 27 (11943936)
I1226 07:02:46.883538 89170 net.cpp:243] Memory required for data: 376069632
I1226 07:02:46.883565 89170 layer_factory.hpp:114] Creating layer norm2
I1226 07:02:46.883613 89170 net.cpp:178] Creating Layer norm2
I1226 07:02:46.883638 89170 net.cpp:612] norm2 <- conv2
I1226 07:02:46.883685 89170 net.cpp:586] norm2 -> norm2
I1226 07:02:46.883774 89170 net.cpp:228] Setting up norm2
I1226 07:02:46.883819 89170 net.cpp:235] Top shape: 64 256 27 27 (11943936)
I1226 07:02:46.883841 89170 net.cpp:243] Memory required for data: 423845376
I1226 07:02:46.883869 89170 layer_factory.hpp:114] Creating layer pool2
I1226 07:02:46.883921 89170 net.cpp:178] Creating Layer pool2
I1226 07:02:46.883954 89170 net.cpp:612] pool2 <- norm2
I1226 07:02:46.883985 89170 net.cpp:586] pool2 -> pool2
I1226 07:02:46.884055 89170 net.cpp:228] Setting up pool2
I1226 07:02:46.884089 89170 net.cpp:235] Top shape: 64 256 13 13 (2768896)
I1226 07:02:46.884202 89170 net.cpp:243] Memory required for data: 434920960
I1226 07:02:46.884261 89170 layer_factory.hpp:114] Creating layer conv3
I1226 07:02:46.884344 89170 net.cpp:178] Creating Layer conv3
I1226 07:02:46.884383 89170 net.cpp:612] conv3 <- pool2
I1226 07:02:46.884423 89170 net.cpp:586] conv3 -> conv3
I1226 07:02:46.898542 96083 net.cpp:228] Setting up conv4
I1226 07:02:46.898651 96083 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:46.898679 96083 net.cpp:243] Memory required for data: 484761088
I1226 07:02:46.898741 96083 layer_factory.hpp:114] Creating layer relu4
I1226 07:02:46.898813 96083 net.cpp:178] Creating Layer relu4
I1226 07:02:46.898854 96083 net.cpp:612] relu4 <- conv4
I1226 07:02:46.898903 96083 net.cpp:573] relu4 -> conv4 (in-place)
I1226 07:02:46.899006 96083 net.cpp:228] Setting up relu4
I1226 07:02:46.899060 96083 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:46.899108 96083 net.cpp:243] Memory required for data: 501374464
I1226 07:02:46.899142 96083 layer_factory.hpp:114] Creating layer conv5
I1226 07:02:46.899240 96083 net.cpp:178] Creating Layer conv5
I1226 07:02:46.899281 96083 net.cpp:612] conv5 <- conv4
I1226 07:02:46.899322 96083 net.cpp:586] conv5 -> conv5
I1226 07:02:46.976279 93507 net.cpp:228] Setting up conv1
I1226 07:02:46.976395 93507 net.cpp:235] Top shape: 64 96 55 55 (18585600)
I1226 07:02:46.976426 93507 net.cpp:243] Memory required for data: 113917440
I1226 07:02:46.976537 93507 layer_factory.hpp:114] Creating layer relu1
I1226 07:02:46.976639 93507 net.cpp:178] Creating Layer relu1
I1226 07:02:46.976683 93507 net.cpp:612] relu1 <- conv1
I1226 07:02:46.976727 93507 net.cpp:573] relu1 -> conv1 (in-place)
I1226 07:02:46.976866 93507 net.cpp:228] Setting up relu1
I1226 07:02:46.976927 93507 net.cpp:235] Top shape: 64 96 55 55 (18585600)
I1226 07:02:46.976953 93507 net.cpp:243] Memory required for data: 188259840
I1226 07:02:46.976982 93507 layer_factory.hpp:114] Creating layer norm1
I1226 07:02:46.977066 93507 net.cpp:178] Creating Layer norm1
I1226 07:02:46.977103 93507 net.cpp:612] norm1 <- conv1
I1226 07:02:46.977152 93507 net.cpp:586] norm1 -> norm1
I1226 07:02:46.977262 93507 net.cpp:228] Setting up norm1
I1226 07:02:46.977308 93507 net.cpp:235] Top shape: 64 96 55 55 (18585600)
I1226 07:02:46.977332 93507 net.cpp:243] Memory required for data: 262602240
I1226 07:02:46.977362 93507 layer_factory.hpp:114] Creating layer pool1
I1226 07:02:46.977428 93507 net.cpp:178] Creating Layer pool1
I1226 07:02:46.977463 93507 net.cpp:612] pool1 <- norm1
I1226 07:02:46.977510 93507 net.cpp:586] pool1 -> pool1
I1226 07:02:46.977601 93507 net.cpp:228] Setting up pool1
I1226 07:02:46.977645 93507 net.cpp:235] Top shape: 64 96 27 27 (4478976)
I1226 07:02:46.977669 93507 net.cpp:243] Memory required for data: 280518144
I1226 07:02:46.977696 93507 layer_factory.hpp:114] Creating layer conv2
I1226 07:02:46.977782 93507 net.cpp:178] Creating Layer conv2
I1226 07:02:46.977864 93507 net.cpp:612] conv2 <- pool1
I1226 07:02:46.977910 93507 net.cpp:586] conv2 -> conv2
I1226 07:02:47.047415 96083 net.cpp:228] Setting up conv5
I1226 07:02:47.047523 96083 net.cpp:235] Top shape: 64 256 13 13 (2768896)
I1226 07:02:47.047550 96083 net.cpp:243] Memory required for data: 512450048
I1226 07:02:47.047623 96083 layer_factory.hpp:114] Creating layer relu5
I1226 07:02:47.047688 96083 net.cpp:178] Creating Layer relu5
I1226 07:02:47.047716 96083 net.cpp:612] relu5 <- conv5
I1226 07:02:47.047868 96083 net.cpp:573] relu5 -> conv5 (in-place)
I1226 07:02:47.047971 96083 net.cpp:228] Setting up relu5
I1226 07:02:47.048019 96083 net.cpp:235] Top shape: 64 256 13 13 (2768896)
I1226 07:02:47.048048 96083 net.cpp:243] Memory required for data: 523525632
I1226 07:02:47.048101 96083 layer_factory.hpp:114] Creating layer pool5
I1226 07:02:47.048169 96083 net.cpp:178] Creating Layer pool5
I1226 07:02:47.048213 96083 net.cpp:612] pool5 <- conv5
I1226 07:02:47.048256 96083 net.cpp:586] pool5 -> pool5
I1226 07:02:47.048355 96083 net.cpp:228] Setting up pool5
I1226 07:02:47.048403 96083 net.cpp:235] Top shape: 64 256 6 6 (589824)
I1226 07:02:47.048425 96083 net.cpp:243] Memory required for data: 525884928
I1226 07:02:47.048451 96083 layer_factory.hpp:114] Creating layer fc6
I1226 07:02:47.048533 96083 net.cpp:178] Creating Layer fc6
I1226 07:02:47.048568 96083 net.cpp:612] fc6 <- pool5
I1226 07:02:47.048612 96083 net.cpp:586] fc6 -> fc6
I1226 07:02:47.120626 90546 net.cpp:228] Setting up conv3
I1226 07:02:47.120736 90546 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:47.120764 90546 net.cpp:243] Memory required for data: 451534336
I1226 07:02:47.120838 90546 layer_factory.hpp:114] Creating layer relu3
I1226 07:02:47.120923 90546 net.cpp:178] Creating Layer relu3
I1226 07:02:47.120964 90546 net.cpp:612] relu3 <- conv3
I1226 07:02:47.121008 90546 net.cpp:573] relu3 -> conv3 (in-place)
I1226 07:02:47.121121 90546 net.cpp:228] Setting up relu3
I1226 07:02:47.121206 90546 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:47.121237 90546 net.cpp:243] Memory required for data: 468147712
I1226 07:02:47.121269 90546 layer_factory.hpp:114] Creating layer conv4
I1226 07:02:47.121368 90546 net.cpp:178] Creating Layer conv4
I1226 07:02:47.121405 90546 net.cpp:612] conv4 <- conv3
I1226 07:02:47.121459 90546 net.cpp:586] conv4 -> conv4
I1226 07:02:47.124430 89165 net.cpp:228] Setting up conv3
I1226 07:02:47.124541 89165 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:47.124568 89165 net.cpp:243] Memory required for data: 451534336
I1226 07:02:47.124639 89165 layer_factory.hpp:114] Creating layer relu3
I1226 07:02:47.124721 89165 net.cpp:178] Creating Layer relu3
I1226 07:02:47.124759 89165 net.cpp:612] relu3 <- conv3
I1226 07:02:47.124800 89165 net.cpp:573] relu3 -> conv3 (in-place)
I1226 07:02:47.124891 89165 net.cpp:228] Setting up relu3
I1226 07:02:47.124935 89165 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:47.124958 89165 net.cpp:243] Memory required for data: 468147712
I1226 07:02:47.124987 89165 layer_factory.hpp:114] Creating layer conv4
I1226 07:02:47.125067 89165 net.cpp:178] Creating Layer conv4
I1226 07:02:47.125102 89165 net.cpp:612] conv4 <- conv3
I1226 07:02:47.125149 89165 net.cpp:586] conv4 -> conv4
I1226 07:02:47.233156 89451 net.cpp:228] Setting up conv3
I1226 07:02:47.233264 89451 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:47.233289 89451 net.cpp:243] Memory required for data: 451534336
I1226 07:02:47.233386 89451 layer_factory.hpp:114] Creating layer relu3
I1226 07:02:47.233466 89451 net.cpp:178] Creating Layer relu3
I1226 07:02:47.233522 89451 net.cpp:612] relu3 <- conv3
I1226 07:02:47.233561 89451 net.cpp:573] relu3 -> conv3 (in-place)
I1226 07:02:47.233666 89451 net.cpp:228] Setting up relu3
I1226 07:02:47.233713 89451 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:47.233736 89451 net.cpp:243] Memory required for data: 468147712
I1226 07:02:47.233764 89451 layer_factory.hpp:114] Creating layer conv4
I1226 07:02:47.233857 89451 net.cpp:178] Creating Layer conv4
I1226 07:02:47.233891 89451 net.cpp:612] conv4 <- conv3
I1226 07:02:47.233940 89451 net.cpp:586] conv4 -> conv4
I1226 07:02:47.246562 88126 net.cpp:228] Setting up conv3
I1226 07:02:47.246721 88126 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:47.246748 88126 net.cpp:243] Memory required for data: 451534336
I1226 07:02:47.246819 88126 layer_factory.hpp:114] Creating layer relu3
I1226 07:02:47.246886 88126 net.cpp:178] Creating Layer relu3
I1226 07:02:47.246915 88126 net.cpp:612] relu3 <- conv3
I1226 07:02:47.246973 88126 net.cpp:573] relu3 -> conv3 (in-place)
I1226 07:02:47.247068 88126 net.cpp:228] Setting up relu3
I1226 07:02:47.247104 88126 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:47.247128 88126 net.cpp:243] Memory required for data: 468147712
I1226 07:02:47.247153 88126 layer_factory.hpp:114] Creating layer conv4
I1226 07:02:47.247232 88126 net.cpp:178] Creating Layer conv4
I1226 07:02:47.247277 88126 net.cpp:612] conv4 <- conv3
I1226 07:02:47.247331 88126 net.cpp:586] conv4 -> conv4
I1226 07:02:47.254883 89377 net.cpp:228] Setting up conv3
I1226 07:02:47.255028 89377 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:47.255065 89377 net.cpp:243] Memory required for data: 451534336
I1226 07:02:47.255141 89377 layer_factory.hpp:114] Creating layer relu3
I1226 07:02:47.255553 89377 net.cpp:178] Creating Layer relu3
I1226 07:02:47.255626 89377 net.cpp:612] relu3 <- conv3
I1226 07:02:47.255753 89377 net.cpp:573] relu3 -> conv3 (in-place)
I1226 07:02:47.255915 89377 net.cpp:228] Setting up relu3
I1226 07:02:47.255995 89377 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:47.256026 89377 net.cpp:243] Memory required for data: 468147712
I1226 07:02:47.256072 89377 layer_factory.hpp:114] Creating layer conv4
I1226 07:02:47.256181 89377 net.cpp:178] Creating Layer conv4
I1226 07:02:47.256214 89377 net.cpp:612] conv4 <- conv3
I1226 07:02:47.256268 89377 net.cpp:586] conv4 -> conv4
I1226 07:02:47.255695 51587 net.cpp:228] Setting up conv3
I1226 07:02:47.255801 51587 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:47.255828 51587 net.cpp:243] Memory required for data: 451534336
I1226 07:02:47.255918 51587 layer_factory.hpp:114] Creating layer relu3
I1226 07:02:47.255988 51587 net.cpp:178] Creating Layer relu3
I1226 07:02:47.256038 51587 net.cpp:612] relu3 <- conv3
I1226 07:02:47.256078 51587 net.cpp:573] relu3 -> conv3 (in-place)
I1226 07:02:47.256198 51587 net.cpp:228] Setting up relu3
I1226 07:02:47.256242 51587 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:47.256265 51587 net.cpp:243] Memory required for data: 468147712
I1226 07:02:47.256294 51587 layer_factory.hpp:114] Creating layer conv4
I1226 07:02:47.256374 51587 net.cpp:178] Creating Layer conv4
I1226 07:02:47.256472 51587 net.cpp:612] conv4 <- conv3
I1226 07:02:47.256527 51587 net.cpp:586] conv4 -> conv4
I1226 07:02:47.269877 89170 net.cpp:228] Setting up conv3
I1226 07:02:47.269984 89170 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:47.270009 89170 net.cpp:243] Memory required for data: 451534336
I1226 07:02:47.270094 89170 layer_factory.hpp:114] Creating layer relu3
I1226 07:02:47.270186 89170 net.cpp:178] Creating Layer relu3
I1226 07:02:47.270325 89170 net.cpp:612] relu3 <- conv3
I1226 07:02:47.270386 89170 net.cpp:573] relu3 -> conv3 (in-place)
I1226 07:02:47.270479 89170 net.cpp:228] Setting up relu3
I1226 07:02:47.270561 89170 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:47.270586 89170 net.cpp:243] Memory required for data: 468147712
I1226 07:02:47.270634 89170 layer_factory.hpp:114] Creating layer conv4
I1226 07:02:47.270771 89170 net.cpp:178] Creating Layer conv4
I1226 07:02:47.270800 89170 net.cpp:612] conv4 <- conv3
I1226 07:02:47.270848 89170 net.cpp:586] conv4 -> conv4
I1226 07:02:47.430802 90546 net.cpp:228] Setting up conv4
I1226 07:02:47.430912 90546 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:47.430939 90546 net.cpp:243] Memory required for data: 484761088
I1226 07:02:47.430997 90546 layer_factory.hpp:114] Creating layer relu4
I1226 07:02:47.431061 90546 net.cpp:178] Creating Layer relu4
I1226 07:02:47.431097 90546 net.cpp:612] relu4 <- conv4
I1226 07:02:47.431161 90546 net.cpp:573] relu4 -> conv4 (in-place)
I1226 07:02:47.431303 90546 net.cpp:228] Setting up relu4
I1226 07:02:47.431375 90546 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:47.431406 90546 net.cpp:243] Memory required for data: 501374464
I1226 07:02:47.431470 90546 layer_factory.hpp:114] Creating layer conv5
I1226 07:02:47.431565 90546 net.cpp:178] Creating Layer conv5
I1226 07:02:47.431597 90546 net.cpp:612] conv5 <- conv4
I1226 07:02:47.431676 90546 net.cpp:586] conv5 -> conv5
I1226 07:02:47.471761 89165 net.cpp:228] Setting up conv4
I1226 07:02:47.471895 89165 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:47.471923 89165 net.cpp:243] Memory required for data: 484761088
I1226 07:02:47.472017 89165 layer_factory.hpp:114] Creating layer relu4
I1226 07:02:47.472138 89165 net.cpp:178] Creating Layer relu4
I1226 07:02:47.472184 89165 net.cpp:612] relu4 <- conv4
I1226 07:02:47.472241 89165 net.cpp:573] relu4 -> conv4 (in-place)
I1226 07:02:47.472697 89165 net.cpp:228] Setting up relu4
I1226 07:02:47.472801 89165 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:47.472827 89165 net.cpp:243] Memory required for data: 501374464
I1226 07:02:47.472861 89165 layer_factory.hpp:114] Creating layer conv5
I1226 07:02:47.472983 89165 net.cpp:178] Creating Layer conv5
I1226 07:02:47.473115 89165 net.cpp:612] conv5 <- conv4
I1226 07:02:47.473182 89165 net.cpp:586] conv5 -> conv5
I1226 07:02:47.544112 89451 net.cpp:228] Setting up conv4
I1226 07:02:47.544251 89451 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:47.544286 89451 net.cpp:243] Memory required for data: 484761088
I1226 07:02:47.544345 89451 layer_factory.hpp:114] Creating layer relu4
I1226 07:02:47.544471 89451 net.cpp:178] Creating Layer relu4
I1226 07:02:47.544559 89451 net.cpp:612] relu4 <- conv4
I1226 07:02:47.544632 89451 net.cpp:573] relu4 -> conv4 (in-place)
I1226 07:02:47.544761 89451 net.cpp:228] Setting up relu4
I1226 07:02:47.544953 89451 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:47.544980 89451 net.cpp:243] Memory required for data: 501374464
I1226 07:02:47.545030 89451 layer_factory.hpp:114] Creating layer conv5
I1226 07:02:47.545126 89451 net.cpp:178] Creating Layer conv5
I1226 07:02:47.545742 89451 net.cpp:612] conv5 <- conv4
I1226 07:02:47.545917 89451 net.cpp:586] conv5 -> conv5
I1226 07:02:47.546833 88126 net.cpp:228] Setting up conv4
I1226 07:02:47.546969 88126 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:47.546996 88126 net.cpp:243] Memory required for data: 484761088
I1226 07:02:47.547055 88126 layer_factory.hpp:114] Creating layer relu4
I1226 07:02:47.547122 88126 net.cpp:178] Creating Layer relu4
I1226 07:02:47.547178 88126 net.cpp:612] relu4 <- conv4
I1226 07:02:47.547296 88126 net.cpp:573] relu4 -> conv4 (in-place)
I1226 07:02:47.547372 88126 net.cpp:228] Setting up relu4
I1226 07:02:47.547417 88126 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:47.547441 88126 net.cpp:243] Memory required for data: 501374464
I1226 07:02:47.547468 88126 layer_factory.hpp:114] Creating layer conv5
I1226 07:02:47.547560 88126 net.cpp:178] Creating Layer conv5
I1226 07:02:47.547627 88126 net.cpp:612] conv5 <- conv4
I1226 07:02:47.547694 88126 net.cpp:586] conv5 -> conv5
I1226 07:02:47.562126 89170 net.cpp:228] Setting up conv4
I1226 07:02:47.563093 51587 net.cpp:228] Setting up conv4
I1226 07:02:47.562269 89170 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:47.562304 89170 net.cpp:243] Memory required for data: 484761088
I1226 07:02:47.563482 51587 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:47.562364 89170 layer_factory.hpp:114] Creating layer relu4
I1226 07:02:47.562453 89170 net.cpp:178] Creating Layer relu4
I1226 07:02:47.562500 89170 net.cpp:612] relu4 <- conv4
I1226 07:02:47.562662 89170 net.cpp:573] relu4 -> conv4 (in-place)
I1226 07:02:47.563513 51587 net.cpp:243] Memory required for data: 484761088
I1226 07:02:47.562858 89170 net.cpp:228] Setting up relu4
I1226 07:02:47.563952 51587 layer_factory.hpp:114] Creating layer relu4
I1226 07:02:47.564059 51587 net.cpp:178] Creating Layer relu4
I1226 07:02:47.564193 51587 net.cpp:612] relu4 <- conv4
I1226 07:02:47.564261 51587 net.cpp:573] relu4 -> conv4 (in-place)
I1226 07:02:47.564368 51587 net.cpp:228] Setting up relu4
I1226 07:02:47.562916 89170 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:47.564420 51587 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:47.564443 51587 net.cpp:243] Memory required for data: 501374464
I1226 07:02:47.563302 89170 net.cpp:243] Memory required for data: 501374464
I1226 07:02:47.564473 51587 layer_factory.hpp:114] Creating layer conv5
I1226 07:02:47.563386 89170 layer_factory.hpp:114] Creating layer conv5
I1226 07:02:47.564580 51587 net.cpp:178] Creating Layer conv5
I1226 07:02:47.564633 51587 net.cpp:612] conv5 <- conv4
I1226 07:02:47.563531 89170 net.cpp:178] Creating Layer conv5
I1226 07:02:47.563627 89170 net.cpp:612] conv5 <- conv4
I1226 07:02:47.564939 51587 net.cpp:586] conv5 -> conv5
I1226 07:02:47.563684 89170 net.cpp:586] conv5 -> conv5
I1226 07:02:47.583225 89377 net.cpp:228] Setting up conv4
I1226 07:02:47.583369 89377 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:47.583401 89377 net.cpp:243] Memory required for data: 484761088
I1226 07:02:47.583490 89377 layer_factory.hpp:114] Creating layer relu4
I1226 07:02:47.583556 89377 net.cpp:178] Creating Layer relu4
I1226 07:02:47.583602 89377 net.cpp:612] relu4 <- conv4
I1226 07:02:47.583660 89377 net.cpp:573] relu4 -> conv4 (in-place)
I1226 07:02:47.583787 89377 net.cpp:228] Setting up relu4
I1226 07:02:47.583971 89377 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:47.584005 89377 net.cpp:243] Memory required for data: 501374464
I1226 07:02:47.584038 89377 layer_factory.hpp:114] Creating layer conv5
I1226 07:02:47.584127 89377 net.cpp:178] Creating Layer conv5
I1226 07:02:47.584600 89377 net.cpp:612] conv5 <- conv4
I1226 07:02:47.584699 89377 net.cpp:586] conv5 -> conv5
I1226 07:02:47.660084 90546 net.cpp:228] Setting up conv5
I1226 07:02:47.660223 90546 net.cpp:235] Top shape: 64 256 13 13 (2768896)
I1226 07:02:47.660253 90546 net.cpp:243] Memory required for data: 512450048
I1226 07:02:47.660326 90546 layer_factory.hpp:114] Creating layer relu5
I1226 07:02:47.660415 90546 net.cpp:178] Creating Layer relu5
I1226 07:02:47.660455 90546 net.cpp:612] relu5 <- conv5
I1226 07:02:47.660496 90546 net.cpp:573] relu5 -> conv5 (in-place)
I1226 07:02:47.660591 90546 net.cpp:228] Setting up relu5
I1226 07:02:47.660636 90546 net.cpp:235] Top shape: 64 256 13 13 (2768896)
I1226 07:02:47.660660 90546 net.cpp:243] Memory required for data: 523525632
I1226 07:02:47.660688 90546 layer_factory.hpp:114] Creating layer pool5
I1226 07:02:47.660751 90546 net.cpp:178] Creating Layer pool5
I1226 07:02:47.660784 90546 net.cpp:612] pool5 <- conv5
I1226 07:02:47.660821 90546 net.cpp:586] pool5 -> pool5
I1226 07:02:47.660912 90546 net.cpp:228] Setting up pool5
I1226 07:02:47.660979 90546 net.cpp:235] Top shape: 64 256 6 6 (589824)
I1226 07:02:47.661003 90546 net.cpp:243] Memory required for data: 525884928
I1226 07:02:47.661031 90546 layer_factory.hpp:114] Creating layer fc6
I1226 07:02:47.661104 90546 net.cpp:178] Creating Layer fc6
I1226 07:02:47.661133 90546 net.cpp:612] fc6 <- pool5
I1226 07:02:47.661239 90546 net.cpp:586] fc6 -> fc6
I1226 07:02:47.709610 89165 net.cpp:228] Setting up conv5
I1226 07:02:47.709722 89165 net.cpp:235] Top shape: 64 256 13 13 (2768896)
I1226 07:02:47.709785 89165 net.cpp:243] Memory required for data: 512450048
I1226 07:02:47.709888 89165 layer_factory.hpp:114] Creating layer relu5
I1226 07:02:47.710080 89165 net.cpp:178] Creating Layer relu5
I1226 07:02:47.710115 89165 net.cpp:612] relu5 <- conv5
I1226 07:02:47.710155 89165 net.cpp:573] relu5 -> conv5 (in-place)
I1226 07:02:47.710278 89165 net.cpp:228] Setting up relu5
I1226 07:02:47.710356 89165 net.cpp:235] Top shape: 64 256 13 13 (2768896)
I1226 07:02:47.710381 89165 net.cpp:243] Memory required for data: 523525632
I1226 07:02:47.710412 89165 layer_factory.hpp:114] Creating layer pool5
I1226 07:02:47.710589 89165 net.cpp:178] Creating Layer pool5
I1226 07:02:47.710644 89165 net.cpp:612] pool5 <- conv5
I1226 07:02:47.710788 89165 net.cpp:586] pool5 -> pool5
I1226 07:02:47.710886 89165 net.cpp:228] Setting up pool5
I1226 07:02:47.710952 89165 net.cpp:235] Top shape: 64 256 6 6 (589824)
I1226 07:02:47.710978 89165 net.cpp:243] Memory required for data: 525884928
I1226 07:02:47.711343 89165 layer_factory.hpp:114] Creating layer fc6
I1226 07:02:47.711467 89165 net.cpp:178] Creating Layer fc6
I1226 07:02:47.711500 89165 net.cpp:612] fc6 <- pool5
I1226 07:02:47.711599 89165 net.cpp:586] fc6 -> fc6
I1226 07:02:47.750870 88126 net.cpp:228] Setting up conv5
I1226 07:02:47.751014 88126 net.cpp:235] Top shape: 64 256 13 13 (2768896)
I1226 07:02:47.751080 88126 net.cpp:243] Memory required for data: 512450048
I1226 07:02:47.751307 88126 layer_factory.hpp:114] Creating layer relu5
I1226 07:02:47.751404 88126 net.cpp:178] Creating Layer relu5
I1226 07:02:47.751441 88126 net.cpp:612] relu5 <- conv5
I1226 07:02:47.751526 88126 net.cpp:573] relu5 -> conv5 (in-place)
I1226 07:02:47.751660 88126 net.cpp:228] Setting up relu5
I1226 07:02:47.752048 88126 net.cpp:235] Top shape: 64 256 13 13 (2768896)
I1226 07:02:47.752081 88126 net.cpp:243] Memory required for data: 523525632
I1226 07:02:47.752117 88126 layer_factory.hpp:114] Creating layer pool5
I1226 07:02:47.752316 88126 net.cpp:178] Creating Layer pool5
I1226 07:02:47.752359 88126 net.cpp:612] pool5 <- conv5
I1226 07:02:47.752427 88126 net.cpp:586] pool5 -> pool5
I1226 07:02:47.752661 88126 net.cpp:228] Setting up pool5
I1226 07:02:47.752745 88126 net.cpp:235] Top shape: 64 256 6 6 (589824)
I1226 07:02:47.752794 88126 net.cpp:243] Memory required for data: 525884928
I1226 07:02:47.752830 88126 layer_factory.hpp:114] Creating layer fc6
I1226 07:02:47.752944 88126 net.cpp:178] Creating Layer fc6
I1226 07:02:47.752979 88126 net.cpp:612] fc6 <- pool5
I1226 07:02:47.753036 88126 net.cpp:586] fc6 -> fc6
I1226 07:02:47.781030 89451 net.cpp:228] Setting up conv5
I1226 07:02:47.781144 89451 net.cpp:235] Top shape: 64 256 13 13 (2768896)
I1226 07:02:47.781170 89451 net.cpp:243] Memory required for data: 512450048
I1226 07:02:47.781242 89451 layer_factory.hpp:114] Creating layer relu5
I1226 07:02:47.781325 89451 net.cpp:178] Creating Layer relu5
I1226 07:02:47.781443 89451 net.cpp:612] relu5 <- conv5
I1226 07:02:47.781505 89451 net.cpp:573] relu5 -> conv5 (in-place)
I1226 07:02:47.781611 89451 net.cpp:228] Setting up relu5
I1226 07:02:47.781661 89451 net.cpp:235] Top shape: 64 256 13 13 (2768896)
I1226 07:02:47.781687 89451 net.cpp:243] Memory required for data: 523525632
I1226 07:02:47.781714 89451 layer_factory.hpp:114] Creating layer pool5
I1226 07:02:47.781777 89451 net.cpp:178] Creating Layer pool5
I1226 07:02:47.781813 89451 net.cpp:612] pool5 <- conv5
I1226 07:02:47.781852 89451 net.cpp:586] pool5 -> pool5
I1226 07:02:47.781941 89451 net.cpp:228] Setting up pool5
I1226 07:02:47.781994 89451 net.cpp:235] Top shape: 64 256 6 6 (589824)
I1226 07:02:47.782016 89451 net.cpp:243] Memory required for data: 525884928
I1226 07:02:47.782042 89451 layer_factory.hpp:114] Creating layer fc6
I1226 07:02:47.782124 89451 net.cpp:178] Creating Layer fc6
I1226 07:02:47.782155 89451 net.cpp:612] fc6 <- pool5
I1226 07:02:47.782204 89451 net.cpp:586] fc6 -> fc6
I1226 07:02:47.809294 51587 net.cpp:228] Setting up conv5
I1226 07:02:47.809406 51587 net.cpp:235] Top shape: 64 256 13 13 (2768896)
I1226 07:02:47.809432 51587 net.cpp:243] Memory required for data: 512450048
I1226 07:02:47.809556 51587 layer_factory.hpp:114] Creating layer relu5
I1226 07:02:47.809638 51587 net.cpp:178] Creating Layer relu5
I1226 07:02:47.809788 51587 net.cpp:612] relu5 <- conv5
I1226 07:02:47.809842 51587 net.cpp:573] relu5 -> conv5 (in-place)
I1226 07:02:47.809939 51587 net.cpp:228] Setting up relu5
I1226 07:02:47.810359 51587 net.cpp:235] Top shape: 64 256 13 13 (2768896)
I1226 07:02:47.810433 51587 net.cpp:243] Memory required for data: 523525632
I1226 07:02:47.810524 51587 layer_factory.hpp:114] Creating layer pool5
I1226 07:02:47.810632 51587 net.cpp:178] Creating Layer pool5
I1226 07:02:47.810705 51587 net.cpp:612] pool5 <- conv5
I1226 07:02:47.810752 51587 net.cpp:586] pool5 -> pool5
I1226 07:02:47.810854 51587 net.cpp:228] Setting up pool5
I1226 07:02:47.810904 51587 net.cpp:235] Top shape: 64 256 6 6 (589824)
I1226 07:02:47.810927 51587 net.cpp:243] Memory required for data: 525884928
I1226 07:02:47.810956 51587 layer_factory.hpp:114] Creating layer fc6
I1226 07:02:47.811034 51587 net.cpp:178] Creating Layer fc6
I1226 07:02:47.811066 51587 net.cpp:612] fc6 <- pool5
I1226 07:02:47.811105 51587 net.cpp:586] fc6 -> fc6
I1226 07:02:47.818888 89170 net.cpp:228] Setting up conv5
I1226 07:02:47.819005 89170 net.cpp:235] Top shape: 64 256 13 13 (2768896)
I1226 07:02:47.819036 89170 net.cpp:243] Memory required for data: 512450048
I1226 07:02:47.819598 89170 layer_factory.hpp:114] Creating layer relu5
I1226 07:02:47.819779 89170 net.cpp:178] Creating Layer relu5
I1226 07:02:47.819860 89170 net.cpp:612] relu5 <- conv5
I1226 07:02:47.819916 89170 net.cpp:573] relu5 -> conv5 (in-place)
I1226 07:02:47.820093 89170 net.cpp:228] Setting up relu5
I1226 07:02:47.820381 89170 net.cpp:235] Top shape: 64 256 13 13 (2768896)
I1226 07:02:47.820432 89170 net.cpp:243] Memory required for data: 523525632
I1226 07:02:47.820466 89170 layer_factory.hpp:114] Creating layer pool5
I1226 07:02:47.820830 89170 net.cpp:178] Creating Layer pool5
I1226 07:02:47.820897 89170 net.cpp:612] pool5 <- conv5
I1226 07:02:47.820960 89170 net.cpp:586] pool5 -> pool5
I1226 07:02:47.821110 89170 net.cpp:228] Setting up pool5
I1226 07:02:47.821162 89170 net.cpp:235] Top shape: 64 256 6 6 (589824)
I1226 07:02:47.821239 89170 net.cpp:243] Memory required for data: 525884928
I1226 07:02:47.821275 89170 layer_factory.hpp:114] Creating layer fc6
I1226 07:02:47.821382 89170 net.cpp:178] Creating Layer fc6
I1226 07:02:47.821419 89170 net.cpp:612] fc6 <- pool5
I1226 07:02:47.821480 89170 net.cpp:586] fc6 -> fc6
I1226 07:02:47.825363 89377 net.cpp:228] Setting up conv5
I1226 07:02:47.825479 89377 net.cpp:235] Top shape: 64 256 13 13 (2768896)
I1226 07:02:47.825511 89377 net.cpp:243] Memory required for data: 512450048
I1226 07:02:47.825588 89377 layer_factory.hpp:114] Creating layer relu5
I1226 07:02:47.825682 89377 net.cpp:178] Creating Layer relu5
I1226 07:02:47.825731 89377 net.cpp:612] relu5 <- conv5
I1226 07:02:47.825783 89377 net.cpp:573] relu5 -> conv5 (in-place)
I1226 07:02:47.825963 89377 net.cpp:228] Setting up relu5
I1226 07:02:47.826174 89377 net.cpp:235] Top shape: 64 256 13 13 (2768896)
I1226 07:02:47.826212 89377 net.cpp:243] Memory required for data: 523525632
I1226 07:02:47.826247 89377 layer_factory.hpp:114] Creating layer pool5
I1226 07:02:47.826326 89377 net.cpp:178] Creating Layer pool5
I1226 07:02:47.826377 89377 net.cpp:612] pool5 <- conv5
I1226 07:02:47.826452 89377 net.cpp:586] pool5 -> pool5
I1226 07:02:47.827164 89377 net.cpp:228] Setting up pool5
I1226 07:02:47.827316 89377 net.cpp:235] Top shape: 64 256 6 6 (589824)
I1226 07:02:47.827419 89377 net.cpp:243] Memory required for data: 525884928
I1226 07:02:47.827462 89377 layer_factory.hpp:114] Creating layer fc6
I1226 07:02:47.827599 89377 net.cpp:178] Creating Layer fc6
I1226 07:02:47.827651 89377 net.cpp:612] fc6 <- pool5
I1226 07:02:47.827700 89377 net.cpp:586] fc6 -> fc6
I1226 07:02:48.419587 93507 net.cpp:228] Setting up conv2
I1226 07:02:48.421298 93507 net.cpp:235] Top shape: 64 256 27 27 (11943936)
I1226 07:02:48.421367 93507 net.cpp:243] Memory required for data: 328293888
I1226 07:02:48.421489 93507 layer_factory.hpp:114] Creating layer relu2
I1226 07:02:48.421622 93507 net.cpp:178] Creating Layer relu2
I1226 07:02:48.421736 93507 net.cpp:612] relu2 <- conv2
I1226 07:02:48.421782 93507 net.cpp:573] relu2 -> conv2 (in-place)
I1226 07:02:48.421916 93507 net.cpp:228] Setting up relu2
I1226 07:02:48.421970 93507 net.cpp:235] Top shape: 64 256 27 27 (11943936)
I1226 07:02:48.421998 93507 net.cpp:243] Memory required for data: 376069632
I1226 07:02:48.422041 93507 layer_factory.hpp:114] Creating layer norm2
I1226 07:02:48.422108 93507 net.cpp:178] Creating Layer norm2
I1226 07:02:48.422147 93507 net.cpp:612] norm2 <- conv2
I1226 07:02:48.422188 93507 net.cpp:586] norm2 -> norm2
I1226 07:02:48.422289 93507 net.cpp:228] Setting up norm2
I1226 07:02:48.422343 93507 net.cpp:235] Top shape: 64 256 27 27 (11943936)
I1226 07:02:48.422369 93507 net.cpp:243] Memory required for data: 423845376
I1226 07:02:48.422399 93507 layer_factory.hpp:114] Creating layer pool2
I1226 07:02:48.422456 93507 net.cpp:178] Creating Layer pool2
I1226 07:02:48.422492 93507 net.cpp:612] pool2 <- norm2
I1226 07:02:48.422529 93507 net.cpp:586] pool2 -> pool2
I1226 07:02:48.422610 93507 net.cpp:228] Setting up pool2
I1226 07:02:48.422655 93507 net.cpp:235] Top shape: 64 256 13 13 (2768896)
I1226 07:02:48.422780 93507 net.cpp:243] Memory required for data: 434920960
I1226 07:02:48.422842 93507 layer_factory.hpp:114] Creating layer conv3
I1226 07:02:48.422937 93507 net.cpp:178] Creating Layer conv3
I1226 07:02:48.422976 93507 net.cpp:612] conv3 <- pool2
I1226 07:02:48.423022 93507 net.cpp:586] conv3 -> conv3
I1226 07:02:49.713770 93507 net.cpp:228] Setting up conv3
I1226 07:02:49.713906 93507 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:49.713935 93507 net.cpp:243] Memory required for data: 451534336
I1226 07:02:49.714032 93507 layer_factory.hpp:114] Creating layer relu3
I1226 07:02:49.714187 93507 net.cpp:178] Creating Layer relu3
I1226 07:02:49.714231 93507 net.cpp:612] relu3 <- conv3
I1226 07:02:49.714278 93507 net.cpp:573] relu3 -> conv3 (in-place)
I1226 07:02:49.714382 93507 net.cpp:228] Setting up relu3
I1226 07:02:49.714431 93507 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:49.714457 93507 net.cpp:243] Memory required for data: 468147712
I1226 07:02:49.714488 93507 layer_factory.hpp:114] Creating layer conv4
I1226 07:02:49.714586 93507 net.cpp:178] Creating Layer conv4
I1226 07:02:49.714627 93507 net.cpp:612] conv4 <- conv3
I1226 07:02:49.714670 93507 net.cpp:586] conv4 -> conv4
I1226 07:02:50.589476 93507 net.cpp:228] Setting up conv4
I1226 07:02:50.589604 93507 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:50.589635 93507 net.cpp:243] Memory required for data: 484761088
I1226 07:02:50.589700 93507 layer_factory.hpp:114] Creating layer relu4
I1226 07:02:50.589772 93507 net.cpp:178] Creating Layer relu4
I1226 07:02:50.589833 93507 net.cpp:612] relu4 <- conv4
I1226 07:02:50.589895 93507 net.cpp:573] relu4 -> conv4 (in-place)
I1226 07:02:50.590014 93507 net.cpp:228] Setting up relu4
I1226 07:02:50.590068 93507 net.cpp:235] Top shape: 64 384 13 13 (4153344)
I1226 07:02:50.590093 93507 net.cpp:243] Memory required for data: 501374464
I1226 07:02:50.590126 93507 layer_factory.hpp:114] Creating layer conv5
I1226 07:02:50.590216 93507 net.cpp:178] Creating Layer conv5
I1226 07:02:50.590256 93507 net.cpp:612] conv5 <- conv4
I1226 07:02:50.590309 93507 net.cpp:586] conv5 -> conv5
I1226 07:02:51.217679 93507 net.cpp:228] Setting up conv5
I1226 07:02:51.217828 93507 net.cpp:235] Top shape: 64 256 13 13 (2768896)
I1226 07:02:51.217865 93507 net.cpp:243] Memory required for data: 512450048
I1226 07:02:51.217948 93507 layer_factory.hpp:114] Creating layer relu5
I1226 07:02:51.218112 93507 net.cpp:178] Creating Layer relu5
I1226 07:02:51.218163 93507 net.cpp:612] relu5 <- conv5
I1226 07:02:51.218209 93507 net.cpp:573] relu5 -> conv5 (in-place)
I1226 07:02:51.218317 93507 net.cpp:228] Setting up relu5
I1226 07:02:51.218369 93507 net.cpp:235] Top shape: 64 256 13 13 (2768896)
I1226 07:02:51.218397 93507 net.cpp:243] Memory required for data: 523525632
I1226 07:02:51.218439 93507 layer_factory.hpp:114] Creating layer pool5
I1226 07:02:51.218513 93507 net.cpp:178] Creating Layer pool5
I1226 07:02:51.218550 93507 net.cpp:612] pool5 <- conv5
I1226 07:02:51.218600 93507 net.cpp:586] pool5 -> pool5
I1226 07:02:51.218701 93507 net.cpp:228] Setting up pool5
I1226 07:02:51.218753 93507 net.cpp:235] Top shape: 64 256 6 6 (589824)
I1226 07:02:51.218780 93507 net.cpp:243] Memory required for data: 525884928
I1226 07:02:51.218834 93507 layer_factory.hpp:114] Creating layer fc6
I1226 07:02:51.218924 93507 net.cpp:178] Creating Layer fc6
I1226 07:02:51.218961 93507 net.cpp:612] fc6 <- pool5
I1226 07:02:51.219020 93507 net.cpp:586] fc6 -> fc6
I1226 07:02:52.158545 96083 net.cpp:228] Setting up fc6
I1226 07:02:52.158663 96083 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:52.158692 96083 net.cpp:243] Memory required for data: 526933504
I1226 07:02:52.158751 96083 layer_factory.hpp:114] Creating layer relu6
I1226 07:02:52.158850 96083 net.cpp:178] Creating Layer relu6
I1226 07:02:52.158954 96083 net.cpp:612] relu6 <- fc6
I1226 07:02:52.158993 96083 net.cpp:573] relu6 -> fc6 (in-place)
I1226 07:02:52.159106 96083 net.cpp:228] Setting up relu6
I1226 07:02:52.159159 96083 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:52.159298 96083 net.cpp:243] Memory required for data: 527982080
I1226 07:02:52.159342 96083 layer_factory.hpp:114] Creating layer drop6
I1226 07:02:52.159412 96083 net.cpp:178] Creating Layer drop6
I1226 07:02:52.159451 96083 net.cpp:612] drop6 <- fc6
I1226 07:02:52.159487 96083 net.cpp:573] drop6 -> fc6 (in-place)
I1226 07:02:52.159545 96083 net.cpp:228] Setting up drop6
I1226 07:02:52.159584 96083 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:52.159616 96083 net.cpp:243] Memory required for data: 529030656
I1226 07:02:52.159646 96083 layer_factory.hpp:114] Creating layer fc7
I1226 07:02:52.159703 96083 net.cpp:178] Creating Layer fc7
I1226 07:02:52.159736 96083 net.cpp:612] fc7 <- fc6
I1226 07:02:52.159790 96083 net.cpp:586] fc7 -> fc7
I1226 07:02:53.397941 89377 net.cpp:228] Setting up fc6
I1226 07:02:53.398080 89377 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:53.398109 89377 net.cpp:243] Memory required for data: 526933504
I1226 07:02:53.398192 89377 layer_factory.hpp:114] Creating layer relu6
I1226 07:02:53.398289 89377 net.cpp:178] Creating Layer relu6
I1226 07:02:53.398334 89377 net.cpp:612] relu6 <- fc6
I1226 07:02:53.398373 89377 net.cpp:573] relu6 -> fc6 (in-place)
I1226 07:02:53.398576 89377 net.cpp:228] Setting up relu6
I1226 07:02:53.398720 89377 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:53.398751 89377 net.cpp:243] Memory required for data: 527982080
I1226 07:02:53.398782 89377 layer_factory.hpp:114] Creating layer drop6
I1226 07:02:53.398872 89377 net.cpp:178] Creating Layer drop6
I1226 07:02:53.398998 89377 net.cpp:612] drop6 <- fc6
I1226 07:02:53.399056 89377 net.cpp:573] drop6 -> fc6 (in-place)
I1226 07:02:53.399111 89377 net.cpp:228] Setting up drop6
I1226 07:02:53.399148 89377 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:53.399171 89377 net.cpp:243] Memory required for data: 529030656
I1226 07:02:53.399199 89377 layer_factory.hpp:114] Creating layer fc7
I1226 07:02:53.399263 89377 net.cpp:178] Creating Layer fc7
I1226 07:02:53.399296 89377 net.cpp:612] fc7 <- fc6
I1226 07:02:53.399333 89377 net.cpp:586] fc7 -> fc7
I1226 07:02:53.420733 89165 net.cpp:228] Setting up fc6
I1226 07:02:53.419478 88126 net.cpp:228] Setting up fc6
I1226 07:02:53.420850 89165 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:53.420877 89165 net.cpp:243] Memory required for data: 526933504
I1226 07:02:53.419616 88126 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:53.419651 88126 net.cpp:243] Memory required for data: 526933504
I1226 07:02:53.420963 89165 layer_factory.hpp:114] Creating layer relu6
I1226 07:02:53.419710 88126 layer_factory.hpp:114] Creating layer relu6
I1226 07:02:53.421041 89165 net.cpp:178] Creating Layer relu6
I1226 07:02:53.419792 88126 net.cpp:178] Creating Layer relu6
I1226 07:02:53.421083 89165 net.cpp:612] relu6 <- fc6
I1226 07:02:53.419826 88126 net.cpp:612] relu6 <- fc6
I1226 07:02:53.421129 89165 net.cpp:573] relu6 -> fc6 (in-place)
I1226 07:02:53.419878 88126 net.cpp:573] relu6 -> fc6 (in-place)
I1226 07:02:53.421216 89165 net.cpp:228] Setting up relu6
I1226 07:02:53.419978 88126 net.cpp:228] Setting up relu6
I1226 07:02:53.421397 89165 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:53.421429 89165 net.cpp:243] Memory required for data: 527982080
I1226 07:02:53.420130 88126 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:53.420161 88126 net.cpp:243] Memory required for data: 527982080
I1226 07:02:53.421461 89165 layer_factory.hpp:114] Creating layer drop6
I1226 07:02:53.420192 88126 layer_factory.hpp:114] Creating layer drop6
I1226 07:02:53.421541 89165 net.cpp:178] Creating Layer drop6
I1226 07:02:53.420271 88126 net.cpp:178] Creating Layer drop6
I1226 07:02:53.421581 89165 net.cpp:612] drop6 <- fc6
I1226 07:02:53.420302 88126 net.cpp:612] drop6 <- fc6
I1226 07:02:53.421627 89165 net.cpp:573] drop6 -> fc6 (in-place)
I1226 07:02:53.421679 89165 net.cpp:228] Setting up drop6
I1226 07:02:53.420341 88126 net.cpp:573] drop6 -> fc6 (in-place)
I1226 07:02:53.421715 89165 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:53.420405 88126 net.cpp:228] Setting up drop6
I1226 07:02:53.421743 89165 net.cpp:243] Memory required for data: 529030656
I1226 07:02:53.421772 89165 layer_factory.hpp:114] Creating layer fc7
I1226 07:02:53.420445 88126 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:53.420469 88126 net.cpp:243] Memory required for data: 529030656
I1226 07:02:53.421829 89165 net.cpp:178] Creating Layer fc7
I1226 07:02:53.420495 88126 layer_factory.hpp:114] Creating layer fc7
I1226 07:02:53.420550 88126 net.cpp:178] Creating Layer fc7
I1226 07:02:53.421862 89165 net.cpp:612] fc7 <- fc6
I1226 07:02:53.421900 89165 net.cpp:586] fc7 -> fc7
I1226 07:02:53.420606 88126 net.cpp:612] fc7 <- fc6
I1226 07:02:53.420649 88126 net.cpp:586] fc7 -> fc7
I1226 07:02:53.439318 89170 net.cpp:228] Setting up fc6
I1226 07:02:53.439435 89170 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:53.439467 89170 net.cpp:243] Memory required for data: 526933504
I1226 07:02:53.439525 89170 layer_factory.hpp:114] Creating layer relu6
I1226 07:02:53.439618 89170 net.cpp:178] Creating Layer relu6
I1226 07:02:53.439736 89170 net.cpp:612] relu6 <- fc6
I1226 07:02:53.439777 89170 net.cpp:573] relu6 -> fc6 (in-place)
I1226 07:02:53.439865 89170 net.cpp:228] Setting up relu6
I1226 07:02:53.440017 89170 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:53.440048 89170 net.cpp:243] Memory required for data: 527982080
I1226 07:02:53.440083 89170 layer_factory.hpp:114] Creating layer drop6
I1226 07:02:53.440145 89170 net.cpp:178] Creating Layer drop6
I1226 07:02:53.440173 89170 net.cpp:612] drop6 <- fc6
I1226 07:02:53.440249 89170 net.cpp:573] drop6 -> fc6 (in-place)
I1226 07:02:53.440322 89170 net.cpp:228] Setting up drop6
I1226 07:02:53.440361 89170 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:53.440387 89170 net.cpp:243] Memory required for data: 529030656
I1226 07:02:53.440415 89170 layer_factory.hpp:114] Creating layer fc7
I1226 07:02:53.440474 89170 net.cpp:178] Creating Layer fc7
I1226 07:02:53.440502 89170 net.cpp:612] fc7 <- fc6
I1226 07:02:53.440554 89170 net.cpp:586] fc7 -> fc7
I1226 07:02:53.459617 51587 net.cpp:228] Setting up fc6
I1226 07:02:53.459728 51587 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:53.459755 51587 net.cpp:243] Memory required for data: 526933504
I1226 07:02:53.459836 51587 layer_factory.hpp:114] Creating layer relu6
I1226 07:02:53.459933 51587 net.cpp:178] Creating Layer relu6
I1226 07:02:53.459978 51587 net.cpp:612] relu6 <- fc6
I1226 07:02:53.460016 51587 net.cpp:573] relu6 -> fc6 (in-place)
I1226 07:02:53.460101 51587 net.cpp:228] Setting up relu6
I1226 07:02:53.460281 51587 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:53.460312 51587 net.cpp:243] Memory required for data: 527982080
I1226 07:02:53.460345 51587 layer_factory.hpp:114] Creating layer drop6
I1226 07:02:53.460398 51587 net.cpp:178] Creating Layer drop6
I1226 07:02:53.460427 51587 net.cpp:612] drop6 <- fc6
I1226 07:02:53.460486 51587 net.cpp:573] drop6 -> fc6 (in-place)
I1226 07:02:53.460561 51587 net.cpp:228] Setting up drop6
I1226 07:02:53.460604 51587 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:53.460628 51587 net.cpp:243] Memory required for data: 529030656
I1226 07:02:53.460654 51587 layer_factory.hpp:114] Creating layer fc7
I1226 07:02:53.460712 51587 net.cpp:178] Creating Layer fc7
I1226 07:02:53.460746 51587 net.cpp:612] fc7 <- fc6
I1226 07:02:53.460784 51587 net.cpp:586] fc7 -> fc7
I1226 07:02:53.463619 90546 net.cpp:228] Setting up fc6
I1226 07:02:53.463729 90546 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:53.463758 90546 net.cpp:243] Memory required for data: 526933504
I1226 07:02:53.463819 90546 layer_factory.hpp:114] Creating layer relu6
I1226 07:02:53.463894 90546 net.cpp:178] Creating Layer relu6
I1226 07:02:53.463935 90546 net.cpp:612] relu6 <- fc6
I1226 07:02:53.463980 90546 net.cpp:573] relu6 -> fc6 (in-place)
I1226 07:02:53.464082 90546 net.cpp:228] Setting up relu6
I1226 07:02:53.464272 90546 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:53.464308 90546 net.cpp:243] Memory required for data: 527982080
I1226 07:02:53.464344 90546 layer_factory.hpp:114] Creating layer drop6
I1226 07:02:53.464422 90546 net.cpp:178] Creating Layer drop6
I1226 07:02:53.464462 90546 net.cpp:612] drop6 <- fc6
I1226 07:02:53.464504 90546 net.cpp:573] drop6 -> fc6 (in-place)
I1226 07:02:53.464565 90546 net.cpp:228] Setting up drop6
I1226 07:02:53.464603 90546 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:53.464627 90546 net.cpp:243] Memory required for data: 529030656
I1226 07:02:53.464655 90546 layer_factory.hpp:114] Creating layer fc7
I1226 07:02:53.464716 90546 net.cpp:178] Creating Layer fc7
I1226 07:02:53.464745 90546 net.cpp:612] fc7 <- fc6
I1226 07:02:53.464782 90546 net.cpp:586] fc7 -> fc7
I1226 07:02:53.522908 89451 net.cpp:228] Setting up fc6
I1226 07:02:53.523022 89451 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:53.523053 89451 net.cpp:243] Memory required for data: 526933504
I1226 07:02:53.523110 89451 layer_factory.hpp:114] Creating layer relu6
I1226 07:02:53.523272 89451 net.cpp:178] Creating Layer relu6
I1226 07:02:53.523306 89451 net.cpp:612] relu6 <- fc6
I1226 07:02:53.523360 89451 net.cpp:573] relu6 -> fc6 (in-place)
I1226 07:02:53.523449 89451 net.cpp:228] Setting up relu6
I1226 07:02:53.523617 89451 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:53.523643 89451 net.cpp:243] Memory required for data: 527982080
I1226 07:02:53.523674 89451 layer_factory.hpp:114] Creating layer drop6
I1226 07:02:53.523737 89451 net.cpp:178] Creating Layer drop6
I1226 07:02:53.523766 89451 net.cpp:612] drop6 <- fc6
I1226 07:02:53.523802 89451 net.cpp:573] drop6 -> fc6 (in-place)
I1226 07:02:53.523862 89451 net.cpp:228] Setting up drop6
I1226 07:02:53.523910 89451 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:53.523934 89451 net.cpp:243] Memory required for data: 529030656
I1226 07:02:53.523962 89451 layer_factory.hpp:114] Creating layer fc7
I1226 07:02:53.524026 89451 net.cpp:178] Creating Layer fc7
I1226 07:02:53.524057 89451 net.cpp:612] fc7 <- fc6
I1226 07:02:53.524093 89451 net.cpp:586] fc7 -> fc7
I1226 07:02:54.445690 96083 net.cpp:228] Setting up fc7
I1226 07:02:54.445806 96083 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:54.445837 96083 net.cpp:243] Memory required for data: 530079232
I1226 07:02:54.445899 96083 layer_factory.hpp:114] Creating layer relu7
I1226 07:02:54.445986 96083 net.cpp:178] Creating Layer relu7
I1226 07:02:54.446135 96083 net.cpp:612] relu7 <- fc7
I1226 07:02:54.446197 96083 net.cpp:573] relu7 -> fc7 (in-place)
I1226 07:02:54.446290 96083 net.cpp:228] Setting up relu7
I1226 07:02:54.446338 96083 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:54.446372 96083 net.cpp:243] Memory required for data: 531127808
I1226 07:02:54.446409 96083 layer_factory.hpp:114] Creating layer drop7
I1226 07:02:54.446452 96083 net.cpp:178] Creating Layer drop7
I1226 07:02:54.446488 96083 net.cpp:612] drop7 <- fc7
I1226 07:02:54.446523 96083 net.cpp:573] drop7 -> fc7 (in-place)
I1226 07:02:54.446569 96083 net.cpp:228] Setting up drop7
I1226 07:02:54.446605 96083 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:54.446638 96083 net.cpp:243] Memory required for data: 532176384
I1226 07:02:54.446667 96083 layer_factory.hpp:114] Creating layer fc8
I1226 07:02:54.446744 96083 net.cpp:178] Creating Layer fc8
I1226 07:02:54.446774 96083 net.cpp:612] fc8 <- fc7
I1226 07:02:54.446811 96083 net.cpp:586] fc8 -> fc8
I1226 07:02:55.005148 96083 net.cpp:228] Setting up fc8
I1226 07:02:55.005260 96083 net.cpp:235] Top shape: 64 1000 (64000)
I1226 07:02:55.005287 96083 net.cpp:243] Memory required for data: 532432384
I1226 07:02:55.005369 96083 layer_factory.hpp:114] Creating layer fc8_fc8_0_split
I1226 07:02:55.005465 96083 net.cpp:178] Creating Layer fc8_fc8_0_split
I1226 07:02:55.005509 96083 net.cpp:612] fc8_fc8_0_split <- fc8
I1226 07:02:55.005559 96083 net.cpp:586] fc8_fc8_0_split -> fc8_fc8_0_split_0
I1226 07:02:55.005611 96083 net.cpp:586] fc8_fc8_0_split -> fc8_fc8_0_split_1
I1226 07:02:55.005769 96083 net.cpp:228] Setting up fc8_fc8_0_split
I1226 07:02:55.005823 96083 net.cpp:235] Top shape: 64 1000 (64000)
I1226 07:02:55.005859 96083 net.cpp:235] Top shape: 64 1000 (64000)
I1226 07:02:55.005882 96083 net.cpp:243] Memory required for data: 532944384
I1226 07:02:55.005913 96083 layer_factory.hpp:114] Creating layer accuracy
I1226 07:02:55.005980 96083 net.cpp:178] Creating Layer accuracy
I1226 07:02:55.006013 96083 net.cpp:612] accuracy <- fc8_fc8_0_split_0
I1226 07:02:55.006045 96083 net.cpp:612] accuracy <- label_data_1_split_0
I1226 07:02:55.006114 96083 net.cpp:586] accuracy -> accuracy
I1226 07:02:55.006170 96083 net.cpp:228] Setting up accuracy
I1226 07:02:55.006206 96083 net.cpp:235] Top shape: (1)
I1226 07:02:55.006235 96083 net.cpp:243] Memory required for data: 532944388
I1226 07:02:55.006263 96083 layer_factory.hpp:114] Creating layer loss
I1226 07:02:55.006309 96083 net.cpp:178] Creating Layer loss
I1226 07:02:55.006337 96083 net.cpp:612] loss <- fc8_fc8_0_split_1
I1226 07:02:55.006366 96083 net.cpp:612] loss <- label_data_1_split_1
I1226 07:02:55.006398 96083 net.cpp:586] loss -> loss
I1226 07:02:55.006518 96083 layer_factory.hpp:114] Creating layer loss
I1226 07:02:55.035747 96083 net.cpp:228] Setting up loss
I1226 07:02:55.035858 96083 net.cpp:235] Top shape: (1)
I1226 07:02:55.035892 96083 net.cpp:238]     with loss weight 1
I1226 07:02:55.036162 96083 net.cpp:243] Memory required for data: 532944392
I1226 07:02:55.036216 96083 net.cpp:305] loss needs backward computation.
I1226 07:02:55.036257 96083 net.cpp:307] accuracy does not need backward computation.
I1226 07:02:55.036453 96083 net.cpp:305] fc8_fc8_0_split needs backward computation.
I1226 07:02:55.036486 96083 net.cpp:305] fc8 needs backward computation.
I1226 07:02:55.036520 96083 net.cpp:305] drop7 needs backward computation.
I1226 07:02:55.036550 96083 net.cpp:305] relu7 needs backward computation.
I1226 07:02:55.036581 96083 net.cpp:305] fc7 needs backward computation.
I1226 07:02:55.036612 96083 net.cpp:305] drop6 needs backward computation.
I1226 07:02:55.036640 96083 net.cpp:305] relu6 needs backward computation.
I1226 07:02:55.036676 96083 net.cpp:305] fc6 needs backward computation.
I1226 07:02:55.036707 96083 net.cpp:305] pool5 needs backward computation.
I1226 07:02:55.036738 96083 net.cpp:305] relu5 needs backward computation.
I1226 07:02:55.036767 96083 net.cpp:305] conv5 needs backward computation.
I1226 07:02:55.036803 96083 net.cpp:305] relu4 needs backward computation.
I1226 07:02:55.036834 96083 net.cpp:305] conv4 needs backward computation.
I1226 07:02:55.036873 96083 net.cpp:305] relu3 needs backward computation.
I1226 07:02:55.036903 96083 net.cpp:305] conv3 needs backward computation.
I1226 07:02:55.036944 96083 net.cpp:305] pool2 needs backward computation.
I1226 07:02:55.036981 96083 net.cpp:305] norm2 needs backward computation.
I1226 07:02:55.037017 96083 net.cpp:305] relu2 needs backward computation.
I1226 07:02:55.037048 96083 net.cpp:305] conv2 needs backward computation.
I1226 07:02:55.037101 96083 net.cpp:305] pool1 needs backward computation.
I1226 07:02:55.037130 96083 net.cpp:305] norm1 needs backward computation.
I1226 07:02:55.037161 96083 net.cpp:305] relu1 needs backward computation.
I1226 07:02:55.037200 96083 net.cpp:305] conv1 needs backward computation.
I1226 07:02:55.037233 96083 net.cpp:307] label_data_1_split does not need backward computation.
I1226 07:02:55.037267 96083 net.cpp:307] data does not need backward computation.
I1226 07:02:55.037302 96083 net.cpp:349] This network produces output accuracy
I1226 07:02:55.037343 96083 net.cpp:349] This network produces output loss
I1226 07:02:55.037453 96083 net.cpp:363] Network initialization done.
I1226 07:02:55.037894 96083 solver.cpp:119] Solver scaffolding done.
I1226 07:02:55.038127 96083 caffe.cpp:212] Finetuning from /export/data1/stanford/hazy/gordon_bell/caffenet_knl/snapshot/caffenet_MN8_B1024/_iter_25000.caffemodel
I1226 07:02:55.672813 89165 net.cpp:228] Setting up fc7
I1226 07:02:55.672926 89165 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:55.672953 89165 net.cpp:243] Memory required for data: 530079232
I1226 07:02:55.673038 89165 layer_factory.hpp:114] Creating layer relu7
I1226 07:02:55.673130 89165 net.cpp:178] Creating Layer relu7
I1226 07:02:55.673172 89165 net.cpp:612] relu7 <- fc7
I1226 07:02:55.673213 89165 net.cpp:573] relu7 -> fc7 (in-place)
I1226 07:02:55.673334 89165 net.cpp:228] Setting up relu7
I1226 07:02:55.674121 89165 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:55.674175 89165 net.cpp:243] Memory required for data: 531127808
I1226 07:02:55.674209 89165 layer_factory.hpp:114] Creating layer drop7
I1226 07:02:55.674305 89165 net.cpp:178] Creating Layer drop7
I1226 07:02:55.674342 89165 net.cpp:612] drop7 <- fc7
I1226 07:02:55.674401 89165 net.cpp:573] drop7 -> fc7 (in-place)
I1226 07:02:55.674458 89165 net.cpp:228] Setting up drop7
I1226 07:02:55.674494 89165 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:55.674517 89165 net.cpp:243] Memory required for data: 532176384
I1226 07:02:55.674545 89165 layer_factory.hpp:114] Creating layer fc8
I1226 07:02:55.674617 89165 net.cpp:178] Creating Layer fc8
I1226 07:02:55.674651 89165 net.cpp:612] fc8 <- fc7
I1226 07:02:55.674690 89165 net.cpp:586] fc8 -> fc8
I1226 07:02:55.671217 89377 net.cpp:228] Setting up fc7
I1226 07:02:55.671329 89377 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:55.671358 89377 net.cpp:243] Memory required for data: 530079232
I1226 07:02:55.671413 89377 layer_factory.hpp:114] Creating layer relu7
I1226 07:02:55.671504 89377 net.cpp:178] Creating Layer relu7
I1226 07:02:55.671607 89377 net.cpp:612] relu7 <- fc7
I1226 07:02:55.671653 89377 net.cpp:573] relu7 -> fc7 (in-place)
I1226 07:02:55.671731 89377 net.cpp:228] Setting up relu7
I1226 07:02:55.671782 89377 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:55.671805 89377 net.cpp:243] Memory required for data: 531127808
I1226 07:02:55.671864 89377 layer_factory.hpp:114] Creating layer drop7
I1226 07:02:55.671905 89377 net.cpp:178] Creating Layer drop7
I1226 07:02:55.671931 89377 net.cpp:612] drop7 <- fc7
I1226 07:02:55.671964 89377 net.cpp:573] drop7 -> fc7 (in-place)
I1226 07:02:55.672008 89377 net.cpp:228] Setting up drop7
I1226 07:02:55.672049 89377 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:55.672072 89377 net.cpp:243] Memory required for data: 532176384
I1226 07:02:55.672099 89377 layer_factory.hpp:114] Creating layer fc8
I1226 07:02:55.672175 89377 net.cpp:178] Creating Layer fc8
I1226 07:02:55.672209 89377 net.cpp:612] fc8 <- fc7
I1226 07:02:55.672246 89377 net.cpp:586] fc8 -> fc8
I1226 07:02:55.703090 88126 net.cpp:228] Setting up fc7
I1226 07:02:55.703210 88126 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:55.703243 88126 net.cpp:243] Memory required for data: 530079232
I1226 07:02:55.703299 88126 layer_factory.hpp:114] Creating layer relu7
I1226 07:02:55.703402 88126 net.cpp:178] Creating Layer relu7
I1226 07:02:55.703451 88126 net.cpp:612] relu7 <- fc7
I1226 07:02:55.703495 88126 net.cpp:573] relu7 -> fc7 (in-place)
I1226 07:02:55.703608 88126 net.cpp:228] Setting up relu7
I1226 07:02:55.703662 88126 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:55.703686 88126 net.cpp:243] Memory required for data: 531127808
I1226 07:02:55.703716 88126 layer_factory.hpp:114] Creating layer drop7
I1226 07:02:55.703763 88126 net.cpp:178] Creating Layer drop7
I1226 07:02:55.703794 88126 net.cpp:612] drop7 <- fc7
I1226 07:02:55.703841 88126 net.cpp:573] drop7 -> fc7 (in-place)
I1226 07:02:55.703896 88126 net.cpp:228] Setting up drop7
I1226 07:02:55.703935 88126 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:55.703958 88126 net.cpp:243] Memory required for data: 532176384
I1226 07:02:55.703984 88126 layer_factory.hpp:114] Creating layer fc8
I1226 07:02:55.704040 88126 net.cpp:178] Creating Layer fc8
I1226 07:02:55.704072 88126 net.cpp:612] fc8 <- fc7
I1226 07:02:55.704110 88126 net.cpp:586] fc8 -> fc8
I1226 07:02:55.730502 89170 net.cpp:228] Setting up fc7
I1226 07:02:55.730614 89170 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:55.730639 89170 net.cpp:243] Memory required for data: 530079232
I1226 07:02:55.730718 89170 layer_factory.hpp:114] Creating layer relu7
I1226 07:02:55.730808 89170 net.cpp:178] Creating Layer relu7
I1226 07:02:55.730854 89170 net.cpp:612] relu7 <- fc7
I1226 07:02:55.730892 89170 net.cpp:573] relu7 -> fc7 (in-place)
I1226 07:02:55.730974 89170 net.cpp:228] Setting up relu7
I1226 07:02:55.731020 89170 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:55.731045 89170 net.cpp:243] Memory required for data: 531127808
I1226 07:02:55.731073 89170 layer_factory.hpp:114] Creating layer drop7
I1226 07:02:55.731109 89170 net.cpp:178] Creating Layer drop7
I1226 07:02:55.731143 89170 net.cpp:612] drop7 <- fc7
I1226 07:02:55.731176 89170 net.cpp:573] drop7 -> fc7 (in-place)
I1226 07:02:55.731259 89170 net.cpp:228] Setting up drop7
I1226 07:02:55.731298 89170 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:55.731322 89170 net.cpp:243] Memory required for data: 532176384
I1226 07:02:55.731361 89170 layer_factory.hpp:114] Creating layer fc8
I1226 07:02:55.731436 89170 net.cpp:178] Creating Layer fc8
I1226 07:02:55.731465 89170 net.cpp:612] fc8 <- fc7
I1226 07:02:55.731503 89170 net.cpp:586] fc8 -> fc8
I1226 07:02:55.752019 90546 net.cpp:228] Setting up fc7
I1226 07:02:55.752130 90546 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:55.752159 90546 net.cpp:243] Memory required for data: 530079232
I1226 07:02:55.752238 90546 layer_factory.hpp:114] Creating layer relu7
I1226 07:02:55.752327 90546 net.cpp:178] Creating Layer relu7
I1226 07:02:55.752370 90546 net.cpp:612] relu7 <- fc7
I1226 07:02:55.752416 90546 net.cpp:573] relu7 -> fc7 (in-place)
I1226 07:02:55.752516 90546 net.cpp:228] Setting up relu7
I1226 07:02:55.752562 90546 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:55.752588 90546 net.cpp:243] Memory required for data: 531127808
I1226 07:02:55.752617 90546 layer_factory.hpp:114] Creating layer drop7
I1226 07:02:55.752657 90546 net.cpp:178] Creating Layer drop7
I1226 07:02:55.752688 90546 net.cpp:612] drop7 <- fc7
I1226 07:02:55.752742 90546 net.cpp:573] drop7 -> fc7 (in-place)
I1226 07:02:55.752804 90546 net.cpp:228] Setting up drop7
I1226 07:02:55.752842 90546 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:55.752866 90546 net.cpp:243] Memory required for data: 532176384
I1226 07:02:55.752893 90546 layer_factory.hpp:114] Creating layer fc8
I1226 07:02:55.752954 90546 net.cpp:178] Creating Layer fc8
I1226 07:02:55.752981 90546 net.cpp:612] fc8 <- fc7
I1226 07:02:55.753020 90546 net.cpp:586] fc8 -> fc8
I1226 07:02:55.762027 51587 net.cpp:228] Setting up fc7
I1226 07:02:55.762161 51587 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:55.762192 51587 net.cpp:243] Memory required for data: 530079232
I1226 07:02:55.762249 51587 layer_factory.hpp:114] Creating layer relu7
I1226 07:02:55.762346 51587 net.cpp:178] Creating Layer relu7
I1226 07:02:55.762390 51587 net.cpp:612] relu7 <- fc7
I1226 07:02:55.762429 51587 net.cpp:573] relu7 -> fc7 (in-place)
I1226 07:02:55.762516 51587 net.cpp:228] Setting up relu7
I1226 07:02:55.762588 51587 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:55.762612 51587 net.cpp:243] Memory required for data: 531127808
I1226 07:02:55.762640 51587 layer_factory.hpp:114] Creating layer drop7
I1226 07:02:55.762683 51587 net.cpp:178] Creating Layer drop7
I1226 07:02:55.762709 51587 net.cpp:612] drop7 <- fc7
I1226 07:02:55.762742 51587 net.cpp:573] drop7 -> fc7 (in-place)
I1226 07:02:55.762786 51587 net.cpp:228] Setting up drop7
I1226 07:02:55.762826 51587 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:55.762850 51587 net.cpp:243] Memory required for data: 532176384
I1226 07:02:55.762876 51587 layer_factory.hpp:114] Creating layer fc8
I1226 07:02:55.762953 51587 net.cpp:178] Creating Layer fc8
I1226 07:02:55.762986 51587 net.cpp:612] fc8 <- fc7
I1226 07:02:55.763023 51587 net.cpp:586] fc8 -> fc8
I1226 07:02:55.790462 89451 net.cpp:228] Setting up fc7
I1226 07:02:55.790596 89451 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:55.790627 89451 net.cpp:243] Memory required for data: 530079232
I1226 07:02:55.790710 89451 layer_factory.hpp:114] Creating layer relu7
I1226 07:02:55.790809 89451 net.cpp:178] Creating Layer relu7
I1226 07:02:55.790854 89451 net.cpp:612] relu7 <- fc7
I1226 07:02:55.790894 89451 net.cpp:573] relu7 -> fc7 (in-place)
I1226 07:02:55.790982 89451 net.cpp:228] Setting up relu7
I1226 07:02:55.791052 89451 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:55.791076 89451 net.cpp:243] Memory required for data: 531127808
I1226 07:02:55.791105 89451 layer_factory.hpp:114] Creating layer drop7
I1226 07:02:55.791152 89451 net.cpp:178] Creating Layer drop7
I1226 07:02:55.791177 89451 net.cpp:612] drop7 <- fc7
I1226 07:02:55.791225 89451 net.cpp:573] drop7 -> fc7 (in-place)
I1226 07:02:55.791272 89451 net.cpp:228] Setting up drop7
I1226 07:02:55.791304 89451 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:02:55.791326 89451 net.cpp:243] Memory required for data: 532176384
I1226 07:02:55.791352 89451 layer_factory.hpp:114] Creating layer fc8
I1226 07:02:55.791409 89451 net.cpp:178] Creating Layer fc8
I1226 07:02:55.791445 89451 net.cpp:612] fc8 <- fc7
I1226 07:02:55.791507 89451 net.cpp:586] fc8 -> fc8
I1226 07:02:56.221218 89377 net.cpp:228] Setting up fc8
I1226 07:02:56.221343 89377 net.cpp:235] Top shape: 64 1000 (64000)
I1226 07:02:56.221372 89377 net.cpp:243] Memory required for data: 532432384
I1226 07:02:56.221427 89377 layer_factory.hpp:114] Creating layer fc8_fc8_0_split
I1226 07:02:56.221499 89377 net.cpp:178] Creating Layer fc8_fc8_0_split
I1226 07:02:56.221532 89377 net.cpp:612] fc8_fc8_0_split <- fc8
I1226 07:02:56.221609 89377 net.cpp:586] fc8_fc8_0_split -> fc8_fc8_0_split_0
I1226 07:02:56.221662 89377 net.cpp:586] fc8_fc8_0_split -> fc8_fc8_0_split_1
I1226 07:02:56.221745 89377 net.cpp:228] Setting up fc8_fc8_0_split
I1226 07:02:56.221793 89377 net.cpp:235] Top shape: 64 1000 (64000)
I1226 07:02:56.221854 89377 net.cpp:235] Top shape: 64 1000 (64000)
I1226 07:02:56.221884 89377 net.cpp:243] Memory required for data: 532944384
I1226 07:02:56.221912 89377 layer_factory.hpp:114] Creating layer accuracy
I1226 07:02:56.221972 89377 net.cpp:178] Creating Layer accuracy
I1226 07:02:56.222007 89377 net.cpp:612] accuracy <- fc8_fc8_0_split_0
I1226 07:02:56.222038 89377 net.cpp:612] accuracy <- label_data_1_split_0
I1226 07:02:56.222074 89377 net.cpp:586] accuracy -> accuracy
I1226 07:02:56.222116 89377 net.cpp:228] Setting up accuracy
I1226 07:02:56.222157 89377 net.cpp:235] Top shape: (1)
I1226 07:02:56.222179 89377 net.cpp:243] Memory required for data: 532944388
I1226 07:02:56.222205 89377 layer_factory.hpp:114] Creating layer loss
I1226 07:02:56.222254 89377 net.cpp:178] Creating Layer loss
I1226 07:02:56.222280 89377 net.cpp:612] loss <- fc8_fc8_0_split_1
I1226 07:02:56.222307 89377 net.cpp:612] loss <- label_data_1_split_1
I1226 07:02:56.222338 89377 net.cpp:586] loss -> loss
I1226 07:02:56.222394 89377 layer_factory.hpp:114] Creating layer loss
I1226 07:02:56.229827 89165 net.cpp:228] Setting up fc8
I1226 07:02:56.229940 89165 net.cpp:235] Top shape: 64 1000 (64000)
I1226 07:02:56.229967 89165 net.cpp:243] Memory required for data: 532432384
I1226 07:02:56.230020 89165 layer_factory.hpp:114] Creating layer fc8_fc8_0_split
I1226 07:02:56.230106 89165 net.cpp:178] Creating Layer fc8_fc8_0_split
I1226 07:02:56.230144 89165 net.cpp:612] fc8_fc8_0_split <- fc8
I1226 07:02:56.230201 89165 net.cpp:586] fc8_fc8_0_split -> fc8_fc8_0_split_0
I1226 07:02:56.230273 89165 net.cpp:586] fc8_fc8_0_split -> fc8_fc8_0_split_1
I1226 07:02:56.230365 89165 net.cpp:228] Setting up fc8_fc8_0_split
I1226 07:02:56.230409 89165 net.cpp:235] Top shape: 64 1000 (64000)
I1226 07:02:56.230439 89165 net.cpp:235] Top shape: 64 1000 (64000)
I1226 07:02:56.230473 89165 net.cpp:243] Memory required for data: 532944384
I1226 07:02:56.230504 89165 layer_factory.hpp:114] Creating layer accuracy
I1226 07:02:56.230572 89165 net.cpp:178] Creating Layer accuracy
I1226 07:02:56.230600 89165 net.cpp:612] accuracy <- fc8_fc8_0_split_0
I1226 07:02:56.230629 89165 net.cpp:612] accuracy <- label_data_1_split_0
I1226 07:02:56.230662 89165 net.cpp:586] accuracy -> accuracy
I1226 07:02:56.230712 89165 net.cpp:228] Setting up accuracy
I1226 07:02:56.230744 89165 net.cpp:235] Top shape: (1)
I1226 07:02:56.230767 89165 net.cpp:243] Memory required for data: 532944388
I1226 07:02:56.230808 89165 layer_factory.hpp:114] Creating layer loss
I1226 07:02:56.230850 89165 net.cpp:178] Creating Layer loss
I1226 07:02:56.230875 89165 net.cpp:612] loss <- fc8_fc8_0_split_1
I1226 07:02:56.230902 89165 net.cpp:612] loss <- label_data_1_split_1
I1226 07:02:56.230939 89165 net.cpp:586] loss -> loss
I1226 07:02:56.230998 89165 layer_factory.hpp:114] Creating layer loss
I1226 07:02:56.253981 88126 net.cpp:228] Setting up fc8
I1226 07:02:56.254098 88126 net.cpp:235] Top shape: 64 1000 (64000)
I1226 07:02:56.254129 88126 net.cpp:243] Memory required for data: 532432384
I1226 07:02:56.254184 88126 layer_factory.hpp:114] Creating layer fc8_fc8_0_split
I1226 07:02:56.254281 88126 net.cpp:178] Creating Layer fc8_fc8_0_split
I1226 07:02:56.254384 88126 net.cpp:612] fc8_fc8_0_split <- fc8
I1226 07:02:56.254437 88126 net.cpp:586] fc8_fc8_0_split -> fc8_fc8_0_split_0
I1226 07:02:56.254489 88126 net.cpp:586] fc8_fc8_0_split -> fc8_fc8_0_split_1
I1226 07:02:56.254608 88126 net.cpp:228] Setting up fc8_fc8_0_split
I1226 07:02:56.254658 88126 net.cpp:235] Top shape: 64 1000 (64000)
I1226 07:02:56.254688 88126 net.cpp:235] Top shape: 64 1000 (64000)
I1226 07:02:56.254724 88126 net.cpp:243] Memory required for data: 532944384
I1226 07:02:56.254755 88126 layer_factory.hpp:114] Creating layer accuracy
I1226 07:02:56.254820 88126 net.cpp:178] Creating Layer accuracy
I1226 07:02:56.254855 88126 net.cpp:612] accuracy <- fc8_fc8_0_split_0
I1226 07:02:56.254887 88126 net.cpp:612] accuracy <- label_data_1_split_0
I1226 07:02:56.254923 88126 net.cpp:586] accuracy -> accuracy
I1226 07:02:56.254974 88126 net.cpp:228] Setting up accuracy
I1226 07:02:56.255007 88126 net.cpp:235] Top shape: (1)
I1226 07:02:56.255028 88126 net.cpp:243] Memory required for data: 532944388
I1226 07:02:56.255054 88126 layer_factory.hpp:114] Creating layer loss
I1226 07:02:56.255100 88126 net.cpp:178] Creating Layer loss
I1226 07:02:56.255131 88126 net.cpp:612] loss <- fc8_fc8_0_split_1
I1226 07:02:56.255159 88126 net.cpp:612] loss <- label_data_1_split_1
I1226 07:02:56.255192 88126 net.cpp:586] loss -> loss
I1226 07:02:56.255249 88126 layer_factory.hpp:114] Creating layer loss
I1226 07:02:56.261711 89165 net.cpp:228] Setting up loss
I1226 07:02:56.261826 89165 net.cpp:235] Top shape: (1)
I1226 07:02:56.261987 89165 net.cpp:238]     with loss weight 1
I1226 07:02:56.262136 89165 net.cpp:243] Memory required for data: 532944392
I1226 07:02:56.262187 89165 net.cpp:305] loss needs backward computation.
I1226 07:02:56.258250 89377 net.cpp:228] Setting up loss
I1226 07:02:56.262233 89165 net.cpp:307] accuracy does not need backward computation.
I1226 07:02:56.262300 89165 net.cpp:305] fc8_fc8_0_split needs backward computation.
I1226 07:02:56.262334 89165 net.cpp:305] fc8 needs backward computation.
I1226 07:02:56.262364 89165 net.cpp:305] drop7 needs backward computation.
I1226 07:02:56.262394 89165 net.cpp:305] relu7 needs backward computation.
I1226 07:02:56.262423 89165 net.cpp:305] fc7 needs backward computation.
I1226 07:02:56.262452 89165 net.cpp:305] drop6 needs backward computation.
I1226 07:02:56.262480 89165 net.cpp:305] relu6 needs backward computation.
I1226 07:02:56.262507 89165 net.cpp:305] fc6 needs backward computation.
I1226 07:02:56.262537 89165 net.cpp:305] pool5 needs backward computation.
I1226 07:02:56.262567 89165 net.cpp:305] relu5 needs backward computation.
I1226 07:02:56.262594 89165 net.cpp:305] conv5 needs backward computation.
I1226 07:02:56.262624 89165 net.cpp:305] relu4 needs backward computation.
I1226 07:02:56.262650 89165 net.cpp:305] conv4 needs backward computation.
I1226 07:02:56.262679 89165 net.cpp:305] relu3 needs backward computation.
I1226 07:02:56.262707 89165 net.cpp:305] conv3 needs backward computation.
I1226 07:02:56.262737 89165 net.cpp:305] pool2 needs backward computation.
I1226 07:02:56.262765 89165 net.cpp:305] norm2 needs backward computation.
I1226 07:02:56.262794 89165 net.cpp:305] relu2 needs backward computation.
I1226 07:02:56.262822 89165 net.cpp:305] conv2 needs backward computation.
I1226 07:02:56.262852 89165 net.cpp:305] pool1 needs backward computation.
I1226 07:02:56.262881 89165 net.cpp:305] norm1 needs backward computation.
I1226 07:02:56.262909 89165 net.cpp:305] relu1 needs backward computation.
I1226 07:02:56.262936 89165 net.cpp:305] conv1 needs backward computation.
I1226 07:02:56.262966 89165 net.cpp:307] label_data_1_split does not need backward computation.
I1226 07:02:56.263000 89165 net.cpp:307] data does not need backward computation.
I1226 07:02:56.263031 89165 net.cpp:349] This network produces output accuracy
I1226 07:02:56.258368 89377 net.cpp:235] Top shape: (1)
I1226 07:02:56.263068 89165 net.cpp:349] This network produces output loss
I1226 07:02:56.258538 89377 net.cpp:238]     with loss weight 1
I1226 07:02:56.258688 89377 net.cpp:243] Memory required for data: 532944392
I1226 07:02:56.263180 89165 net.cpp:363] Network initialization done.
I1226 07:02:56.258736 89377 net.cpp:305] loss needs backward computation.
I1226 07:02:56.258777 89377 net.cpp:307] accuracy does not need backward computation.
I1226 07:02:56.258836 89377 net.cpp:305] fc8_fc8_0_split needs backward computation.
I1226 07:02:56.258875 89377 net.cpp:305] fc8 needs backward computation.
I1226 07:02:56.258908 89377 net.cpp:305] drop7 needs backward computation.
I1226 07:02:56.258941 89377 net.cpp:305] relu7 needs backward computation.
I1226 07:02:56.258970 89377 net.cpp:305] fc7 needs backward computation.
I1226 07:02:56.259001 89377 net.cpp:305] drop6 needs backward computation.
I1226 07:02:56.259030 89377 net.cpp:305] relu6 needs backward computation.
I1226 07:02:56.259060 89377 net.cpp:305] fc6 needs backward computation.
I1226 07:02:56.259105 89377 net.cpp:305] pool5 needs backward computation.
I1226 07:02:56.263720 89165 solver.cpp:119] Solver scaffolding done.
I1226 07:02:56.259140 89377 net.cpp:305] relu5 needs backward computation.
I1226 07:02:56.263954 89165 caffe.cpp:212] Finetuning from /export/data1/stanford/hazy/gordon_bell/caffenet_knl/snapshot/caffenet_MN8_B1024/_iter_25000.caffemodel
I1226 07:02:56.259176 89377 net.cpp:305] conv5 needs backward computation.
I1226 07:02:56.259207 89377 net.cpp:305] relu4 needs backward computation.
I1226 07:02:56.259244 89377 net.cpp:305] conv4 needs backward computation.
I1226 07:02:56.259276 89377 net.cpp:305] relu3 needs backward computation.
I1226 07:02:56.259312 89377 net.cpp:305] conv3 needs backward computation.
I1226 07:02:56.259346 89377 net.cpp:305] pool2 needs backward computation.
I1226 07:02:56.259382 89377 net.cpp:305] norm2 needs backward computation.
I1226 07:02:56.259419 89377 net.cpp:305] relu2 needs backward computation.
I1226 07:02:56.259455 89377 net.cpp:305] conv2 needs backward computation.
I1226 07:02:56.259493 89377 net.cpp:305] pool1 needs backward computation.
I1226 07:02:56.259531 89377 net.cpp:305] norm1 needs backward computation.
I1226 07:02:56.259567 89377 net.cpp:305] relu1 needs backward computation.
I1226 07:02:56.259605 89377 net.cpp:305] conv1 needs backward computation.
I1226 07:02:56.259645 89377 net.cpp:307] label_data_1_split does not need backward computation.
I1226 07:02:56.259683 89377 net.cpp:307] data does not need backward computation.
I1226 07:02:56.259716 89377 net.cpp:349] This network produces output accuracy
I1226 07:02:56.259759 89377 net.cpp:349] This network produces output loss
I1226 07:02:56.259888 89377 net.cpp:363] Network initialization done.
I1226 07:02:56.260332 89377 solver.cpp:119] Solver scaffolding done.
I1226 07:02:56.260551 89377 caffe.cpp:212] Finetuning from /export/data1/stanford/hazy/gordon_bell/caffenet_knl/snapshot/caffenet_MN8_B1024/_iter_25000.caffemodel
I1226 07:02:56.287649 88126 net.cpp:228] Setting up loss
I1226 07:02:56.287766 88126 net.cpp:235] Top shape: (1)
I1226 07:02:56.287936 88126 net.cpp:238]     with loss weight 1
I1226 07:02:56.288094 88126 net.cpp:243] Memory required for data: 532944392
I1226 07:02:56.288141 88126 net.cpp:305] loss needs backward computation.
I1226 07:02:56.288183 88126 net.cpp:307] accuracy does not need backward computation.
I1226 07:02:56.288228 88126 net.cpp:305] fc8_fc8_0_split needs backward computation.
I1226 07:02:56.288261 88126 net.cpp:305] fc8 needs backward computation.
I1226 07:02:56.288293 88126 net.cpp:305] drop7 needs backward computation.
I1226 07:02:56.288324 88126 net.cpp:305] relu7 needs backward computation.
I1226 07:02:56.288354 88126 net.cpp:305] fc7 needs backward computation.
I1226 07:02:56.288396 88126 net.cpp:305] drop6 needs backward computation.
I1226 07:02:56.288427 88126 net.cpp:305] relu6 needs backward computation.
I1226 07:02:56.288457 88126 net.cpp:305] fc6 needs backward computation.
I1226 07:02:56.288493 88126 net.cpp:305] pool5 needs backward computation.
I1226 07:02:56.288525 88126 net.cpp:305] relu5 needs backward computation.
I1226 07:02:56.288564 88126 net.cpp:305] conv5 needs backward computation.
I1226 07:02:56.288624 88126 net.cpp:305] relu4 needs backward computation.
I1226 07:02:56.288657 88126 net.cpp:305] conv4 needs backward computation.
I1226 07:02:56.288689 88126 net.cpp:305] relu3 needs backward computation.
I1226 07:02:56.288730 88126 net.cpp:305] conv3 needs backward computation.
I1226 07:02:56.288775 88126 net.cpp:305] pool2 needs backward computation.
I1226 07:02:56.288815 88126 net.cpp:305] norm2 needs backward computation.
I1226 07:02:56.288844 88126 net.cpp:305] relu2 needs backward computation.
I1226 07:02:56.288873 88126 net.cpp:305] conv2 needs backward computation.
I1226 07:02:56.288905 88126 net.cpp:305] pool1 needs backward computation.
I1226 07:02:56.288944 88126 net.cpp:305] norm1 needs backward computation.
I1226 07:02:56.288975 88126 net.cpp:305] relu1 needs backward computation.
I1226 07:02:56.289010 88126 net.cpp:305] conv1 needs backward computation.
I1226 07:02:56.289042 88126 net.cpp:307] label_data_1_split does not need backward computation.
I1226 07:02:56.289075 88126 net.cpp:307] data does not need backward computation.
I1226 07:02:56.289111 88126 net.cpp:349] This network produces output accuracy
I1226 07:02:56.289145 88126 net.cpp:349] This network produces output loss
I1226 07:02:56.289260 88126 net.cpp:363] Network initialization done.
I1226 07:02:56.289736 88126 solver.cpp:119] Solver scaffolding done.
I1226 07:02:56.289966 88126 caffe.cpp:212] Finetuning from /export/data1/stanford/hazy/gordon_bell/caffenet_knl/snapshot/caffenet_MN8_B1024/_iter_25000.caffemodel
I1226 07:02:56.301091 89170 net.cpp:228] Setting up fc8
I1226 07:02:56.301239 89170 net.cpp:235] Top shape: 64 1000 (64000)
I1226 07:02:56.301275 89170 net.cpp:243] Memory required for data: 532432384
I1226 07:02:56.301329 89170 layer_factory.hpp:114] Creating layer fc8_fc8_0_split
I1226 07:02:56.301434 89170 net.cpp:178] Creating Layer fc8_fc8_0_split
I1226 07:02:56.301625 89170 net.cpp:612] fc8_fc8_0_split <- fc8
I1226 07:02:56.301692 89170 net.cpp:586] fc8_fc8_0_split -> fc8_fc8_0_split_0
I1226 07:02:56.301898 89170 net.cpp:586] fc8_fc8_0_split -> fc8_fc8_0_split_1
I1226 07:02:56.302000 89170 net.cpp:228] Setting up fc8_fc8_0_split
I1226 07:02:56.302053 89170 net.cpp:235] Top shape: 64 1000 (64000)
I1226 07:02:56.302083 89170 net.cpp:235] Top shape: 64 1000 (64000)
I1226 07:02:56.302108 89170 net.cpp:243] Memory required for data: 532944384
I1226 07:02:56.302147 89170 layer_factory.hpp:114] Creating layer accuracy
I1226 07:02:56.302230 89170 net.cpp:178] Creating Layer accuracy
I1226 07:02:56.302266 89170 net.cpp:612] accuracy <- fc8_fc8_0_split_0
I1226 07:02:56.302299 89170 net.cpp:612] accuracy <- label_data_1_split_0
I1226 07:02:56.302333 89170 net.cpp:586] accuracy -> accuracy
I1226 07:02:56.302379 89170 net.cpp:228] Setting up accuracy
I1226 07:02:56.302414 89170 net.cpp:235] Top shape: (1)
I1226 07:02:56.302449 89170 net.cpp:243] Memory required for data: 532944388
I1226 07:02:56.302487 89170 layer_factory.hpp:114] Creating layer loss
I1226 07:02:56.302531 89170 net.cpp:178] Creating Layer loss
I1226 07:02:56.302564 89170 net.cpp:612] loss <- fc8_fc8_0_split_1
I1226 07:02:56.302594 89170 net.cpp:612] loss <- label_data_1_split_1
I1226 07:02:56.302628 89170 net.cpp:586] loss -> loss
I1226 07:02:56.302686 89170 layer_factory.hpp:114] Creating layer loss
I1226 07:02:56.317596 51587 net.cpp:228] Setting up fc8
I1226 07:02:56.317719 51587 net.cpp:235] Top shape: 64 1000 (64000)
I1226 07:02:56.317749 51587 net.cpp:243] Memory required for data: 532432384
I1226 07:02:56.317805 51587 layer_factory.hpp:114] Creating layer fc8_fc8_0_split
I1226 07:02:56.317873 51587 net.cpp:178] Creating Layer fc8_fc8_0_split
I1226 07:02:56.317903 51587 net.cpp:612] fc8_fc8_0_split <- fc8
I1226 07:02:56.317965 51587 net.cpp:586] fc8_fc8_0_split -> fc8_fc8_0_split_0
I1226 07:02:56.318017 51587 net.cpp:586] fc8_fc8_0_split -> fc8_fc8_0_split_1
I1226 07:02:56.318097 51587 net.cpp:228] Setting up fc8_fc8_0_split
I1226 07:02:56.318166 51587 net.cpp:235] Top shape: 64 1000 (64000)
I1226 07:02:56.318199 51587 net.cpp:235] Top shape: 64 1000 (64000)
I1226 07:02:56.321033 90546 net.cpp:228] Setting up fc8
I1226 07:02:56.318222 51587 net.cpp:243] Memory required for data: 532944384
I1226 07:02:56.321137 90546 net.cpp:235] Top shape: 64 1000 (64000)
I1226 07:02:56.321197 90546 net.cpp:243] Memory required for data: 532432384
I1226 07:02:56.321257 90546 layer_factory.hpp:114] Creating layer fc8_fc8_0_split
I1226 07:02:56.318256 51587 layer_factory.hpp:114] Creating layer accuracy
I1226 07:02:56.318320 51587 net.cpp:178] Creating Layer accuracy
I1226 07:02:56.321338 90546 net.cpp:178] Creating Layer fc8_fc8_0_split
I1226 07:02:56.318349 51587 net.cpp:612] accuracy <- fc8_fc8_0_split_0
I1226 07:02:56.321380 90546 net.cpp:612] fc8_fc8_0_split <- fc8
I1226 07:02:56.318380 51587 net.cpp:612] accuracy <- label_data_1_split_0
I1226 07:02:56.321434 90546 net.cpp:586] fc8_fc8_0_split -> fc8_fc8_0_split_0
I1226 07:02:56.318426 51587 net.cpp:586] accuracy -> accuracy
I1226 07:02:56.321485 90546 net.cpp:586] fc8_fc8_0_split -> fc8_fc8_0_split_1
I1226 07:02:56.318473 51587 net.cpp:228] Setting up accuracy
I1226 07:02:56.321571 90546 net.cpp:228] Setting up fc8_fc8_0_split
I1226 07:02:56.318512 51587 net.cpp:235] Top shape: (1)
I1226 07:02:56.318536 51587 net.cpp:243] Memory required for data: 532944388
I1226 07:02:56.318562 51587 layer_factory.hpp:114] Creating layer loss
I1226 07:02:56.321650 90546 net.cpp:235] Top shape: 64 1000 (64000)
I1226 07:02:56.318606 51587 net.cpp:178] Creating Layer loss
I1226 07:02:56.318631 51587 net.cpp:612] loss <- fc8_fc8_0_split_1
I1226 07:02:56.321760 90546 net.cpp:235] Top shape: 64 1000 (64000)
I1226 07:02:56.321784 90546 net.cpp:243] Memory required for data: 532944384
I1226 07:02:56.318660 51587 net.cpp:612] loss <- label_data_1_split_1
I1226 07:02:56.321813 90546 layer_factory.hpp:114] Creating layer accuracy
I1226 07:02:56.318698 51587 net.cpp:586] loss -> loss
I1226 07:02:56.321880 90546 net.cpp:178] Creating Layer accuracy
I1226 07:02:56.321913 90546 net.cpp:612] accuracy <- fc8_fc8_0_split_0
I1226 07:02:56.318754 51587 layer_factory.hpp:114] Creating layer loss
I1226 07:02:56.321945 90546 net.cpp:612] accuracy <- label_data_1_split_0
I1226 07:02:56.321985 90546 net.cpp:586] accuracy -> accuracy
I1226 07:02:56.322037 90546 net.cpp:228] Setting up accuracy
I1226 07:02:56.322077 90546 net.cpp:235] Top shape: (1)
I1226 07:02:56.322099 90546 net.cpp:243] Memory required for data: 532944388
I1226 07:02:56.322127 90546 layer_factory.hpp:114] Creating layer loss
I1226 07:02:56.322245 90546 net.cpp:178] Creating Layer loss
I1226 07:02:56.322278 90546 net.cpp:612] loss <- fc8_fc8_0_split_1
I1226 07:02:56.322309 90546 net.cpp:612] loss <- label_data_1_split_1
I1226 07:02:56.322343 90546 net.cpp:586] loss -> loss
I1226 07:02:56.322409 90546 layer_factory.hpp:114] Creating layer loss
I1226 07:02:56.326304 89170 net.cpp:228] Setting up loss
I1226 07:02:56.326419 89170 net.cpp:235] Top shape: (1)
I1226 07:02:56.326588 89170 net.cpp:238]     with loss weight 1
I1226 07:02:56.326741 89170 net.cpp:243] Memory required for data: 532944392
I1226 07:02:56.326788 89170 net.cpp:305] loss needs backward computation.
I1226 07:02:56.326828 89170 net.cpp:307] accuracy does not need backward computation.
I1226 07:02:56.326864 89170 net.cpp:305] fc8_fc8_0_split needs backward computation.
I1226 07:02:56.326903 89170 net.cpp:305] fc8 needs backward computation.
I1226 07:02:56.326934 89170 net.cpp:305] drop7 needs backward computation.
I1226 07:02:56.326964 89170 net.cpp:305] relu7 needs backward computation.
I1226 07:02:56.326995 89170 net.cpp:305] fc7 needs backward computation.
I1226 07:02:56.327025 89170 net.cpp:305] drop6 needs backward computation.
I1226 07:02:56.327054 89170 net.cpp:305] relu6 needs backward computation.
I1226 07:02:56.327083 89170 net.cpp:305] fc6 needs backward computation.
I1226 07:02:56.327122 89170 net.cpp:305] pool5 needs backward computation.
I1226 07:02:56.327154 89170 net.cpp:305] relu5 needs backward computation.
I1226 07:02:56.327184 89170 net.cpp:305] conv5 needs backward computation.
I1226 07:02:56.327247 89170 net.cpp:305] relu4 needs backward computation.
I1226 07:02:56.327281 89170 net.cpp:305] conv4 needs backward computation.
I1226 07:02:56.327311 89170 net.cpp:305] relu3 needs backward computation.
I1226 07:02:56.327338 89170 net.cpp:305] conv3 needs backward computation.
I1226 07:02:56.327368 89170 net.cpp:305] pool2 needs backward computation.
I1226 07:02:56.327397 89170 net.cpp:305] norm2 needs backward computation.
I1226 07:02:56.327426 89170 net.cpp:305] relu2 needs backward computation.
I1226 07:02:56.327455 89170 net.cpp:305] conv2 needs backward computation.
I1226 07:02:56.327482 89170 net.cpp:305] pool1 needs backward computation.
I1226 07:02:56.327512 89170 net.cpp:305] norm1 needs backward computation.
I1226 07:02:56.327541 89170 net.cpp:305] relu1 needs backward computation.
I1226 07:02:56.327569 89170 net.cpp:305] conv1 needs backward computation.
I1226 07:02:56.327600 89170 net.cpp:307] label_data_1_split does not need backward computation.
I1226 07:02:56.327630 89170 net.cpp:307] data does not need backward computation.
I1226 07:02:56.327656 89170 net.cpp:349] This network produces output accuracy
I1226 07:02:56.327687 89170 net.cpp:349] This network produces output loss
I1226 07:02:56.327795 89170 net.cpp:363] Network initialization done.
I1226 07:02:56.328371 89170 solver.cpp:119] Solver scaffolding done.
I1226 07:02:56.328590 89170 caffe.cpp:212] Finetuning from /export/data1/stanford/hazy/gordon_bell/caffenet_knl/snapshot/caffenet_MN8_B1024/_iter_25000.caffemodel
I1226 07:02:56.344100 51587 net.cpp:228] Setting up loss
I1226 07:02:56.344228 51587 net.cpp:235] Top shape: (1)
I1226 07:02:56.344384 51587 net.cpp:238]     with loss weight 1
I1226 07:02:56.344532 51587 net.cpp:243] Memory required for data: 532944392
I1226 07:02:56.344583 51587 net.cpp:305] loss needs backward computation.
I1226 07:02:56.344624 51587 net.cpp:307] accuracy does not need backward computation.
I1226 07:02:56.344658 51587 net.cpp:305] fc8_fc8_0_split needs backward computation.
I1226 07:02:56.344691 51587 net.cpp:305] fc8 needs backward computation.
I1226 07:02:56.344722 51587 net.cpp:305] drop7 needs backward computation.
I1226 07:02:56.344753 51587 net.cpp:305] relu7 needs backward computation.
I1226 07:02:56.344784 51587 net.cpp:305] fc7 needs backward computation.
I1226 07:02:56.344815 51587 net.cpp:305] drop6 needs backward computation.
I1226 07:02:56.344843 51587 net.cpp:305] relu6 needs backward computation.
I1226 07:02:56.344874 51587 net.cpp:305] fc6 needs backward computation.
I1226 07:02:56.344905 51587 net.cpp:305] pool5 needs backward computation.
I1226 07:02:56.344936 51587 net.cpp:305] relu5 needs backward computation.
I1226 07:02:56.344980 51587 net.cpp:305] conv5 needs backward computation.
I1226 07:02:56.345012 51587 net.cpp:305] relu4 needs backward computation.
I1226 07:02:56.345052 51587 net.cpp:305] conv4 needs backward computation.
I1226 07:02:56.345084 51587 net.cpp:305] relu3 needs backward computation.
I1226 07:02:56.345114 51587 net.cpp:305] conv3 needs backward computation.
I1226 07:02:56.345372 51587 net.cpp:305] pool2 needs backward computation.
I1226 07:02:56.345418 51587 net.cpp:305] norm2 needs backward computation.
I1226 07:02:56.345450 51587 net.cpp:305] relu2 needs backward computation.
I1226 07:02:56.345494 51587 net.cpp:305] conv2 needs backward computation.
I1226 07:02:56.345525 51587 net.cpp:305] pool1 needs backward computation.
I1226 07:02:56.345566 51587 net.cpp:305] norm1 needs backward computation.
I1226 07:02:56.345607 51587 net.cpp:305] relu1 needs backward computation.
I1226 07:02:56.345644 51587 net.cpp:305] conv1 needs backward computation.
I1226 07:02:56.345685 51587 net.cpp:307] label_data_1_split does not need backward computation.
I1226 07:02:56.345721 51587 net.cpp:307] data does not need backward computation.
I1226 07:02:56.345751 51587 net.cpp:349] This network produces output accuracy
I1226 07:02:56.345785 51587 net.cpp:349] This network produces output loss
I1226 07:02:56.345885 51587 net.cpp:363] Network initialization done.
I1226 07:02:56.346366 51587 solver.cpp:119] Solver scaffolding done.
I1226 07:02:56.346593 51587 caffe.cpp:212] Finetuning from /export/data1/stanford/hazy/gordon_bell/caffenet_knl/snapshot/caffenet_MN8_B1024/_iter_25000.caffemodel
I1226 07:02:56.353907 89451 net.cpp:228] Setting up fc8
I1226 07:02:56.354020 89451 net.cpp:235] Top shape: 64 1000 (64000)
I1226 07:02:56.354049 89451 net.cpp:243] Memory required for data: 532432384
I1226 07:02:56.354102 89451 layer_factory.hpp:114] Creating layer fc8_fc8_0_split
I1226 07:02:56.354198 89451 net.cpp:178] Creating Layer fc8_fc8_0_split
I1226 07:02:56.354241 89451 net.cpp:612] fc8_fc8_0_split <- fc8
I1226 07:02:56.354298 89451 net.cpp:586] fc8_fc8_0_split -> fc8_fc8_0_split_0
I1226 07:02:56.354356 89451 net.cpp:586] fc8_fc8_0_split -> fc8_fc8_0_split_1
I1226 07:02:56.354439 89451 net.cpp:228] Setting up fc8_fc8_0_split
I1226 07:02:56.354514 89451 net.cpp:235] Top shape: 64 1000 (64000)
I1226 07:02:56.354547 89451 net.cpp:235] Top shape: 64 1000 (64000)
I1226 07:02:56.354570 89451 net.cpp:243] Memory required for data: 532944384
I1226 07:02:56.354601 89451 layer_factory.hpp:114] Creating layer accuracy
I1226 07:02:56.354763 89451 net.cpp:178] Creating Layer accuracy
I1226 07:02:56.354800 89451 net.cpp:612] accuracy <- fc8_fc8_0_split_0
I1226 07:02:56.354840 89451 net.cpp:612] accuracy <- label_data_1_split_0
I1226 07:02:56.354874 89451 net.cpp:586] accuracy -> accuracy
I1226 07:02:56.354920 89451 net.cpp:228] Setting up accuracy
I1226 07:02:56.354955 89451 net.cpp:235] Top shape: (1)
I1226 07:02:56.354989 89451 net.cpp:243] Memory required for data: 532944388
I1226 07:02:56.355015 89451 layer_factory.hpp:114] Creating layer loss
I1226 07:02:56.355065 89451 net.cpp:178] Creating Layer loss
I1226 07:02:56.355095 89451 net.cpp:612] loss <- fc8_fc8_0_split_1
I1226 07:02:56.355123 89451 net.cpp:612] loss <- label_data_1_split_1
I1226 07:02:56.355156 89451 net.cpp:586] loss -> loss
I1226 07:02:56.355212 89451 layer_factory.hpp:114] Creating layer loss
I1226 07:02:56.351058 90546 net.cpp:228] Setting up loss
I1226 07:02:56.351161 90546 net.cpp:235] Top shape: (1)
I1226 07:02:56.351313 90546 net.cpp:238]     with loss weight 1
I1226 07:02:56.351476 90546 net.cpp:243] Memory required for data: 532944392
I1226 07:02:56.351527 90546 net.cpp:305] loss needs backward computation.
I1226 07:02:56.351575 90546 net.cpp:307] accuracy does not need backward computation.
I1226 07:02:56.351620 90546 net.cpp:305] fc8_fc8_0_split needs backward computation.
I1226 07:02:56.351660 90546 net.cpp:305] fc8 needs backward computation.
I1226 07:02:56.351699 90546 net.cpp:305] drop7 needs backward computation.
I1226 07:02:56.351737 90546 net.cpp:305] relu7 needs backward computation.
I1226 07:02:56.351774 90546 net.cpp:305] fc7 needs backward computation.
I1226 07:02:56.351814 90546 net.cpp:305] drop6 needs backward computation.
I1226 07:02:56.351850 90546 net.cpp:305] relu6 needs backward computation.
I1226 07:02:56.351887 90546 net.cpp:305] fc6 needs backward computation.
I1226 07:02:56.351927 90546 net.cpp:305] pool5 needs backward computation.
I1226 07:02:56.351964 90546 net.cpp:305] relu5 needs backward computation.
I1226 07:02:56.352002 90546 net.cpp:305] conv5 needs backward computation.
I1226 07:02:56.352041 90546 net.cpp:305] relu4 needs backward computation.
I1226 07:02:56.352077 90546 net.cpp:305] conv4 needs backward computation.
I1226 07:02:56.352115 90546 net.cpp:305] relu3 needs backward computation.
I1226 07:02:56.352154 90546 net.cpp:305] conv3 needs backward computation.
I1226 07:02:56.352215 90546 net.cpp:305] pool2 needs backward computation.
I1226 07:02:56.352252 90546 net.cpp:305] norm2 needs backward computation.
I1226 07:02:56.352288 90546 net.cpp:305] relu2 needs backward computation.
I1226 07:02:56.352324 90546 net.cpp:305] conv2 needs backward computation.
I1226 07:02:56.352360 90546 net.cpp:305] pool1 needs backward computation.
I1226 07:02:56.352396 90546 net.cpp:305] norm1 needs backward computation.
I1226 07:02:56.352430 90546 net.cpp:305] relu1 needs backward computation.
I1226 07:02:56.352468 90546 net.cpp:305] conv1 needs backward computation.
I1226 07:02:56.352509 90546 net.cpp:307] label_data_1_split does not need backward computation.
I1226 07:02:56.352550 90546 net.cpp:307] data does not need backward computation.
I1226 07:02:56.352584 90546 net.cpp:349] This network produces output accuracy
I1226 07:02:56.352627 90546 net.cpp:349] This network produces output loss
I1226 07:02:56.352761 90546 net.cpp:363] Network initialization done.
I1226 07:02:56.353268 90546 solver.cpp:119] Solver scaffolding done.
I1226 07:02:56.353507 90546 caffe.cpp:212] Finetuning from /export/data1/stanford/hazy/gordon_bell/caffenet_knl/snapshot/caffenet_MN8_B1024/_iter_25000.caffemodel
I1226 07:02:56.381945 89451 net.cpp:228] Setting up loss
I1226 07:02:56.382057 89451 net.cpp:235] Top shape: (1)
I1226 07:02:56.382372 89451 net.cpp:238]     with loss weight 1
I1226 07:02:56.382555 89451 net.cpp:243] Memory required for data: 532944392
I1226 07:02:56.382611 89451 net.cpp:305] loss needs backward computation.
I1226 07:02:56.382655 89451 net.cpp:307] accuracy does not need backward computation.
I1226 07:02:56.382689 89451 net.cpp:305] fc8_fc8_0_split needs backward computation.
I1226 07:02:56.382724 89451 net.cpp:305] fc8 needs backward computation.
I1226 07:02:56.382755 89451 net.cpp:305] drop7 needs backward computation.
I1226 07:02:56.382784 89451 net.cpp:305] relu7 needs backward computation.
I1226 07:02:56.382829 89451 net.cpp:305] fc7 needs backward computation.
I1226 07:02:56.382861 89451 net.cpp:305] drop6 needs backward computation.
I1226 07:02:56.382892 89451 net.cpp:305] relu6 needs backward computation.
I1226 07:02:56.382922 89451 net.cpp:305] fc6 needs backward computation.
I1226 07:02:56.382961 89451 net.cpp:305] pool5 needs backward computation.
I1226 07:02:56.382992 89451 net.cpp:305] relu5 needs backward computation.
I1226 07:02:56.383023 89451 net.cpp:305] conv5 needs backward computation.
I1226 07:02:56.383055 89451 net.cpp:305] relu4 needs backward computation.
I1226 07:02:56.383085 89451 net.cpp:305] conv4 needs backward computation.
I1226 07:02:56.383114 89451 net.cpp:305] relu3 needs backward computation.
I1226 07:02:56.383147 89451 net.cpp:305] conv3 needs backward computation.
I1226 07:02:56.383189 89451 net.cpp:305] pool2 needs backward computation.
I1226 07:02:56.383220 89451 net.cpp:305] norm2 needs backward computation.
I1226 07:02:56.383257 89451 net.cpp:305] relu2 needs backward computation.
I1226 07:02:56.383296 89451 net.cpp:305] conv2 needs backward computation.
I1226 07:02:56.383327 89451 net.cpp:305] pool1 needs backward computation.
I1226 07:02:56.383358 89451 net.cpp:305] norm1 needs backward computation.
I1226 07:02:56.383389 89451 net.cpp:305] relu1 needs backward computation.
I1226 07:02:56.383427 89451 net.cpp:305] conv1 needs backward computation.
I1226 07:02:56.383460 89451 net.cpp:307] label_data_1_split does not need backward computation.
I1226 07:02:56.383518 89451 net.cpp:307] data does not need backward computation.
I1226 07:02:56.383546 89451 net.cpp:349] This network produces output accuracy
I1226 07:02:56.383580 89451 net.cpp:349] This network produces output loss
I1226 07:02:56.383685 89451 net.cpp:363] Network initialization done.
I1226 07:02:56.384136 89451 solver.cpp:119] Solver scaffolding done.
I1226 07:02:56.384361 89451 caffe.cpp:212] Finetuning from /export/data1/stanford/hazy/gordon_bell/caffenet_knl/snapshot/caffenet_MN8_B1024/_iter_25000.caffemodel
I1226 07:02:59.283718 96083 caffe.cpp:376] Configuring multinode setup
I1226 07:02:59.287775 96083 caffe.cpp:386] Starting parameter server in mpi environment
I1226 07:03:00.290684 89165 caffe.cpp:376] Configuring multinode setup
I1226 07:03:00.292187 89165 caffe.cpp:392] Starting Multi-node Optimization in mpi environment
I1226 07:03:00.319166 89377 caffe.cpp:376] Configuring multinode setup
I1226 07:03:00.320648 89377 caffe.cpp:392] Starting Multi-node Optimization in mpi environment
I1226 07:03:00.351864 88126 caffe.cpp:376] Configuring multinode setup
I1226 07:03:00.353302 88126 caffe.cpp:392] Starting Multi-node Optimization in mpi environment
I1226 07:03:00.375329 89170 caffe.cpp:376] Configuring multinode setup
I1226 07:03:00.376873 89170 caffe.cpp:392] Starting Multi-node Optimization in mpi environment
I1226 07:03:00.393020 51587 caffe.cpp:376] Configuring multinode setup
I1226 07:03:00.394587 51587 caffe.cpp:392] Starting Multi-node Optimization in mpi environment
I1226 07:03:00.422309 90546 caffe.cpp:376] Configuring multinode setup
I1226 07:03:00.423832 90546 caffe.cpp:392] Starting Multi-node Optimization in mpi environment
I1226 07:03:00.462393 89451 caffe.cpp:376] Configuring multinode setup
I1226 07:03:00.463934 89451 caffe.cpp:392] Starting Multi-node Optimization in mpi environment
I1226 07:03:20.621745 93507 net.cpp:228] Setting up fc6
I1226 07:03:20.622036 93507 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:03:20.622081 93507 net.cpp:243] Memory required for data: 526933504
I1226 07:03:20.622145 93507 layer_factory.hpp:114] Creating layer relu6
I1226 07:03:20.622342 93507 net.cpp:178] Creating Layer relu6
I1226 07:03:20.622398 93507 net.cpp:612] relu6 <- fc6
I1226 07:03:20.622442 93507 net.cpp:573] relu6 -> fc6 (in-place)
I1226 07:03:20.622534 93507 net.cpp:228] Setting up relu6
I1226 07:03:20.622589 93507 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:03:20.622615 93507 net.cpp:243] Memory required for data: 527982080
I1226 07:03:20.622647 93507 layer_factory.hpp:114] Creating layer drop6
I1226 07:03:20.622709 93507 net.cpp:178] Creating Layer drop6
I1226 07:03:20.622750 93507 net.cpp:612] drop6 <- fc6
I1226 07:03:20.622836 93507 net.cpp:573] drop6 -> fc6 (in-place)
I1226 07:03:20.622903 93507 net.cpp:228] Setting up drop6
I1226 07:03:20.622941 93507 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:03:20.622964 93507 net.cpp:243] Memory required for data: 529030656
I1226 07:03:20.622993 93507 layer_factory.hpp:114] Creating layer fc7
I1226 07:03:20.623051 93507 net.cpp:178] Creating Layer fc7
I1226 07:03:20.623080 93507 net.cpp:612] fc7 <- fc6
I1226 07:03:20.623116 93507 net.cpp:586] fc7 -> fc7
I1226 07:03:33.696946 93507 net.cpp:228] Setting up fc7
I1226 07:03:33.697067 93507 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:03:33.697101 93507 net.cpp:243] Memory required for data: 530079232
I1226 07:03:33.697165 93507 layer_factory.hpp:114] Creating layer relu7
I1226 07:03:33.697327 93507 net.cpp:178] Creating Layer relu7
I1226 07:03:33.697374 93507 net.cpp:612] relu7 <- fc7
I1226 07:03:33.697427 93507 net.cpp:573] relu7 -> fc7 (in-place)
I1226 07:03:33.697525 93507 net.cpp:228] Setting up relu7
I1226 07:03:33.697578 93507 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:03:33.697605 93507 net.cpp:243] Memory required for data: 531127808
I1226 07:03:33.697638 93507 layer_factory.hpp:114] Creating layer drop7
I1226 07:03:33.697680 93507 net.cpp:178] Creating Layer drop7
I1226 07:03:33.697711 93507 net.cpp:612] drop7 <- fc7
I1226 07:03:33.697756 93507 net.cpp:573] drop7 -> fc7 (in-place)
I1226 07:03:33.697835 93507 net.cpp:228] Setting up drop7
I1226 07:03:33.697878 93507 net.cpp:235] Top shape: 64 4096 (262144)
I1226 07:03:33.697903 93507 net.cpp:243] Memory required for data: 532176384
I1226 07:03:33.697934 93507 layer_factory.hpp:114] Creating layer fc8
I1226 07:03:33.697999 93507 net.cpp:178] Creating Layer fc8
I1226 07:03:33.698038 93507 net.cpp:612] fc8 <- fc7
I1226 07:03:33.698101 93507 net.cpp:586] fc8 -> fc8
I1226 07:03:36.887037 93507 net.cpp:228] Setting up fc8
I1226 07:03:36.887159 93507 net.cpp:235] Top shape: 64 1000 (64000)
I1226 07:03:36.887195 93507 net.cpp:243] Memory required for data: 532432384
I1226 07:03:36.887260 93507 layer_factory.hpp:114] Creating layer fc8_fc8_0_split
I1226 07:03:36.887343 93507 net.cpp:178] Creating Layer fc8_fc8_0_split
I1226 07:03:36.887390 93507 net.cpp:612] fc8_fc8_0_split <- fc8
I1226 07:03:36.887459 93507 net.cpp:586] fc8_fc8_0_split -> fc8_fc8_0_split_0
I1226 07:03:36.887523 93507 net.cpp:586] fc8_fc8_0_split -> fc8_fc8_0_split_1
I1226 07:03:36.887620 93507 net.cpp:228] Setting up fc8_fc8_0_split
I1226 07:03:36.887678 93507 net.cpp:235] Top shape: 64 1000 (64000)
I1226 07:03:36.887718 93507 net.cpp:235] Top shape: 64 1000 (64000)
I1226 07:03:36.887749 93507 net.cpp:243] Memory required for data: 532944384
I1226 07:03:36.887819 93507 layer_factory.hpp:114] Creating layer accuracy
I1226 07:03:36.887881 93507 net.cpp:178] Creating Layer accuracy
I1226 07:03:36.887915 93507 net.cpp:612] accuracy <- fc8_fc8_0_split_0
I1226 07:03:36.887948 93507 net.cpp:612] accuracy <- label_data_1_split_0
I1226 07:03:36.888002 93507 net.cpp:586] accuracy -> accuracy
I1226 07:03:36.888069 93507 net.cpp:228] Setting up accuracy
I1226 07:03:36.888121 93507 net.cpp:235] Top shape: (1)
I1226 07:03:36.888154 93507 net.cpp:243] Memory required for data: 532944388
I1226 07:03:36.888195 93507 layer_factory.hpp:114] Creating layer loss
I1226 07:03:36.888347 93507 net.cpp:178] Creating Layer loss
I1226 07:03:36.888392 93507 net.cpp:612] loss <- fc8_fc8_0_split_1
I1226 07:03:36.888433 93507 net.cpp:612] loss <- label_data_1_split_1
I1226 07:03:36.888473 93507 net.cpp:586] loss -> loss
I1226 07:03:36.888546 93507 layer_factory.hpp:114] Creating layer loss
I1226 07:03:36.927884 93507 net.cpp:228] Setting up loss
I1226 07:03:36.928012 93507 net.cpp:235] Top shape: (1)
I1226 07:03:36.928061 93507 net.cpp:238]     with loss weight 1
I1226 07:03:36.928208 93507 net.cpp:243] Memory required for data: 532944392
I1226 07:03:36.928258 93507 net.cpp:305] loss needs backward computation.
I1226 07:03:36.928315 93507 net.cpp:307] accuracy does not need backward computation.
I1226 07:03:36.928359 93507 net.cpp:305] fc8_fc8_0_split needs backward computation.
I1226 07:03:36.928390 93507 net.cpp:305] fc8 needs backward computation.
I1226 07:03:36.928421 93507 net.cpp:305] drop7 needs backward computation.
I1226 07:03:36.928462 93507 net.cpp:305] relu7 needs backward computation.
I1226 07:03:36.928493 93507 net.cpp:305] fc7 needs backward computation.
I1226 07:03:36.928534 93507 net.cpp:305] drop6 needs backward computation.
I1226 07:03:36.928565 93507 net.cpp:305] relu6 needs backward computation.
I1226 07:03:36.928596 93507 net.cpp:305] fc6 needs backward computation.
I1226 07:03:36.928627 93507 net.cpp:305] pool5 needs backward computation.
I1226 07:03:36.928673 93507 net.cpp:305] relu5 needs backward computation.
I1226 07:03:36.928710 93507 net.cpp:305] conv5 needs backward computation.
I1226 07:03:36.928742 93507 net.cpp:305] relu4 needs backward computation.
I1226 07:03:36.928781 93507 net.cpp:305] conv4 needs backward computation.
I1226 07:03:36.928838 93507 net.cpp:305] relu3 needs backward computation.
I1226 07:03:36.928869 93507 net.cpp:305] conv3 needs backward computation.
I1226 07:03:36.928902 93507 net.cpp:305] pool2 needs backward computation.
I1226 07:03:36.928935 93507 net.cpp:305] norm2 needs backward computation.
I1226 07:03:36.928966 93507 net.cpp:305] relu2 needs backward computation.
I1226 07:03:36.928995 93507 net.cpp:305] conv2 needs backward computation.
I1226 07:03:36.929028 93507 net.cpp:305] pool1 needs backward computation.
I1226 07:03:36.929059 93507 net.cpp:305] norm1 needs backward computation.
I1226 07:03:36.929097 93507 net.cpp:305] relu1 needs backward computation.
I1226 07:03:36.929128 93507 net.cpp:305] conv1 needs backward computation.
I1226 07:03:36.929172 93507 net.cpp:307] label_data_1_split does not need backward computation.
I1226 07:03:36.929205 93507 net.cpp:307] data does not need backward computation.
I1226 07:03:36.929234 93507 net.cpp:349] This network produces output accuracy
I1226 07:03:36.929270 93507 net.cpp:349] This network produces output loss
I1226 07:03:36.929381 93507 net.cpp:363] Network initialization done.
I1226 07:03:36.929847 93507 solver.cpp:119] Solver scaffolding done.
I1226 07:03:36.930078 93507 caffe.cpp:212] Finetuning from /export/data1/stanford/hazy/gordon_bell/caffenet_knl/snapshot/caffenet_MN8_B1024/_iter_25000.caffemodel
I1226 07:03:42.345237 93507 caffe.cpp:376] Configuring multinode setup
I1226 07:03:42.347491 93507 caffe.cpp:392] Starting Multi-node Optimization in mpi environment
I1226 07:03:42.347748 93507 SynchronousNode.cpp:662] [7] [proc 7] solving
I1226 07:03:42.347903 93507 solver.cpp:370] Solving AlexNet
I1226 07:03:42.347949 93507 solver.cpp:371] Learning Rate Policy: step
I1226 07:03:42.350778 90546 SynchronousNode.cpp:662] [0] [proc 0] solving
I1226 07:03:42.348255 93507 solver.cpp:298] [7] PROFILING BEGIN[Forward] Iteration 1
I1226 07:03:42.346981 89170 SynchronousNode.cpp:662] [3] [proc 3] solving
I1226 07:03:42.347277 89170 solver.cpp:370] Solving AlexNet
I1226 07:03:42.347326 89170 solver.cpp:371] Learning Rate Policy: step
I1226 07:03:42.347551 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 1
I1226 07:03:42.349010 89377 SynchronousNode.cpp:662] [1] [proc 1] solving
I1226 07:03:42.348098 51587 SynchronousNode.cpp:662] [5] [proc 5] solving
I1226 07:03:42.344631 96083 async_param_server.cpp:187] PS: Comm loop
I1226 07:03:42.352617 89165 SynchronousNode.cpp:662] [4] [proc 4] solving
I1226 07:03:42.351472 88126 SynchronousNode.cpp:662] [6] [proc 6] solving
I1226 07:03:42.355172 89451 SynchronousNode.cpp:662] [2] [proc 2] solving
I1226 07:03:42.349295 89377 solver.cpp:370] Solving AlexNet
I1226 07:03:42.349342 89377 solver.cpp:371] Learning Rate Policy: step
I1226 07:03:42.348386 51587 solver.cpp:370] Solving AlexNet
I1226 07:03:42.348461 51587 solver.cpp:371] Learning Rate Policy: step
I1226 07:03:42.352908 89165 solver.cpp:370] Solving AlexNet
I1226 07:03:42.351771 88126 solver.cpp:370] Solving AlexNet
I1226 07:03:42.351824 88126 solver.cpp:371] Learning Rate Policy: step
I1226 07:03:42.355456 89451 solver.cpp:370] Solving AlexNet
I1226 07:03:42.355535 89451 solver.cpp:371] Learning Rate Policy: step
I1226 07:03:42.349561 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 1
I1226 07:03:42.348686 51587 solver.cpp:298] [5] PROFILING BEGIN[Forward] Iteration 1
I1226 07:03:42.352959 89165 solver.cpp:371] Learning Rate Policy: step
I1226 07:03:42.352042 88126 solver.cpp:298] [6] PROFILING BEGIN[Forward] Iteration 1
I1226 07:03:42.355770 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 1
I1226 07:03:42.351058 90546 solver.cpp:370] Solving AlexNet
I1226 07:03:42.351106 90546 solver.cpp:371] Learning Rate Policy: step
I1226 07:03:42.351372 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 1
I1226 07:03:42.353191 89165 solver.cpp:298] [4] PROFILING BEGIN[Forward] Iteration 1
I1226 07:03:42.351734 93579 SynchronousNode.cpp:280] [7] Comm thread started 1 0
I1226 07:03:42.360141 88196 SynchronousNode.cpp:280] [6] Comm thread started 1 0
I1226 07:03:42.362185 89233 SynchronousNode.cpp:280] [4] Comm thread started 0 1
I1226 07:03:42.358193 96155 async_param_server.cpp:175] PS: Compute loop
I1226 07:03:42.361914 89242 SynchronousNode.cpp:280] [3] Comm thread started 1 0
I1226 07:03:42.385002 89524 SynchronousNode.cpp:280] [2] Comm thread started 1 0
I1226 07:03:42.380375 89450 SynchronousNode.cpp:280] [1] Comm thread started 0 0
I1226 07:03:42.381232 51655 SynchronousNode.cpp:280] [5] Comm thread started 0 0
I1226 07:03:42.387292 90619 SynchronousNode.cpp:280] [0] Comm thread started 0 1
I1226 07:03:42.392853 89233 SynchronousNode.cpp:466] [4] initialized root of cluster with nodes: 9 and the total iter size is: 4
I1226 07:03:42.395241 90619 SynchronousNode.cpp:466] [0] initialized root of cluster with nodes: 9 and the total iter size is: 4
I1226 07:03:43.170392 89165 solver.cpp:300] [4] PROFILING END[Forward] Iteration 1
I1226 07:03:43.170470 89165 solver.cpp:305] [4] PROFILING BEGIN[Other] Iteration 1
I1226 07:03:43.170532 89165 solver.cpp:306] [4] Iteration 1, loss = 3.11985
I1226 07:03:43.170585 89165 solver.cpp:309] [4] PROFILING END[Other] Iteration 1
I1226 07:03:43.170920 89165 solver.cpp:333]     Train net output #0: accuracy = 0.296875
I1226 07:03:43.170979 89165 solver.cpp:333]     Train net output #1: loss = 3.11985 (* 1 = 3.11985 loss)
I1226 07:03:43.171030 89165 solver.cpp:298] [4] PROFILING BEGIN[Forward] Iteration 2
I1226 07:03:43.341490 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 1
I1226 07:03:43.341564 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 1
I1226 07:03:43.341596 90546 solver.cpp:306] [0] Iteration 1, loss = 3.35463
I1226 07:03:43.341648 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 1
I1226 07:03:43.341677 90546 solver.cpp:333]     Train net output #0: accuracy = 0.28125
I1226 07:03:43.341734 90546 solver.cpp:333]     Train net output #1: loss = 3.35463 (* 1 = 3.35463 loss)
I1226 07:03:43.341778 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 2
I1226 07:03:43.850358 88126 solver.cpp:300] [6] PROFILING END[Forward] Iteration 1
I1226 07:03:43.850452 88126 solver.cpp:305] [6] PROFILING BEGIN[Other] Iteration 1
I1226 07:03:43.850500 88126 solver.cpp:306] [6] Iteration 1, loss = 3.23536
I1226 07:03:43.850613 88126 solver.cpp:309] [6] PROFILING END[Other] Iteration 1
I1226 07:03:43.850680 88126 solver.cpp:333]     Train net output #0: accuracy = 0.328125
I1226 07:03:43.850910 88126 solver.cpp:333]     Train net output #1: loss = 3.23536 (* 1 = 3.23536 loss)
I1226 07:03:43.850996 88126 solver.cpp:298] [6] PROFILING BEGIN[Forward] Iteration 2
I1226 07:03:43.932813 51587 solver.cpp:300] [5] PROFILING END[Forward] Iteration 1
I1226 07:03:43.932901 51587 solver.cpp:305] [5] PROFILING BEGIN[Other] Iteration 1
I1226 07:03:43.932940 51587 solver.cpp:306] [5] Iteration 1, loss = 3.32593
I1226 07:03:43.933007 51587 solver.cpp:309] [5] PROFILING END[Other] Iteration 1
I1226 07:03:43.933065 51587 solver.cpp:333]     Train net output #0: accuracy = 0.21875
I1226 07:03:43.933173 51587 solver.cpp:333]     Train net output #1: loss = 3.32593 (* 1 = 3.32593 loss)
I1226 07:03:43.933241 51587 solver.cpp:298] [5] PROFILING BEGIN[Forward] Iteration 2
I1226 07:03:44.144896 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 1
I1226 07:03:44.144987 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 1
I1226 07:03:44.145035 89451 solver.cpp:306] [2] Iteration 1, loss = 3.19913
I1226 07:03:44.145113 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 1
I1226 07:03:44.145171 89451 solver.cpp:333]     Train net output #0: accuracy = 0.28125
I1226 07:03:44.145256 89451 solver.cpp:333]     Train net output #1: loss = 3.19913 (* 1 = 3.19913 loss)
I1226 07:03:44.145344 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 2
I1226 07:03:44.247205 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 1
I1226 07:03:44.247298 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 1
I1226 07:03:44.247355 89377 solver.cpp:306] [1] Iteration 1, loss = 3.12098
I1226 07:03:44.247429 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 1
I1226 07:03:44.247488 89377 solver.cpp:333]     Train net output #0: accuracy = 0.265625
I1226 07:03:44.247570 89377 solver.cpp:333]     Train net output #1: loss = 3.12098 (* 1 = 3.12098 loss)
I1226 07:03:44.247635 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 2
I1226 07:03:44.302716 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 1
I1226 07:03:44.302815 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 1
I1226 07:03:44.302865 89170 solver.cpp:306] [3] Iteration 1, loss = 3.24982
I1226 07:03:44.302937 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 1
I1226 07:03:44.302997 89170 solver.cpp:333]     Train net output #0: accuracy = 0.296875
I1226 07:03:44.303077 89170 solver.cpp:333]     Train net output #1: loss = 3.24982 (* 1 = 3.24982 loss)
I1226 07:03:44.303143 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 2
I1226 07:03:45.625917 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 2
I1226 07:03:45.626003 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 2
I1226 07:03:45.626041 90546 solver.cpp:306] [0] Iteration 2, loss = 3.59242
I1226 07:03:45.626133 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 2
I1226 07:03:45.626210 90546 solver.cpp:333]     Train net output #0: accuracy = 0.3125
I1226 07:03:45.626286 90546 solver.cpp:333]     Train net output #1: loss = 3.59242 (* 1 = 3.59242 loss)
I1226 07:03:45.626353 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 3
I1226 07:03:45.644248 93507 solver.cpp:300] [7] PROFILING END[Forward] Iteration 1
I1226 07:03:45.644343 93507 solver.cpp:305] [7] PROFILING BEGIN[Other] Iteration 1
I1226 07:03:45.644394 93507 solver.cpp:306] [7] Iteration 1, loss = 3.02748
I1226 07:03:45.644496 93507 solver.cpp:309] [7] PROFILING END[Other] Iteration 1
I1226 07:03:45.644961 93507 solver.cpp:333]     Train net output #0: accuracy = 0.328125
I1226 07:03:45.645200 93507 solver.cpp:333]     Train net output #1: loss = 3.02748 (* 1 = 3.02748 loss)
I1226 07:03:45.645437 93507 solver.cpp:298] [7] PROFILING BEGIN[Forward] Iteration 2
I1226 07:03:45.848922 89165 solver.cpp:300] [4] PROFILING END[Forward] Iteration 2
I1226 07:03:45.849012 89165 solver.cpp:305] [4] PROFILING BEGIN[Other] Iteration 2
I1226 07:03:45.849051 89165 solver.cpp:306] [4] Iteration 2, loss = 3.70481
I1226 07:03:45.849117 89165 solver.cpp:309] [4] PROFILING END[Other] Iteration 2
I1226 07:03:45.849156 89165 solver.cpp:333]     Train net output #0: accuracy = 0.171875
I1226 07:03:45.849220 89165 solver.cpp:333]     Train net output #1: loss = 3.70481 (* 1 = 3.70481 loss)
I1226 07:03:45.849313 89165 solver.cpp:298] [4] PROFILING BEGIN[Forward] Iteration 3
I1226 07:03:45.977923 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 2
I1226 07:03:45.978009 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 2
I1226 07:03:45.978094 89377 solver.cpp:306] [1] Iteration 2, loss = 3.55086
I1226 07:03:45.978307 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 2
I1226 07:03:45.978348 89377 solver.cpp:333]     Train net output #0: accuracy = 0.40625
I1226 07:03:45.978430 89377 solver.cpp:333]     Train net output #1: loss = 3.55086 (* 1 = 3.55086 loss)
I1226 07:03:45.978499 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 3
I1226 07:03:46.043320 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 2
I1226 07:03:46.043409 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 2
I1226 07:03:46.043462 89451 solver.cpp:306] [2] Iteration 2, loss = 3.58811
I1226 07:03:46.043568 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 2
I1226 07:03:46.043628 89451 solver.cpp:333]     Train net output #0: accuracy = 0.328125
I1226 07:03:46.043712 89451 solver.cpp:333]     Train net output #1: loss = 3.58811 (* 1 = 3.58811 loss)
I1226 07:03:46.043808 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 3
I1226 07:03:46.053318 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 2
I1226 07:03:46.053422 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 2
I1226 07:03:46.053483 89170 solver.cpp:306] [3] Iteration 2, loss = 2.59799
I1226 07:03:46.053570 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 2
I1226 07:03:46.053639 89170 solver.cpp:333]     Train net output #0: accuracy = 0.46875
I1226 07:03:46.053733 89170 solver.cpp:333]     Train net output #1: loss = 2.59799 (* 1 = 2.59799 loss)
I1226 07:03:46.053834 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 3
I1226 07:03:46.199401 51587 solver.cpp:300] [5] PROFILING END[Forward] Iteration 2
I1226 07:03:46.199487 51587 solver.cpp:305] [5] PROFILING BEGIN[Other] Iteration 2
I1226 07:03:46.199527 51587 solver.cpp:306] [5] Iteration 2, loss = 3.38332
I1226 07:03:46.199594 51587 solver.cpp:309] [5] PROFILING END[Other] Iteration 2
I1226 07:03:46.199631 51587 solver.cpp:333]     Train net output #0: accuracy = 0.296875
I1226 07:03:46.199698 51587 solver.cpp:333]     Train net output #1: loss = 3.38332 (* 1 = 3.38332 loss)
I1226 07:03:46.199779 51587 solver.cpp:298] [5] PROFILING BEGIN[Forward] Iteration 3
I1226 07:03:46.253255 88126 solver.cpp:300] [6] PROFILING END[Forward] Iteration 2
I1226 07:03:46.253351 88126 solver.cpp:305] [6] PROFILING BEGIN[Other] Iteration 2
I1226 07:03:46.253408 88126 solver.cpp:306] [6] Iteration 2, loss = 2.84072
I1226 07:03:46.253481 88126 solver.cpp:309] [6] PROFILING END[Other] Iteration 2
I1226 07:03:46.253526 88126 solver.cpp:333]     Train net output #0: accuracy = 0.28125
I1226 07:03:46.253782 88126 solver.cpp:333]     Train net output #1: loss = 2.84072 (* 1 = 2.84072 loss)
I1226 07:03:46.253847 88126 solver.cpp:298] [6] PROFILING BEGIN[Forward] Iteration 3
I1226 07:03:47.150380 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 3
I1226 07:03:47.150465 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 3
I1226 07:03:47.150509 90546 solver.cpp:306] [0] Iteration 3, loss = 3.24445
I1226 07:03:47.150578 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 3
I1226 07:03:47.150626 90546 solver.cpp:333]     Train net output #0: accuracy = 0.328125
I1226 07:03:47.150705 90546 solver.cpp:333]     Train net output #1: loss = 3.24445 (* 1 = 3.24445 loss)
I1226 07:03:47.150867 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 4
I1226 07:03:47.618363 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 3
I1226 07:03:47.618444 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 3
I1226 07:03:47.618484 89377 solver.cpp:306] [1] Iteration 3, loss = 3.94601
I1226 07:03:47.618556 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 3
I1226 07:03:47.618604 89377 solver.cpp:333]     Train net output #0: accuracy = 0.171875
I1226 07:03:47.618671 89377 solver.cpp:333]     Train net output #1: loss = 3.94601 (* 1 = 3.94601 loss)
I1226 07:03:47.618729 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 4
I1226 07:03:47.681372 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 3
I1226 07:03:47.681458 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 3
I1226 07:03:47.681535 89451 solver.cpp:306] [2] Iteration 3, loss = 2.92093
I1226 07:03:47.681609 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 3
I1226 07:03:47.681654 89451 solver.cpp:333]     Train net output #0: accuracy = 0.390625
I1226 07:03:47.681741 89451 solver.cpp:333]     Train net output #1: loss = 2.92093 (* 1 = 2.92093 loss)
I1226 07:03:47.681849 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 4
I1226 07:03:47.689435 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 3
I1226 07:03:47.689539 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 3
I1226 07:03:47.689652 89170 solver.cpp:306] [3] Iteration 3, loss = 2.63634
I1226 07:03:47.689741 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 3
I1226 07:03:47.689806 89170 solver.cpp:333]     Train net output #0: accuracy = 0.453125
I1226 07:03:47.689893 89170 solver.cpp:333]     Train net output #1: loss = 2.63634 (* 1 = 2.63634 loss)
I1226 07:03:47.689965 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 4
I1226 07:03:48.123778 93507 solver.cpp:300] [7] PROFILING END[Forward] Iteration 2
I1226 07:03:48.123910 93507 solver.cpp:305] [7] PROFILING BEGIN[Other] Iteration 2
I1226 07:03:48.123958 93507 solver.cpp:306] [7] Iteration 2, loss = 3.28898
I1226 07:03:48.124032 93507 solver.cpp:309] [7] PROFILING END[Other] Iteration 2
I1226 07:03:48.124079 93507 solver.cpp:333]     Train net output #0: accuracy = 0.28125
I1226 07:03:48.124164 93507 solver.cpp:333]     Train net output #1: loss = 3.28898 (* 1 = 3.28898 loss)
I1226 07:03:48.124238 93507 solver.cpp:298] [7] PROFILING BEGIN[Forward] Iteration 3
I1226 07:03:48.480295 89165 solver.cpp:300] [4] PROFILING END[Forward] Iteration 3
I1226 07:03:48.480378 89165 solver.cpp:305] [4] PROFILING BEGIN[Other] Iteration 3
I1226 07:03:48.480418 89165 solver.cpp:306] [4] Iteration 3, loss = 3.26279
I1226 07:03:48.480484 89165 solver.cpp:309] [4] PROFILING END[Other] Iteration 3
I1226 07:03:48.480523 89165 solver.cpp:333]     Train net output #0: accuracy = 0.265625
I1226 07:03:48.480592 89165 solver.cpp:333]     Train net output #1: loss = 3.26279 (* 1 = 3.26279 loss)
I1226 07:03:48.480695 89165 solver.cpp:298] [4] PROFILING BEGIN[Forward] Iteration 4
I1226 07:03:48.721987 51587 solver.cpp:300] [5] PROFILING END[Forward] Iteration 3
I1226 07:03:48.722067 51587 solver.cpp:305] [5] PROFILING BEGIN[Other] Iteration 3
I1226 07:03:48.722172 51587 solver.cpp:306] [5] Iteration 3, loss = 3.32325
I1226 07:03:48.722239 51587 solver.cpp:309] [5] PROFILING END[Other] Iteration 3
I1226 07:03:48.722285 51587 solver.cpp:333]     Train net output #0: accuracy = 0.296875
I1226 07:03:48.722358 51587 solver.cpp:333]     Train net output #1: loss = 3.32325 (* 1 = 3.32325 loss)
I1226 07:03:48.722465 51587 solver.cpp:298] [5] PROFILING BEGIN[Forward] Iteration 4
I1226 07:03:48.774301 88126 solver.cpp:300] [6] PROFILING END[Forward] Iteration 3
I1226 07:03:48.774392 88126 solver.cpp:305] [6] PROFILING BEGIN[Other] Iteration 3
I1226 07:03:48.774442 88126 solver.cpp:306] [6] Iteration 3, loss = 3.27373
I1226 07:03:48.774523 88126 solver.cpp:309] [6] PROFILING END[Other] Iteration 3
I1226 07:03:48.774567 88126 solver.cpp:333]     Train net output #0: accuracy = 0.3125
I1226 07:03:48.774665 88126 solver.cpp:333]     Train net output #1: loss = 3.27373 (* 1 = 3.27373 loss)
I1226 07:03:48.774736 88126 solver.cpp:298] [6] PROFILING BEGIN[Forward] Iteration 4
I1226 07:03:48.789250 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 4
I1226 07:03:48.789335 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 4
I1226 07:03:48.789373 90546 solver.cpp:306] [0] Iteration 4, loss = 3.67379
I1226 07:03:48.789443 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 4
I1226 07:03:48.789491 90546 solver.cpp:333]     Train net output #0: accuracy = 0.3125
I1226 07:03:48.789573 90546 solver.cpp:333]     Train net output #1: loss = 3.67379 (* 1 = 3.67379 loss)
I1226 07:03:48.789652 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 5
I1226 07:03:49.265722 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 4
I1226 07:03:49.265871 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 4
I1226 07:03:49.265915 89377 solver.cpp:306] [1] Iteration 4, loss = 3.51686
I1226 07:03:49.265991 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 4
I1226 07:03:49.266039 89377 solver.cpp:333]     Train net output #0: accuracy = 0.328125
I1226 07:03:49.266110 89377 solver.cpp:333]     Train net output #1: loss = 3.51686 (* 1 = 3.51686 loss)
I1226 07:03:49.266211 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 5
I1226 07:03:49.323145 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 4
I1226 07:03:49.323235 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 4
I1226 07:03:49.323285 89451 solver.cpp:306] [2] Iteration 4, loss = 3.55505
I1226 07:03:49.323357 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 4
I1226 07:03:49.323403 89451 solver.cpp:333]     Train net output #0: accuracy = 0.28125
I1226 07:03:49.323519 89451 solver.cpp:333]     Train net output #1: loss = 3.55505 (* 1 = 3.55505 loss)
I1226 07:03:49.323593 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 5
I1226 07:03:49.346554 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 4
I1226 07:03:49.346642 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 4
I1226 07:03:49.346694 89170 solver.cpp:306] [3] Iteration 4, loss = 3.62135
I1226 07:03:49.346768 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 4
I1226 07:03:49.346814 89170 solver.cpp:333]     Train net output #0: accuracy = 0.21875
I1226 07:03:49.346899 89170 solver.cpp:333]     Train net output #1: loss = 3.62135 (* 1 = 3.62135 loss)
I1226 07:03:49.346968 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 5
I1226 07:03:50.422127 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 5
I1226 07:03:50.422250 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 5
I1226 07:03:50.422294 90546 solver.cpp:306] [0] Iteration 5, loss = 3.4059
I1226 07:03:50.422376 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 5
I1226 07:03:50.422425 90546 solver.cpp:333]     Train net output #0: accuracy = 0.265625
I1226 07:03:50.422505 90546 solver.cpp:333]     Train net output #1: loss = 3.4059 (* 1 = 3.4059 loss)
I1226 07:03:50.422580 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 6
I1226 07:03:50.521669 93507 solver.cpp:300] [7] PROFILING END[Forward] Iteration 3
I1226 07:03:50.521767 93507 solver.cpp:305] [7] PROFILING BEGIN[Other] Iteration 3
I1226 07:03:50.521859 93507 solver.cpp:306] [7] Iteration 3, loss = 3.13831
I1226 07:03:50.521935 93507 solver.cpp:309] [7] PROFILING END[Other] Iteration 3
I1226 07:03:50.521981 93507 solver.cpp:333]     Train net output #0: accuracy = 0.296875
I1226 07:03:50.522066 93507 solver.cpp:333]     Train net output #1: loss = 3.13831 (* 1 = 3.13831 loss)
I1226 07:03:50.522140 93507 solver.cpp:298] [7] PROFILING BEGIN[Forward] Iteration 4
I1226 07:03:50.850291 89165 solver.cpp:300] [4] PROFILING END[Forward] Iteration 4
I1226 07:03:50.850397 89165 solver.cpp:305] [4] PROFILING BEGIN[Other] Iteration 4
I1226 07:03:50.850441 89165 solver.cpp:306] [4] Iteration 4, loss = 3.7005
I1226 07:03:50.850529 89165 solver.cpp:309] [4] PROFILING END[Other] Iteration 4
I1226 07:03:50.850685 89165 solver.cpp:333]     Train net output #0: accuracy = 0.203125
I1226 07:03:50.850777 89165 solver.cpp:333]     Train net output #1: loss = 3.7005 (* 1 = 3.7005 loss)
I1226 07:03:50.850977 89165 solver.cpp:298] [4] PROFILING BEGIN[Forward] Iteration 5
I1226 07:03:50.913782 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 5
I1226 07:03:50.913915 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 5
I1226 07:03:50.913967 89377 solver.cpp:306] [1] Iteration 5, loss = 3.35144
I1226 07:03:50.914041 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 5
I1226 07:03:50.914086 89377 solver.cpp:333]     Train net output #0: accuracy = 0.359375
I1226 07:03:50.914161 89377 solver.cpp:333]     Train net output #1: loss = 3.35144 (* 1 = 3.35144 loss)
I1226 07:03:50.914291 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 6
I1226 07:03:50.973562 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 5
I1226 07:03:50.973657 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 5
I1226 07:03:50.973713 89451 solver.cpp:306] [2] Iteration 5, loss = 3.14386
I1226 07:03:50.973786 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 5
I1226 07:03:50.973831 89451 solver.cpp:333]     Train net output #0: accuracy = 0.3125
I1226 07:03:50.973914 89451 solver.cpp:333]     Train net output #1: loss = 3.14386 (* 1 = 3.14386 loss)
I1226 07:03:50.973994 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 6
I1226 07:03:50.982738 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 5
I1226 07:03:50.982830 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 5
I1226 07:03:50.982879 89170 solver.cpp:306] [3] Iteration 5, loss = 3.0987
I1226 07:03:50.982964 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 5
I1226 07:03:50.983009 89170 solver.cpp:333]     Train net output #0: accuracy = 0.328125
I1226 07:03:50.983095 89170 solver.cpp:333]     Train net output #1: loss = 3.0987 (* 1 = 3.0987 loss)
I1226 07:03:50.983194 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 6
I1226 07:03:51.105358 51587 solver.cpp:300] [5] PROFILING END[Forward] Iteration 4
I1226 07:03:51.105448 51587 solver.cpp:305] [5] PROFILING BEGIN[Other] Iteration 4
I1226 07:03:51.105486 51587 solver.cpp:306] [5] Iteration 4, loss = 2.98025
I1226 07:03:51.105557 51587 solver.cpp:309] [5] PROFILING END[Other] Iteration 4
I1226 07:03:51.105595 51587 solver.cpp:333]     Train net output #0: accuracy = 0.359375
I1226 07:03:51.105672 51587 solver.cpp:333]     Train net output #1: loss = 2.98025 (* 1 = 2.98025 loss)
I1226 07:03:51.105753 51587 solver.cpp:298] [5] PROFILING BEGIN[Forward] Iteration 5
I1226 07:03:51.157230 88126 solver.cpp:300] [6] PROFILING END[Forward] Iteration 4
I1226 07:03:51.157321 88126 solver.cpp:305] [6] PROFILING BEGIN[Other] Iteration 4
I1226 07:03:51.157372 88126 solver.cpp:306] [6] Iteration 4, loss = 3.42754
I1226 07:03:51.157449 88126 solver.cpp:309] [6] PROFILING END[Other] Iteration 4
I1226 07:03:51.157496 88126 solver.cpp:333]     Train net output #0: accuracy = 0.265625
I1226 07:03:51.157750 88126 solver.cpp:333]     Train net output #1: loss = 3.42754 (* 1 = 3.42754 loss)
I1226 07:03:51.157829 88126 solver.cpp:298] [6] PROFILING BEGIN[Forward] Iteration 5
I1226 07:03:52.087456 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 6
I1226 07:03:52.087549 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 6
I1226 07:03:52.087657 90546 solver.cpp:306] [0] Iteration 6, loss = 2.71974
I1226 07:03:52.087736 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 6
I1226 07:03:52.087785 90546 solver.cpp:333]     Train net output #0: accuracy = 0.359375
I1226 07:03:52.087867 90546 solver.cpp:333]     Train net output #1: loss = 2.71974 (* 1 = 2.71974 loss)
I1226 07:03:52.087946 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 7
I1226 07:03:52.555963 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 6
I1226 07:03:52.556044 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 6
I1226 07:03:52.556084 89377 solver.cpp:306] [1] Iteration 6, loss = 3.52141
I1226 07:03:52.556149 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 6
I1226 07:03:52.556187 89377 solver.cpp:333]     Train net output #0: accuracy = 0.265625
I1226 07:03:52.556259 89377 solver.cpp:333]     Train net output #1: loss = 3.52141 (* 1 = 3.52141 loss)
I1226 07:03:52.556344 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 7
I1226 07:03:52.610507 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 6
I1226 07:03:52.610597 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 6
I1226 07:03:52.610646 89451 solver.cpp:306] [2] Iteration 6, loss = 3.55295
I1226 07:03:52.610721 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 6
I1226 07:03:52.610767 89451 solver.cpp:333]     Train net output #0: accuracy = 0.296875
I1226 07:03:52.610849 89451 solver.cpp:333]     Train net output #1: loss = 3.55295 (* 1 = 3.55295 loss)
I1226 07:03:52.610939 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 7
I1226 07:03:52.634059 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 6
I1226 07:03:52.634150 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 6
I1226 07:03:52.634202 89170 solver.cpp:306] [3] Iteration 6, loss = 2.70283
I1226 07:03:52.634307 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 6
I1226 07:03:52.634354 89170 solver.cpp:333]     Train net output #0: accuracy = 0.375
I1226 07:03:52.634436 89170 solver.cpp:333]     Train net output #1: loss = 2.70283 (* 1 = 2.70283 loss)
I1226 07:03:52.634518 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 7
I1226 07:03:52.892912 93507 solver.cpp:300] [7] PROFILING END[Forward] Iteration 4
I1226 07:03:52.894201 93507 solver.cpp:305] [7] PROFILING BEGIN[Other] Iteration 4
I1226 07:03:52.894266 93507 solver.cpp:306] [7] Iteration 4, loss = 3.39402
I1226 07:03:52.894350 93507 solver.cpp:309] [7] PROFILING END[Other] Iteration 4
I1226 07:03:52.894405 93507 solver.cpp:333]     Train net output #0: accuracy = 0.375
I1226 07:03:52.894487 93507 solver.cpp:333]     Train net output #1: loss = 3.39402 (* 1 = 3.39402 loss)
I1226 07:03:52.894558 93507 solver.cpp:298] [7] PROFILING BEGIN[Forward] Iteration 5
I1226 07:03:53.219482 89165 solver.cpp:300] [4] PROFILING END[Forward] Iteration 5
I1226 07:03:53.219563 89165 solver.cpp:305] [4] PROFILING BEGIN[Other] Iteration 5
I1226 07:03:53.219647 89165 solver.cpp:306] [4] Iteration 5, loss = 2.55724
I1226 07:03:53.219712 89165 solver.cpp:309] [4] PROFILING END[Other] Iteration 5
I1226 07:03:53.219761 89165 solver.cpp:333]     Train net output #0: accuracy = 0.34375
I1226 07:03:53.219833 89165 solver.cpp:333]     Train net output #1: loss = 2.55724 (* 1 = 2.55724 loss)
I1226 07:03:53.219902 89165 solver.cpp:298] [4] PROFILING BEGIN[Forward] Iteration 6
I1226 07:03:53.473392 51587 solver.cpp:300] [5] PROFILING END[Forward] Iteration 5
I1226 07:03:53.473476 51587 solver.cpp:305] [5] PROFILING BEGIN[Other] Iteration 5
I1226 07:03:53.473517 51587 solver.cpp:306] [5] Iteration 5, loss = 2.85498
I1226 07:03:53.473582 51587 solver.cpp:309] [5] PROFILING END[Other] Iteration 5
I1226 07:03:53.473635 51587 solver.cpp:333]     Train net output #0: accuracy = 0.375
I1226 07:03:53.473702 51587 solver.cpp:333]     Train net output #1: loss = 2.85498 (* 1 = 2.85498 loss)
I1226 07:03:53.473767 51587 solver.cpp:298] [5] PROFILING BEGIN[Forward] Iteration 6
I1226 07:03:53.529695 88126 solver.cpp:300] [6] PROFILING END[Forward] Iteration 5
I1226 07:03:53.529788 88126 solver.cpp:305] [6] PROFILING BEGIN[Other] Iteration 5
I1226 07:03:53.529835 88126 solver.cpp:306] [6] Iteration 5, loss = 3.50914
I1226 07:03:53.529909 88126 solver.cpp:309] [6] PROFILING END[Other] Iteration 5
I1226 07:03:53.529956 88126 solver.cpp:333]     Train net output #0: accuracy = 0.203125
I1226 07:03:53.530035 88126 solver.cpp:333]     Train net output #1: loss = 3.50914 (* 1 = 3.50914 loss)
I1226 07:03:53.530110 88126 solver.cpp:298] [6] PROFILING BEGIN[Forward] Iteration 6
I1226 07:03:53.711630 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 7
I1226 07:03:53.711796 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 7
I1226 07:03:53.711879 90546 solver.cpp:306] [0] Iteration 7, loss = 3.17267
I1226 07:03:53.711961 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 7
I1226 07:03:53.712009 90546 solver.cpp:333]     Train net output #0: accuracy = 0.296875
I1226 07:03:53.712090 90546 solver.cpp:333]     Train net output #1: loss = 3.17267 (* 1 = 3.17267 loss)
I1226 07:03:53.712229 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 8
I1226 07:03:54.187137 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 7
I1226 07:03:54.187233 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 7
I1226 07:03:54.187283 89377 solver.cpp:306] [1] Iteration 7, loss = 3.02319
I1226 07:03:54.187495 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 7
I1226 07:03:54.187549 89377 solver.cpp:333]     Train net output #0: accuracy = 0.359375
I1226 07:03:54.187628 89377 solver.cpp:333]     Train net output #1: loss = 3.02319 (* 1 = 3.02319 loss)
I1226 07:03:54.187695 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 8
I1226 07:03:54.246812 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 7
I1226 07:03:54.246906 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 7
I1226 07:03:54.246958 89451 solver.cpp:306] [2] Iteration 7, loss = 2.80332
I1226 07:03:54.247159 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 7
I1226 07:03:54.247211 89451 solver.cpp:333]     Train net output #0: accuracy = 0.375
I1226 07:03:54.247287 89451 solver.cpp:333]     Train net output #1: loss = 2.80332 (* 1 = 2.80332 loss)
I1226 07:03:54.247371 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 8
I1226 07:03:54.251477 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 7
I1226 07:03:54.251569 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 7
I1226 07:03:54.251649 89170 solver.cpp:306] [3] Iteration 7, loss = 3.54237
I1226 07:03:54.251823 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 7
I1226 07:03:54.251871 89170 solver.cpp:333]     Train net output #0: accuracy = 0.3125
I1226 07:03:54.251956 89170 solver.cpp:333]     Train net output #1: loss = 3.54237 (* 1 = 3.54237 loss)
I1226 07:03:54.252075 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 8
I1226 07:03:55.283062 93507 solver.cpp:300] [7] PROFILING END[Forward] Iteration 5
I1226 07:03:55.283159 93507 solver.cpp:305] [7] PROFILING BEGIN[Other] Iteration 5
I1226 07:03:55.283205 93507 solver.cpp:306] [7] Iteration 5, loss = 2.78378
I1226 07:03:55.283280 93507 solver.cpp:309] [7] PROFILING END[Other] Iteration 5
I1226 07:03:55.283326 93507 solver.cpp:333]     Train net output #0: accuracy = 0.40625
I1226 07:03:55.283417 93507 solver.cpp:333]     Train net output #1: loss = 2.78378 (* 1 = 2.78378 loss)
I1226 07:03:55.283481 93507 solver.cpp:298] [7] PROFILING BEGIN[Forward] Iteration 6
I1226 07:03:55.497025 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 8
I1226 07:03:55.497104 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 8
I1226 07:03:55.497143 90546 solver.cpp:306] [0] Iteration 8, loss = 3.11477
I1226 07:03:55.497238 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 8
I1226 07:03:55.497287 90546 solver.cpp:333]     Train net output #0: accuracy = 0.234375
I1226 07:03:55.497367 90546 solver.cpp:333]     Train net output #1: loss = 3.11477 (* 1 = 3.11477 loss)
I1226 07:03:55.497442 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 9
I1226 07:03:55.588840 89165 solver.cpp:300] [4] PROFILING END[Forward] Iteration 6
I1226 07:03:55.588989 89165 solver.cpp:305] [4] PROFILING BEGIN[Other] Iteration 6
I1226 07:03:55.589087 89165 solver.cpp:306] [4] Iteration 6, loss = 3.36123
I1226 07:03:55.589174 89165 solver.cpp:309] [4] PROFILING END[Other] Iteration 6
I1226 07:03:55.589213 89165 solver.cpp:333]     Train net output #0: accuracy = 0.359375
I1226 07:03:55.589300 89165 solver.cpp:333]     Train net output #1: loss = 3.36123 (* 1 = 3.36123 loss)
I1226 07:03:55.589351 89165 solver.cpp:298] [4] PROFILING BEGIN[Forward] Iteration 7
I1226 07:03:55.911945 51587 solver.cpp:300] [5] PROFILING END[Forward] Iteration 6
I1226 07:03:55.912027 51587 solver.cpp:305] [5] PROFILING BEGIN[Other] Iteration 6
I1226 07:03:55.912096 51587 solver.cpp:306] [5] Iteration 6, loss = 3.47329
I1226 07:03:55.912195 51587 solver.cpp:309] [5] PROFILING END[Other] Iteration 6
I1226 07:03:55.912235 51587 solver.cpp:333]     Train net output #0: accuracy = 0.265625
I1226 07:03:55.912302 51587 solver.cpp:333]     Train net output #1: loss = 3.47329 (* 1 = 3.47329 loss)
I1226 07:03:55.912425 51587 solver.cpp:298] [5] PROFILING BEGIN[Forward] Iteration 7
I1226 07:03:55.965400 88126 solver.cpp:300] [6] PROFILING END[Forward] Iteration 6
I1226 07:03:55.965490 88126 solver.cpp:305] [6] PROFILING BEGIN[Other] Iteration 6
I1226 07:03:55.965543 88126 solver.cpp:306] [6] Iteration 6, loss = 2.80838
I1226 07:03:55.965669 88126 solver.cpp:309] [6] PROFILING END[Other] Iteration 6
I1226 07:03:55.965723 88126 solver.cpp:333]     Train net output #0: accuracy = 0.359375
I1226 07:03:55.965808 88126 solver.cpp:333]     Train net output #1: loss = 2.80838 (* 1 = 2.80838 loss)
I1226 07:03:55.965875 88126 solver.cpp:298] [6] PROFILING BEGIN[Forward] Iteration 7
I1226 07:03:55.987082 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 8
I1226 07:03:55.987174 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 8
I1226 07:03:55.987224 89377 solver.cpp:306] [1] Iteration 8, loss = 2.97284
I1226 07:03:55.987300 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 8
I1226 07:03:55.987347 89377 solver.cpp:333]     Train net output #0: accuracy = 0.328125
I1226 07:03:55.987431 89377 solver.cpp:333]     Train net output #1: loss = 2.97284 (* 1 = 2.97284 loss)
I1226 07:03:55.987504 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 9
I1226 07:03:56.054204 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 8
I1226 07:03:56.054294 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 8
I1226 07:03:56.054342 89451 solver.cpp:306] [2] Iteration 8, loss = 3.70197
I1226 07:03:56.054445 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 8
I1226 07:03:56.054527 89451 solver.cpp:333]     Train net output #0: accuracy = 0.203125
I1226 07:03:56.054605 89451 solver.cpp:333]     Train net output #1: loss = 3.70197 (* 1 = 3.70197 loss)
I1226 07:03:56.054697 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 9
I1226 07:03:56.056901 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 8
I1226 07:03:56.056995 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 8
I1226 07:03:56.057052 89170 solver.cpp:306] [3] Iteration 8, loss = 3.35766
I1226 07:03:56.057132 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 8
I1226 07:03:56.057179 89170 solver.cpp:333]     Train net output #0: accuracy = 0.296875
I1226 07:03:56.057397 89170 solver.cpp:333]     Train net output #1: loss = 3.35766 (* 1 = 3.35766 loss)
I1226 07:03:56.057483 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 9
I1226 07:03:57.157498 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 9
I1226 07:03:57.157578 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 9
I1226 07:03:57.157616 90546 solver.cpp:306] [0] Iteration 9, loss = 4.20764
I1226 07:03:57.157683 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 9
I1226 07:03:57.157732 90546 solver.cpp:333]     Train net output #0: accuracy = 0.21875
I1226 07:03:57.157811 90546 solver.cpp:333]     Train net output #1: loss = 4.20764 (* 1 = 4.20764 loss)
I1226 07:03:57.157958 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 10
I1226 07:03:57.647353 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 9
I1226 07:03:57.647436 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 9
I1226 07:03:57.647475 89377 solver.cpp:306] [1] Iteration 9, loss = 3.67806
I1226 07:03:57.647547 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 9
I1226 07:03:57.647732 89377 solver.cpp:333]     Train net output #0: accuracy = 0.296875
I1226 07:03:57.647802 89377 solver.cpp:333]     Train net output #1: loss = 3.67806 (* 1 = 3.67806 loss)
I1226 07:03:57.647891 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 10
I1226 07:03:57.689504 93507 solver.cpp:300] [7] PROFILING END[Forward] Iteration 6
I1226 07:03:57.689599 93507 solver.cpp:305] [7] PROFILING BEGIN[Other] Iteration 6
I1226 07:03:57.689648 93507 solver.cpp:306] [7] Iteration 6, loss = 2.92102
I1226 07:03:57.689723 93507 solver.cpp:309] [7] PROFILING END[Other] Iteration 6
I1226 07:03:57.689767 93507 solver.cpp:333]     Train net output #0: accuracy = 0.40625
I1226 07:03:57.697260 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 9
I1226 07:03:57.689878 93507 solver.cpp:333]     Train net output #1: loss = 2.92102 (* 1 = 2.92102 loss)
I1226 07:03:57.689944 93507 solver.cpp:298] [7] PROFILING BEGIN[Forward] Iteration 7
I1226 07:03:57.697353 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 9
I1226 07:03:57.697401 89451 solver.cpp:306] [2] Iteration 9, loss = 3.12528
I1226 07:03:57.697505 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 9
I1226 07:03:57.697554 89451 solver.cpp:333]     Train net output #0: accuracy = 0.359375
I1226 07:03:57.697636 89451 solver.cpp:333]     Train net output #1: loss = 3.12528 (* 1 = 3.12528 loss)
I1226 07:03:57.697783 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 10
I1226 07:03:57.724081 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 9
I1226 07:03:57.724181 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 9
I1226 07:03:57.724267 89170 solver.cpp:306] [3] Iteration 9, loss = 3.33523
I1226 07:03:57.724342 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 9
I1226 07:03:57.724390 89170 solver.cpp:333]     Train net output #0: accuracy = 0.3125
I1226 07:03:57.724472 89170 solver.cpp:333]     Train net output #1: loss = 3.33523 (* 1 = 3.33523 loss)
I1226 07:03:57.724542 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 10
I1226 07:03:58.017770 89165 solver.cpp:300] [4] PROFILING END[Forward] Iteration 7
I1226 07:03:58.017936 89165 solver.cpp:305] [4] PROFILING BEGIN[Other] Iteration 7
I1226 07:03:58.017984 89165 solver.cpp:306] [4] Iteration 7, loss = 3.66406
I1226 07:03:58.018100 89165 solver.cpp:309] [4] PROFILING END[Other] Iteration 7
I1226 07:03:58.018141 89165 solver.cpp:333]     Train net output #0: accuracy = 0.234375
I1226 07:03:58.018218 89165 solver.cpp:333]     Train net output #1: loss = 3.66406 (* 1 = 3.66406 loss)
I1226 07:03:58.018327 89165 solver.cpp:298] [4] PROFILING BEGIN[Forward] Iteration 8
I1226 07:03:58.265689 51587 solver.cpp:300] [5] PROFILING END[Forward] Iteration 7
I1226 07:03:58.265776 51587 solver.cpp:305] [5] PROFILING BEGIN[Other] Iteration 7
I1226 07:03:58.265820 51587 solver.cpp:306] [5] Iteration 7, loss = 3.25135
I1226 07:03:58.265974 51587 solver.cpp:309] [5] PROFILING END[Other] Iteration 7
I1226 07:03:58.266014 51587 solver.cpp:333]     Train net output #0: accuracy = 0.3125
I1226 07:03:58.266093 51587 solver.cpp:333]     Train net output #1: loss = 3.25135 (* 1 = 3.25135 loss)
I1226 07:03:58.266229 51587 solver.cpp:298] [5] PROFILING BEGIN[Forward] Iteration 8
I1226 07:03:58.320327 88126 solver.cpp:300] [6] PROFILING END[Forward] Iteration 7
I1226 07:03:58.320441 88126 solver.cpp:305] [6] PROFILING BEGIN[Other] Iteration 7
I1226 07:03:58.320538 88126 solver.cpp:306] [6] Iteration 7, loss = 2.90005
I1226 07:03:58.320760 88126 solver.cpp:309] [6] PROFILING END[Other] Iteration 7
I1226 07:03:58.320812 88126 solver.cpp:333]     Train net output #0: accuracy = 0.359375
I1226 07:03:58.320901 88126 solver.cpp:333]     Train net output #1: loss = 2.90005 (* 1 = 2.90005 loss)
I1226 07:03:58.321033 88126 solver.cpp:298] [6] PROFILING BEGIN[Forward] Iteration 8
I1226 07:03:58.814677 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 10
I1226 07:03:58.814764 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 10
I1226 07:03:58.814802 90546 solver.cpp:306] [0] Iteration 10, loss = 2.99819
I1226 07:03:58.814875 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 10
I1226 07:03:58.814924 90546 solver.cpp:333]     Train net output #0: accuracy = 0.359375
I1226 07:03:58.815002 90546 solver.cpp:333]     Train net output #1: loss = 2.99819 (* 1 = 2.99819 loss)
I1226 07:03:58.815071 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 11
I1226 07:03:59.292321 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 10
I1226 07:03:59.292407 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 10
I1226 07:03:59.292451 89377 solver.cpp:306] [1] Iteration 10, loss = 3.73317
I1226 07:03:59.292517 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 10
I1226 07:03:59.292570 89377 solver.cpp:333]     Train net output #0: accuracy = 0.234375
I1226 07:03:59.292637 89377 solver.cpp:333]     Train net output #1: loss = 3.73317 (* 1 = 3.73317 loss)
I1226 07:03:59.292698 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 11
I1226 07:03:59.341450 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 10
I1226 07:03:59.341562 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 10
I1226 07:03:59.341612 89451 solver.cpp:306] [2] Iteration 10, loss = 3.35692
I1226 07:03:59.341686 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 10
I1226 07:03:59.341730 89451 solver.cpp:333]     Train net output #0: accuracy = 0.328125
I1226 07:03:59.341943 89451 solver.cpp:333]     Train net output #1: loss = 3.35692 (* 1 = 3.35692 loss)
I1226 07:03:59.342025 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 11
I1226 07:03:59.370354 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 10
I1226 07:03:59.370450 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 10
I1226 07:03:59.370509 89170 solver.cpp:306] [3] Iteration 10, loss = 3.34076
I1226 07:03:59.370587 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 10
I1226 07:03:59.370635 89170 solver.cpp:333]     Train net output #0: accuracy = 0.390625
I1226 07:03:59.370718 89170 solver.cpp:333]     Train net output #1: loss = 3.34076 (* 1 = 3.34076 loss)
I1226 07:03:59.370782 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 11
I1226 07:04:00.060431 93507 solver.cpp:300] [7] PROFILING END[Forward] Iteration 7
I1226 07:04:00.060547 93507 solver.cpp:305] [7] PROFILING BEGIN[Other] Iteration 7
I1226 07:04:00.060597 93507 solver.cpp:306] [7] Iteration 7, loss = 3.26583
I1226 07:04:00.060701 93507 solver.cpp:309] [7] PROFILING END[Other] Iteration 7
I1226 07:04:00.060922 93507 solver.cpp:333]     Train net output #0: accuracy = 0.28125
I1226 07:04:00.061000 93507 solver.cpp:333]     Train net output #1: loss = 3.26583 (* 1 = 3.26583 loss)
I1226 07:04:00.061098 93507 solver.cpp:298] [7] PROFILING BEGIN[Forward] Iteration 8
I1226 07:04:00.494005 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 11
I1226 07:04:00.494103 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 11
I1226 07:04:00.494158 90546 solver.cpp:306] [0] Iteration 11, loss = 3.83974
I1226 07:04:00.494232 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 11
I1226 07:04:00.494262 90546 solver.cpp:333]     Train net output #0: accuracy = 0.296875
I1226 07:04:00.494316 90546 solver.cpp:333]     Train net output #1: loss = 3.83974 (* 1 = 3.83974 loss)
I1226 07:04:00.494405 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 12
I1226 07:04:00.507864 89165 solver.cpp:300] [4] PROFILING END[Forward] Iteration 8
I1226 07:04:00.508005 89165 solver.cpp:305] [4] PROFILING BEGIN[Other] Iteration 8
I1226 07:04:00.508051 89165 solver.cpp:306] [4] Iteration 8, loss = 2.95215
I1226 07:04:00.508147 89165 solver.cpp:309] [4] PROFILING END[Other] Iteration 8
I1226 07:04:00.508185 89165 solver.cpp:333]     Train net output #0: accuracy = 0.375
I1226 07:04:00.508436 89165 solver.cpp:333]     Train net output #1: loss = 2.95215 (* 1 = 2.95215 loss)
I1226 07:04:00.508496 89165 solver.cpp:298] [4] PROFILING BEGIN[Forward] Iteration 9
I1226 07:04:00.702343 51587 solver.cpp:300] [5] PROFILING END[Forward] Iteration 8
I1226 07:04:00.702427 51587 solver.cpp:305] [5] PROFILING BEGIN[Other] Iteration 8
I1226 07:04:00.702469 51587 solver.cpp:306] [5] Iteration 8, loss = 2.96532
I1226 07:04:00.702534 51587 solver.cpp:309] [5] PROFILING END[Other] Iteration 8
I1226 07:04:00.702574 51587 solver.cpp:333]     Train net output #0: accuracy = 0.390625
I1226 07:04:00.702647 51587 solver.cpp:333]     Train net output #1: loss = 2.96532 (* 1 = 2.96532 loss)
I1226 07:04:00.702713 51587 solver.cpp:298] [5] PROFILING BEGIN[Forward] Iteration 9
I1226 07:04:00.759376 88126 solver.cpp:300] [6] PROFILING END[Forward] Iteration 8
I1226 07:04:00.759467 88126 solver.cpp:305] [6] PROFILING BEGIN[Other] Iteration 8
I1226 07:04:00.759516 88126 solver.cpp:306] [6] Iteration 8, loss = 3.65413
I1226 07:04:00.759627 88126 solver.cpp:309] [6] PROFILING END[Other] Iteration 8
I1226 07:04:00.759676 88126 solver.cpp:333]     Train net output #0: accuracy = 0.265625
I1226 07:04:00.759760 88126 solver.cpp:333]     Train net output #1: loss = 3.65413 (* 1 = 3.65413 loss)
I1226 07:04:00.759846 88126 solver.cpp:298] [6] PROFILING BEGIN[Forward] Iteration 9
I1226 07:04:00.937705 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 11
I1226 07:04:00.937804 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 11
I1226 07:04:00.937876 89377 solver.cpp:306] [1] Iteration 11, loss = 3.63832
I1226 07:04:00.937973 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 11
I1226 07:04:00.938017 89377 solver.cpp:333]     Train net output #0: accuracy = 0.25
I1226 07:04:00.938092 89377 solver.cpp:333]     Train net output #1: loss = 3.63832 (* 1 = 3.63832 loss)
I1226 07:04:00.938154 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 12
I1226 07:04:01.010905 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 11
I1226 07:04:01.010994 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 11
I1226 07:04:01.011044 89170 solver.cpp:306] [3] Iteration 11, loss = 3.33858
I1226 07:04:01.011189 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 11
I1226 07:04:01.011392 89170 solver.cpp:333]     Train net output #0: accuracy = 0.34375
I1226 07:04:01.011652 89170 solver.cpp:333]     Train net output #1: loss = 3.33858 (* 1 = 3.33858 loss)
I1226 07:04:01.011808 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 12
I1226 07:04:01.024132 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 11
I1226 07:04:01.024217 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 11
I1226 07:04:01.024266 89451 solver.cpp:306] [2] Iteration 11, loss = 3.01628
I1226 07:04:01.024346 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 11
I1226 07:04:01.024394 89451 solver.cpp:333]     Train net output #0: accuracy = 0.328125
I1226 07:04:01.024505 89451 solver.cpp:333]     Train net output #1: loss = 3.01628 (* 1 = 3.01628 loss)
I1226 07:04:01.024646 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 12
I1226 07:04:02.099622 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 12
I1226 07:04:02.099704 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 12
I1226 07:04:02.099736 90546 solver.cpp:306] [0] Iteration 12, loss = 3.15636
I1226 07:04:02.099812 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 12
I1226 07:04:02.099843 90546 solver.cpp:333]     Train net output #0: accuracy = 0.3125
I1226 07:04:02.099892 90546 solver.cpp:333]     Train net output #1: loss = 3.15636 (* 1 = 3.15636 loss)
I1226 07:04:02.099968 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 13
I1226 07:04:02.452337 93507 solver.cpp:300] [7] PROFILING END[Forward] Iteration 8
I1226 07:04:02.452435 93507 solver.cpp:305] [7] PROFILING BEGIN[Other] Iteration 8
I1226 07:04:02.452482 93507 solver.cpp:306] [7] Iteration 8, loss = 3.15311
I1226 07:04:02.452559 93507 solver.cpp:309] [7] PROFILING END[Other] Iteration 8
I1226 07:04:02.452606 93507 solver.cpp:333]     Train net output #0: accuracy = 0.3125
I1226 07:04:02.452693 93507 solver.cpp:333]     Train net output #1: loss = 3.15311 (* 1 = 3.15311 loss)
I1226 07:04:02.452767 93507 solver.cpp:298] [7] PROFILING BEGIN[Forward] Iteration 9
I1226 07:04:02.567392 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 12
I1226 07:04:02.567483 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 12
I1226 07:04:02.567524 89377 solver.cpp:306] [1] Iteration 12, loss = 2.858
I1226 07:04:02.567632 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 12
I1226 07:04:02.567677 89377 solver.cpp:333]     Train net output #0: accuracy = 0.421875
I1226 07:04:02.567751 89377 solver.cpp:333]     Train net output #1: loss = 2.858 (* 1 = 2.858 loss)
I1226 07:04:02.567854 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 13
I1226 07:04:02.624971 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 12
I1226 07:04:02.625061 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 12
I1226 07:04:02.625108 89451 solver.cpp:306] [2] Iteration 12, loss = 3.46168
I1226 07:04:02.625186 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 12
I1226 07:04:02.625231 89451 solver.cpp:333]     Train net output #0: accuracy = 0.28125
I1226 07:04:02.625316 89451 solver.cpp:333]     Train net output #1: loss = 3.46168 (* 1 = 3.46168 loss)
I1226 07:04:02.625402 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 13
I1226 07:04:02.645035 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 12
I1226 07:04:02.645131 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 12
I1226 07:04:02.645182 89170 solver.cpp:306] [3] Iteration 12, loss = 3.79357
I1226 07:04:02.645285 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 12
I1226 07:04:02.645339 89170 solver.cpp:333]     Train net output #0: accuracy = 0.234375
I1226 07:04:02.645421 89170 solver.cpp:333]     Train net output #1: loss = 3.79357 (* 1 = 3.79357 loss)
I1226 07:04:02.645494 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 13
I1226 07:04:02.768824 89165 solver.cpp:300] [4] PROFILING END[Forward] Iteration 9
I1226 07:04:02.768911 89165 solver.cpp:305] [4] PROFILING BEGIN[Other] Iteration 9
I1226 07:04:02.768950 89165 solver.cpp:306] [4] Iteration 9, loss = 2.82701
I1226 07:04:02.769013 89165 solver.cpp:309] [4] PROFILING END[Other] Iteration 9
I1226 07:04:02.769052 89165 solver.cpp:333]     Train net output #0: accuracy = 0.3125
I1226 07:04:02.769129 89165 solver.cpp:333]     Train net output #1: loss = 2.82701 (* 1 = 2.82701 loss)
I1226 07:04:02.769218 89165 solver.cpp:298] [4] PROFILING BEGIN[Forward] Iteration 10
I1226 07:04:03.015733 51587 solver.cpp:300] [5] PROFILING END[Forward] Iteration 9
I1226 07:04:03.015813 51587 solver.cpp:305] [5] PROFILING BEGIN[Other] Iteration 9
I1226 07:04:03.015879 51587 solver.cpp:306] [5] Iteration 9, loss = 3.23603
I1226 07:04:03.015949 51587 solver.cpp:309] [5] PROFILING END[Other] Iteration 9
I1226 07:04:03.015985 51587 solver.cpp:333]     Train net output #0: accuracy = 0.34375
I1226 07:04:03.016058 51587 solver.cpp:333]     Train net output #1: loss = 3.23603 (* 1 = 3.23603 loss)
I1226 07:04:03.016178 51587 solver.cpp:298] [5] PROFILING BEGIN[Forward] Iteration 10
I1226 07:04:03.067992 88126 solver.cpp:300] [6] PROFILING END[Forward] Iteration 9
I1226 07:04:03.068087 88126 solver.cpp:305] [6] PROFILING BEGIN[Other] Iteration 9
I1226 07:04:03.068137 88126 solver.cpp:306] [6] Iteration 9, loss = 3.42772
I1226 07:04:03.068214 88126 solver.cpp:309] [6] PROFILING END[Other] Iteration 9
I1226 07:04:03.068262 88126 solver.cpp:333]     Train net output #0: accuracy = 0.25
I1226 07:04:03.068344 88126 solver.cpp:333]     Train net output #1: loss = 3.42772 (* 1 = 3.42772 loss)
I1226 07:04:03.068483 88126 solver.cpp:298] [6] PROFILING BEGIN[Forward] Iteration 10
I1226 07:04:03.747594 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 13
I1226 07:04:03.747719 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 13
I1226 07:04:03.747752 90546 solver.cpp:306] [0] Iteration 13, loss = 3.40305
I1226 07:04:03.747854 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 13
I1226 07:04:03.747885 90546 solver.cpp:333]     Train net output #0: accuracy = 0.34375
I1226 07:04:03.747936 90546 solver.cpp:333]     Train net output #1: loss = 3.40305 (* 1 = 3.40305 loss)
I1226 07:04:03.747987 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 14
I1226 07:04:04.238381 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 13
I1226 07:04:04.238463 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 13
I1226 07:04:04.238530 89377 solver.cpp:306] [1] Iteration 13, loss = 3.02788
I1226 07:04:04.238593 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 13
I1226 07:04:04.238631 89377 solver.cpp:333]     Train net output #0: accuracy = 0.328125
I1226 07:04:04.238704 89377 solver.cpp:333]     Train net output #1: loss = 3.02788 (* 1 = 3.02788 loss)
I1226 07:04:04.238787 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 14
I1226 07:04:04.291090 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 13
I1226 07:04:04.291185 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 13
I1226 07:04:04.291240 89451 solver.cpp:306] [2] Iteration 13, loss = 3.33869
I1226 07:04:04.291314 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 13
I1226 07:04:04.291360 89451 solver.cpp:333]     Train net output #0: accuracy = 0.3125
I1226 07:04:04.291442 89451 solver.cpp:333]     Train net output #1: loss = 3.33869 (* 1 = 3.33869 loss)
I1226 07:04:04.291546 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 14
I1226 07:04:04.317417 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 13
I1226 07:04:04.317507 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 13
I1226 07:04:04.317556 89170 solver.cpp:306] [3] Iteration 13, loss = 3.25996
I1226 07:04:04.317636 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 13
I1226 07:04:04.317683 89170 solver.cpp:333]     Train net output #0: accuracy = 0.359375
I1226 07:04:04.317769 89170 solver.cpp:333]     Train net output #1: loss = 3.25996 (* 1 = 3.25996 loss)
I1226 07:04:04.317860 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 14
I1226 07:04:04.815702 93507 solver.cpp:300] [7] PROFILING END[Forward] Iteration 9
I1226 07:04:04.815842 93507 solver.cpp:305] [7] PROFILING BEGIN[Other] Iteration 9
I1226 07:04:04.815894 93507 solver.cpp:306] [7] Iteration 9, loss = 3.2116
I1226 07:04:04.815969 93507 solver.cpp:309] [7] PROFILING END[Other] Iteration 9
I1226 07:04:04.816015 93507 solver.cpp:333]     Train net output #0: accuracy = 0.390625
I1226 07:04:04.816098 93507 solver.cpp:333]     Train net output #1: loss = 3.2116 (* 1 = 3.2116 loss)
I1226 07:04:04.816174 93507 solver.cpp:298] [7] PROFILING BEGIN[Forward] Iteration 10
I1226 07:04:05.184798 89165 solver.cpp:300] [4] PROFILING END[Forward] Iteration 10
I1226 07:04:05.184878 89165 solver.cpp:305] [4] PROFILING BEGIN[Other] Iteration 10
I1226 07:04:05.184919 89165 solver.cpp:306] [4] Iteration 10, loss = 2.66194
I1226 07:04:05.185036 89165 solver.cpp:309] [4] PROFILING END[Other] Iteration 10
I1226 07:04:05.185078 89165 solver.cpp:333]     Train net output #0: accuracy = 0.390625
I1226 07:04:05.185142 89165 solver.cpp:333]     Train net output #1: loss = 2.66194 (* 1 = 2.66194 loss)
I1226 07:04:05.185287 89165 solver.cpp:298] [4] PROFILING BEGIN[Forward] Iteration 11
I1226 07:04:05.398748 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 14
I1226 07:04:05.398828 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 14
I1226 07:04:05.398861 90546 solver.cpp:306] [0] Iteration 14, loss = 2.79832
I1226 07:04:05.398913 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 14
I1226 07:04:05.398942 90546 solver.cpp:333]     Train net output #0: accuracy = 0.375
I1226 07:04:05.398991 90546 solver.cpp:333]     Train net output #1: loss = 2.79832 (* 1 = 2.79832 loss)
I1226 07:04:05.399035 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 15
I1226 07:04:05.412415 51587 solver.cpp:300] [5] PROFILING END[Forward] Iteration 10
I1226 07:04:05.412494 51587 solver.cpp:305] [5] PROFILING BEGIN[Other] Iteration 10
I1226 07:04:05.412535 51587 solver.cpp:306] [5] Iteration 10, loss = 3.34705
I1226 07:04:05.412600 51587 solver.cpp:309] [5] PROFILING END[Other] Iteration 10
I1226 07:04:05.412638 51587 solver.cpp:333]     Train net output #0: accuracy = 0.390625
I1226 07:04:05.412711 51587 solver.cpp:333]     Train net output #1: loss = 3.34705 (* 1 = 3.34705 loss)
I1226 07:04:05.412791 51587 solver.cpp:298] [5] PROFILING BEGIN[Forward] Iteration 11
I1226 07:04:05.460053 88126 solver.cpp:300] [6] PROFILING END[Forward] Iteration 10
I1226 07:04:05.460140 88126 solver.cpp:305] [6] PROFILING BEGIN[Other] Iteration 10
I1226 07:04:05.460218 88126 solver.cpp:306] [6] Iteration 10, loss = 3.58506
I1226 07:04:05.460289 88126 solver.cpp:309] [6] PROFILING END[Other] Iteration 10
I1226 07:04:05.460342 88126 solver.cpp:333]     Train net output #0: accuracy = 0.234375
I1226 07:04:05.460422 88126 solver.cpp:333]     Train net output #1: loss = 3.58506 (* 1 = 3.58506 loss)
I1226 07:04:05.460494 88126 solver.cpp:298] [6] PROFILING BEGIN[Forward] Iteration 11
I1226 07:04:05.861451 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 14
I1226 07:04:05.861670 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 14
I1226 07:04:05.861716 89377 solver.cpp:306] [1] Iteration 14, loss = 3.52561
I1226 07:04:05.861845 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 14
I1226 07:04:05.861887 89377 solver.cpp:333]     Train net output #0: accuracy = 0.28125
I1226 07:04:05.861958 89377 solver.cpp:333]     Train net output #1: loss = 3.52561 (* 1 = 3.52561 loss)
I1226 07:04:05.862015 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 15
I1226 07:04:05.920191 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 14
I1226 07:04:05.920392 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 14
I1226 07:04:05.920440 89451 solver.cpp:306] [2] Iteration 14, loss = 3.42843
I1226 07:04:05.920543 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 14
I1226 07:04:05.920603 89451 solver.cpp:333]     Train net output #0: accuracy = 0.296875
I1226 07:04:05.920684 89451 solver.cpp:333]     Train net output #1: loss = 3.42843 (* 1 = 3.42843 loss)
I1226 07:04:05.920760 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 15
I1226 07:04:05.933334 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 14
I1226 07:04:05.933512 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 14
I1226 07:04:05.933562 89170 solver.cpp:306] [3] Iteration 14, loss = 3.35485
I1226 07:04:05.933668 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 14
I1226 07:04:05.933725 89170 solver.cpp:333]     Train net output #0: accuracy = 0.265625
I1226 07:04:05.933809 89170 solver.cpp:333]     Train net output #1: loss = 3.35485 (* 1 = 3.35485 loss)
I1226 07:04:05.933897 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 15
I1226 07:04:07.021239 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 15
I1226 07:04:07.021332 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 15
I1226 07:04:07.021585 90546 solver.cpp:306] [0] Iteration 15, loss = 4.07399
I1226 07:04:07.021788 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 15
I1226 07:04:07.021828 90546 solver.cpp:333]     Train net output #0: accuracy = 0.265625
I1226 07:04:07.021898 90546 solver.cpp:333]     Train net output #1: loss = 4.07399 (* 1 = 4.07399 loss)
I1226 07:04:07.021967 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 16
I1226 07:04:07.178642 93507 solver.cpp:300] [7] PROFILING END[Forward] Iteration 10
I1226 07:04:07.178738 93507 solver.cpp:305] [7] PROFILING BEGIN[Other] Iteration 10
I1226 07:04:07.178829 93507 solver.cpp:306] [7] Iteration 10, loss = 3.06318
I1226 07:04:07.178907 93507 solver.cpp:309] [7] PROFILING END[Other] Iteration 10
I1226 07:04:07.178952 93507 solver.cpp:333]     Train net output #0: accuracy = 0.359375
I1226 07:04:07.179036 93507 solver.cpp:333]     Train net output #1: loss = 3.06318 (* 1 = 3.06318 loss)
I1226 07:04:07.179101 93507 solver.cpp:298] [7] PROFILING BEGIN[Forward] Iteration 11
I1226 07:04:07.496493 89165 solver.cpp:300] [4] PROFILING END[Forward] Iteration 11
I1226 07:04:07.496574 89165 solver.cpp:305] [4] PROFILING BEGIN[Other] Iteration 11
I1226 07:04:07.496681 89165 solver.cpp:306] [4] Iteration 11, loss = 3.09535
I1226 07:04:07.496757 89165 solver.cpp:309] [4] PROFILING END[Other] Iteration 11
I1226 07:04:07.496794 89165 solver.cpp:333]     Train net output #0: accuracy = 0.25
I1226 07:04:07.496861 89165 solver.cpp:333]     Train net output #1: loss = 3.09535 (* 1 = 3.09535 loss)
I1226 07:04:07.496925 89165 solver.cpp:298] [4] PROFILING BEGIN[Forward] Iteration 12
I1226 07:04:07.501575 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 15
I1226 07:04:07.501668 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 15
I1226 07:04:07.501768 89377 solver.cpp:306] [1] Iteration 15, loss = 3.2789
I1226 07:04:07.501869 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 15
I1226 07:04:07.501919 89377 solver.cpp:333]     Train net output #0: accuracy = 0.3125
I1226 07:04:07.501996 89377 solver.cpp:333]     Train net output #1: loss = 3.2789 (* 1 = 3.2789 loss)
I1226 07:04:07.502064 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 16
I1226 07:04:07.541862 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 15
I1226 07:04:07.541951 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 15
I1226 07:04:07.541998 89451 solver.cpp:306] [2] Iteration 15, loss = 3.32965
I1226 07:04:07.542073 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 15
I1226 07:04:07.542117 89451 solver.cpp:333]     Train net output #0: accuracy = 0.265625
I1226 07:04:07.542198 89451 solver.cpp:333]     Train net output #1: loss = 3.32965 (* 1 = 3.32965 loss)
I1226 07:04:07.542271 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 16
I1226 07:04:07.557786 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 15
I1226 07:04:07.557883 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 15
I1226 07:04:07.557936 89170 solver.cpp:306] [3] Iteration 15, loss = 3.31378
I1226 07:04:07.558017 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 15
I1226 07:04:07.558063 89170 solver.cpp:333]     Train net output #0: accuracy = 0.359375
I1226 07:04:07.558303 89170 solver.cpp:333]     Train net output #1: loss = 3.31378 (* 1 = 3.31378 loss)
I1226 07:04:07.558420 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 16
I1226 07:04:07.746829 51587 solver.cpp:300] [5] PROFILING END[Forward] Iteration 11
I1226 07:04:07.746909 51587 solver.cpp:305] [5] PROFILING BEGIN[Other] Iteration 11
I1226 07:04:07.746949 51587 solver.cpp:306] [5] Iteration 11, loss = 3.29143
I1226 07:04:07.747015 51587 solver.cpp:309] [5] PROFILING END[Other] Iteration 11
I1226 07:04:07.747064 51587 solver.cpp:333]     Train net output #0: accuracy = 0.3125
I1226 07:04:07.747174 51587 solver.cpp:333]     Train net output #1: loss = 3.29143 (* 1 = 3.29143 loss)
I1226 07:04:07.747278 51587 solver.cpp:298] [5] PROFILING BEGIN[Forward] Iteration 12
I1226 07:04:07.795459 88126 solver.cpp:300] [6] PROFILING END[Forward] Iteration 11
I1226 07:04:07.795545 88126 solver.cpp:305] [6] PROFILING BEGIN[Other] Iteration 11
I1226 07:04:07.795621 88126 solver.cpp:306] [6] Iteration 11, loss = 2.60721
I1226 07:04:07.795707 88126 solver.cpp:309] [6] PROFILING END[Other] Iteration 11
I1226 07:04:07.795768 88126 solver.cpp:333]     Train net output #0: accuracy = 0.421875
I1226 07:04:07.795877 88126 solver.cpp:333]     Train net output #1: loss = 2.60721 (* 1 = 2.60721 loss)
I1226 07:04:07.796303 88126 solver.cpp:298] [6] PROFILING BEGIN[Forward] Iteration 12
I1226 07:04:08.656647 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 16
I1226 07:04:08.656762 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 16
I1226 07:04:08.656798 90546 solver.cpp:306] [0] Iteration 16, loss = 3.33445
I1226 07:04:08.656893 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 16
I1226 07:04:08.656924 90546 solver.cpp:333]     Train net output #0: accuracy = 0.28125
I1226 07:04:08.656975 90546 solver.cpp:333]     Train net output #1: loss = 3.33445 (* 1 = 3.33445 loss)
I1226 07:04:08.657032 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 17
I1226 07:04:09.111644 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 16
I1226 07:04:09.111724 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 16
I1226 07:04:09.111763 89377 solver.cpp:306] [1] Iteration 16, loss = 3.22438
I1226 07:04:09.111863 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 16
I1226 07:04:09.111903 89377 solver.cpp:333]     Train net output #0: accuracy = 0.296875
I1226 07:04:09.111979 89377 solver.cpp:333]     Train net output #1: loss = 3.22438 (* 1 = 3.22438 loss)
I1226 07:04:09.112040 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 17
I1226 07:04:09.179299 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 16
I1226 07:04:09.179386 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 16
I1226 07:04:09.179435 89451 solver.cpp:306] [2] Iteration 16, loss = 3.33886
I1226 07:04:09.179548 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 16
I1226 07:04:09.179605 89451 solver.cpp:333]     Train net output #0: accuracy = 0.359375
I1226 07:04:09.179682 89451 solver.cpp:333]     Train net output #1: loss = 3.33886 (* 1 = 3.33886 loss)
I1226 07:04:09.179769 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 17
I1226 07:04:09.184322 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 16
I1226 07:04:09.184413 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 16
I1226 07:04:09.184463 89170 solver.cpp:306] [3] Iteration 16, loss = 3.20078
I1226 07:04:09.184538 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 16
I1226 07:04:09.184584 89170 solver.cpp:333]     Train net output #0: accuracy = 0.359375
I1226 07:04:09.184666 89170 solver.cpp:333]     Train net output #1: loss = 3.20078 (* 1 = 3.20078 loss)
I1226 07:04:09.184746 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 17
I1226 07:04:09.538425 93507 solver.cpp:300] [7] PROFILING END[Forward] Iteration 11
I1226 07:04:09.538522 93507 solver.cpp:305] [7] PROFILING BEGIN[Other] Iteration 11
I1226 07:04:09.538569 93507 solver.cpp:306] [7] Iteration 11, loss = 3.09147
I1226 07:04:09.538645 93507 solver.cpp:309] [7] PROFILING END[Other] Iteration 11
I1226 07:04:09.538692 93507 solver.cpp:333]     Train net output #0: accuracy = 0.34375
I1226 07:04:09.538777 93507 solver.cpp:333]     Train net output #1: loss = 3.09147 (* 1 = 3.09147 loss)
I1226 07:04:09.538872 93507 solver.cpp:298] [7] PROFILING BEGIN[Forward] Iteration 12
I1226 07:04:09.855968 89165 solver.cpp:300] [4] PROFILING END[Forward] Iteration 12
I1226 07:04:09.856098 89165 solver.cpp:305] [4] PROFILING BEGIN[Other] Iteration 12
I1226 07:04:09.856144 89165 solver.cpp:306] [4] Iteration 12, loss = 2.98193
I1226 07:04:09.856225 89165 solver.cpp:309] [4] PROFILING END[Other] Iteration 12
I1226 07:04:09.856295 89165 solver.cpp:333]     Train net output #0: accuracy = 0.34375
I1226 07:04:09.856351 89165 solver.cpp:333]     Train net output #1: loss = 2.98193 (* 1 = 2.98193 loss)
I1226 07:04:09.856405 89165 solver.cpp:298] [4] PROFILING BEGIN[Forward] Iteration 13
I1226 07:04:10.120712 51587 solver.cpp:300] [5] PROFILING END[Forward] Iteration 12
I1226 07:04:10.120796 51587 solver.cpp:305] [5] PROFILING BEGIN[Other] Iteration 12
I1226 07:04:10.120837 51587 solver.cpp:306] [5] Iteration 12, loss = 3.2152
I1226 07:04:10.120934 51587 solver.cpp:309] [5] PROFILING END[Other] Iteration 12
I1226 07:04:10.120977 51587 solver.cpp:333]     Train net output #0: accuracy = 0.3125
I1226 07:04:10.121045 51587 solver.cpp:333]     Train net output #1: loss = 3.2152 (* 1 = 3.2152 loss)
I1226 07:04:10.121204 51587 solver.cpp:298] [5] PROFILING BEGIN[Forward] Iteration 13
I1226 07:04:10.168969 88126 solver.cpp:300] [6] PROFILING END[Forward] Iteration 12
I1226 07:04:10.169061 88126 solver.cpp:305] [6] PROFILING BEGIN[Other] Iteration 12
I1226 07:04:10.169112 88126 solver.cpp:306] [6] Iteration 12, loss = 3.56273
I1226 07:04:10.169215 88126 solver.cpp:309] [6] PROFILING END[Other] Iteration 12
I1226 07:04:10.169271 88126 solver.cpp:333]     Train net output #0: accuracy = 0.28125
I1226 07:04:10.169356 88126 solver.cpp:333]     Train net output #1: loss = 3.56273 (* 1 = 3.56273 loss)
I1226 07:04:10.169435 88126 solver.cpp:298] [6] PROFILING BEGIN[Forward] Iteration 13
I1226 07:04:10.271435 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 17
I1226 07:04:10.271512 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 17
I1226 07:04:10.271543 90546 solver.cpp:306] [0] Iteration 17, loss = 3.82241
I1226 07:04:10.271596 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 17
I1226 07:04:10.271626 90546 solver.cpp:333]     Train net output #0: accuracy = 0.234375
I1226 07:04:10.271675 90546 solver.cpp:333]     Train net output #1: loss = 3.82241 (* 1 = 3.82241 loss)
I1226 07:04:10.271767 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 18
I1226 07:04:10.746860 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 17
I1226 07:04:10.746955 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 17
I1226 07:04:10.747017 89377 solver.cpp:306] [1] Iteration 17, loss = 3.24254
I1226 07:04:10.747133 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 17
I1226 07:04:10.747184 89377 solver.cpp:333]     Train net output #0: accuracy = 0.328125
I1226 07:04:10.747267 89377 solver.cpp:333]     Train net output #1: loss = 3.24254 (* 1 = 3.24254 loss)
I1226 07:04:10.747334 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 18
I1226 07:04:10.817330 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 17
I1226 07:04:10.817420 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 17
I1226 07:04:10.817471 89451 solver.cpp:306] [2] Iteration 17, loss = 3.13753
I1226 07:04:10.817601 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 17
I1226 07:04:10.817653 89451 solver.cpp:333]     Train net output #0: accuracy = 0.296875
I1226 07:04:10.817737 89451 solver.cpp:333]     Train net output #1: loss = 3.13753 (* 1 = 3.13753 loss)
I1226 07:04:10.817819 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 18
I1226 07:04:10.814496 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 17
I1226 07:04:10.814584 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 17
I1226 07:04:10.814637 89170 solver.cpp:306] [3] Iteration 17, loss = 3.32344
I1226 07:04:10.814710 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 17
I1226 07:04:10.814756 89170 solver.cpp:333]     Train net output #0: accuracy = 0.265625
I1226 07:04:10.814838 89170 solver.cpp:333]     Train net output #1: loss = 3.32344 (* 1 = 3.32344 loss)
I1226 07:04:10.814935 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 18
I1226 07:04:11.901340 93507 solver.cpp:300] [7] PROFILING END[Forward] Iteration 12
I1226 07:04:11.904515 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 18
I1226 07:04:11.901427 93507 solver.cpp:305] [7] PROFILING BEGIN[Other] Iteration 12
I1226 07:04:11.904587 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 18
I1226 07:04:11.904660 90546 solver.cpp:306] [0] Iteration 18, loss = 3.42538
I1226 07:04:11.901510 93507 solver.cpp:306] [7] Iteration 12, loss = 3.63448
I1226 07:04:11.904714 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 18
I1226 07:04:11.904743 90546 solver.cpp:333]     Train net output #0: accuracy = 0.25
I1226 07:04:11.904793 90546 solver.cpp:333]     Train net output #1: loss = 3.42538 (* 1 = 3.42538 loss)
I1226 07:04:11.901584 93507 solver.cpp:309] [7] PROFILING END[Other] Iteration 12
I1226 07:04:11.904860 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 19
I1226 07:04:11.901810 93507 solver.cpp:333]     Train net output #0: accuracy = 0.296875
I1226 07:04:11.901888 93507 solver.cpp:333]     Train net output #1: loss = 3.63448 (* 1 = 3.63448 loss)
I1226 07:04:11.901979 93507 solver.cpp:298] [7] PROFILING BEGIN[Forward] Iteration 13
I1226 07:04:12.112848 89165 solver.cpp:300] [4] PROFILING END[Forward] Iteration 13
I1226 07:04:12.112977 89165 solver.cpp:305] [4] PROFILING BEGIN[Other] Iteration 13
I1226 07:04:12.113023 89165 solver.cpp:306] [4] Iteration 13, loss = 3.41876
I1226 07:04:12.113126 89165 solver.cpp:309] [4] PROFILING END[Other] Iteration 13
I1226 07:04:12.113324 89165 solver.cpp:333]     Train net output #0: accuracy = 0.390625
I1226 07:04:12.113394 89165 solver.cpp:333]     Train net output #1: loss = 3.41876 (* 1 = 3.41876 loss)
I1226 07:04:12.113461 89165 solver.cpp:298] [4] PROFILING BEGIN[Forward] Iteration 14
I1226 07:04:12.372916 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 18
I1226 07:04:12.374011 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 18
I1226 07:04:12.374083 89377 solver.cpp:306] [1] Iteration 18, loss = 3.01719
I1226 07:04:12.374153 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 18
I1226 07:04:12.374194 89377 solver.cpp:333]     Train net output #0: accuracy = 0.390625
I1226 07:04:12.374266 89377 solver.cpp:333]     Train net output #1: loss = 3.01719 (* 1 = 3.01719 loss)
I1226 07:04:12.374354 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 19
I1226 07:04:12.437739 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 18
I1226 07:04:12.438840 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 18
I1226 07:04:12.438910 89451 solver.cpp:306] [2] Iteration 18, loss = 3.37497
I1226 07:04:12.438992 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 18
I1226 07:04:12.439038 89451 solver.cpp:333]     Train net output #0: accuracy = 0.375
I1226 07:04:12.439296 89451 solver.cpp:333]     Train net output #1: loss = 3.37497 (* 1 = 3.37497 loss)
I1226 07:04:12.439426 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 19
I1226 07:04:12.451746 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 18
I1226 07:04:12.452976 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 18
I1226 07:04:12.453048 89170 solver.cpp:306] [3] Iteration 18, loss = 3.62416
I1226 07:04:12.453125 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 18
I1226 07:04:12.453174 89170 solver.cpp:333]     Train net output #0: accuracy = 0.21875
I1226 07:04:12.453274 89170 solver.cpp:333]     Train net output #1: loss = 3.62416 (* 1 = 3.62416 loss)
I1226 07:04:12.453356 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 19
I1226 07:04:12.497407 51587 solver.cpp:300] [5] PROFILING END[Forward] Iteration 13
I1226 07:04:12.498500 51587 solver.cpp:305] [5] PROFILING BEGIN[Other] Iteration 13
I1226 07:04:12.498565 51587 solver.cpp:306] [5] Iteration 13, loss = 3.11654
I1226 07:04:12.498788 51587 solver.cpp:309] [5] PROFILING END[Other] Iteration 13
I1226 07:04:12.498975 51587 solver.cpp:333]     Train net output #0: accuracy = 0.359375
I1226 07:04:12.499052 51587 solver.cpp:333]     Train net output #1: loss = 3.11654 (* 1 = 3.11654 loss)
I1226 07:04:12.499116 51587 solver.cpp:298] [5] PROFILING BEGIN[Forward] Iteration 14
I1226 07:04:12.552865 88126 solver.cpp:300] [6] PROFILING END[Forward] Iteration 13
I1226 07:04:12.553956 88126 solver.cpp:305] [6] PROFILING BEGIN[Other] Iteration 13
I1226 07:04:12.554020 88126 solver.cpp:306] [6] Iteration 13, loss = 3.84672
I1226 07:04:12.554096 88126 solver.cpp:309] [6] PROFILING END[Other] Iteration 13
I1226 07:04:12.554148 88126 solver.cpp:333]     Train net output #0: accuracy = 0.265625
I1226 07:04:12.554224 88126 solver.cpp:333]     Train net output #1: loss = 3.84672 (* 1 = 3.84672 loss)
I1226 07:04:12.554303 88126 solver.cpp:298] [6] PROFILING BEGIN[Forward] Iteration 14
I1226 07:04:13.661264 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 19
I1226 07:04:13.662430 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 19
I1226 07:04:13.662544 90546 solver.cpp:306] [0] Iteration 19, loss = 2.99641
I1226 07:04:13.662613 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 19
I1226 07:04:13.662650 90546 solver.cpp:333]     Train net output #0: accuracy = 0.421875
I1226 07:04:13.662703 90546 solver.cpp:333]     Train net output #1: loss = 2.99641 (* 1 = 2.99641 loss)
I1226 07:04:13.662816 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 20
I1226 07:04:14.029943 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 19
I1226 07:04:14.030038 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 19
I1226 07:04:14.030086 89377 solver.cpp:306] [1] Iteration 19, loss = 3.46791
I1226 07:04:14.030160 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 19
I1226 07:04:14.030208 89377 solver.cpp:333]     Train net output #0: accuracy = 0.28125
I1226 07:04:14.030289 89377 solver.cpp:333]     Train net output #1: loss = 3.46791 (* 1 = 3.46791 loss)
I1226 07:04:14.030360 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 20
I1226 07:04:14.087298 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 19
I1226 07:04:14.087385 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 19
I1226 07:04:14.087534 89451 solver.cpp:306] [2] Iteration 19, loss = 2.80446
I1226 07:04:14.087774 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 19
I1226 07:04:14.087819 89451 solver.cpp:333]     Train net output #0: accuracy = 0.46875
I1226 07:04:14.088058 89451 solver.cpp:333]     Train net output #1: loss = 2.80446 (* 1 = 2.80446 loss)
I1226 07:04:14.088170 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 20
I1226 07:04:14.095314 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 19
I1226 07:04:14.095435 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 19
I1226 07:04:14.095489 89170 solver.cpp:306] [3] Iteration 19, loss = 3.44772
I1226 07:04:14.095569 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 19
I1226 07:04:14.095616 89170 solver.cpp:333]     Train net output #0: accuracy = 0.296875
I1226 07:04:14.095697 89170 solver.cpp:333]     Train net output #1: loss = 3.44772 (* 1 = 3.44772 loss)
I1226 07:04:14.095769 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 20
I1226 07:04:14.345206 93507 solver.cpp:300] [7] PROFILING END[Forward] Iteration 13
I1226 07:04:14.345302 93507 solver.cpp:305] [7] PROFILING BEGIN[Other] Iteration 13
I1226 07:04:14.345350 93507 solver.cpp:306] [7] Iteration 13, loss = 2.91192
I1226 07:04:14.345424 93507 solver.cpp:309] [7] PROFILING END[Other] Iteration 13
I1226 07:04:14.345484 93507 solver.cpp:333]     Train net output #0: accuracy = 0.375
I1226 07:04:14.345561 93507 solver.cpp:333]     Train net output #1: loss = 2.91192 (* 1 = 2.91192 loss)
I1226 07:04:14.345633 93507 solver.cpp:298] [7] PROFILING BEGIN[Forward] Iteration 14
I1226 07:04:14.671535 89165 solver.cpp:300] [4] PROFILING END[Forward] Iteration 14
I1226 07:04:14.672338 89165 solver.cpp:305] [4] PROFILING BEGIN[Other] Iteration 14
I1226 07:04:14.672394 89165 solver.cpp:306] [4] Iteration 14, loss = 3.36842
I1226 07:04:14.672462 89165 solver.cpp:309] [4] PROFILING END[Other] Iteration 14
I1226 07:04:14.672502 89165 solver.cpp:333]     Train net output #0: accuracy = 0.3125
I1226 07:04:14.672583 89165 solver.cpp:333]     Train net output #1: loss = 3.36842 (* 1 = 3.36842 loss)
I1226 07:04:14.672713 89165 solver.cpp:298] [4] PROFILING BEGIN[Forward] Iteration 15
I1226 07:04:14.959096 88126 solver.cpp:300] [6] PROFILING END[Forward] Iteration 14
I1226 07:04:14.959183 88126 solver.cpp:305] [6] PROFILING BEGIN[Other] Iteration 14
I1226 07:04:14.959233 88126 solver.cpp:306] [6] Iteration 14, loss = 3.04358
I1226 07:04:14.959314 88126 solver.cpp:309] [6] PROFILING END[Other] Iteration 14
I1226 07:04:14.959360 88126 solver.cpp:333]     Train net output #0: accuracy = 0.296875
I1226 07:04:14.959440 88126 solver.cpp:333]     Train net output #1: loss = 3.04358 (* 1 = 3.04358 loss)
I1226 07:04:14.959544 88126 solver.cpp:298] [6] PROFILING BEGIN[Forward] Iteration 15
I1226 07:04:15.014983 51587 solver.cpp:300] [5] PROFILING END[Forward] Iteration 14
I1226 07:04:15.015066 51587 solver.cpp:305] [5] PROFILING BEGIN[Other] Iteration 14
I1226 07:04:15.015106 51587 solver.cpp:306] [5] Iteration 14, loss = 2.96648
I1226 07:04:15.015208 51587 solver.cpp:309] [5] PROFILING END[Other] Iteration 14
I1226 07:04:15.015247 51587 solver.cpp:333]     Train net output #0: accuracy = 0.375
I1226 07:04:15.015311 51587 solver.cpp:333]     Train net output #1: loss = 2.96648 (* 1 = 2.96648 loss)
I1226 07:04:15.015382 51587 solver.cpp:298] [5] PROFILING BEGIN[Forward] Iteration 15
I1226 07:04:15.212024 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 20
I1226 07:04:15.212098 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 20
I1226 07:04:15.212131 90546 solver.cpp:306] [0] Iteration 20, loss = 3.19991
I1226 07:04:15.212231 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 20
I1226 07:04:15.212265 90546 solver.cpp:333]     Train net output #0: accuracy = 0.25
I1226 07:04:15.212326 90546 solver.cpp:333]     Train net output #1: loss = 3.19991 (* 1 = 3.19991 loss)
I1226 07:04:15.212388 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 21
I1226 07:04:15.708693 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 20
I1226 07:04:15.708859 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 20
I1226 07:04:15.708904 89377 solver.cpp:306] [1] Iteration 20, loss = 3.17823
I1226 07:04:15.709010 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 20
I1226 07:04:15.709053 89377 solver.cpp:333]     Train net output #0: accuracy = 0.375
I1226 07:04:15.709127 89377 solver.cpp:333]     Train net output #1: loss = 3.17823 (* 1 = 3.17823 loss)
I1226 07:04:15.709230 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 21
I1226 07:04:15.819713 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 20
I1226 07:04:15.819806 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 20
I1226 07:04:15.819855 89170 solver.cpp:306] [3] Iteration 20, loss = 3.19908
I1226 07:04:15.819931 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 20
I1226 07:04:15.819977 89170 solver.cpp:333]     Train net output #0: accuracy = 0.25
I1226 07:04:15.820058 89170 solver.cpp:333]     Train net output #1: loss = 3.19908 (* 1 = 3.19908 loss)
I1226 07:04:15.820171 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 21
I1226 07:04:15.890875 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 20
I1226 07:04:15.890961 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 20
I1226 07:04:15.891016 89451 solver.cpp:306] [2] Iteration 20, loss = 3.18782
I1226 07:04:15.891088 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 20
I1226 07:04:15.891132 89451 solver.cpp:333]     Train net output #0: accuracy = 0.296875
I1226 07:04:15.891216 89451 solver.cpp:333]     Train net output #1: loss = 3.18782 (* 1 = 3.18782 loss)
I1226 07:04:15.891284 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 21
I1226 07:04:16.856287 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 21
I1226 07:04:16.856401 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 21
I1226 07:04:16.856436 90546 solver.cpp:306] [0] Iteration 21, loss = 3.07096
I1226 07:04:16.856509 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 21
I1226 07:04:16.856539 90546 solver.cpp:333]     Train net output #0: accuracy = 0.34375
I1226 07:04:16.856590 90546 solver.cpp:333]     Train net output #1: loss = 3.07096 (* 1 = 3.07096 loss)
I1226 07:04:16.856688 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 22
I1226 07:04:17.338661 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 21
I1226 07:04:17.338754 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 21
I1226 07:04:17.338802 89377 solver.cpp:306] [1] Iteration 21, loss = 3.10641
I1226 07:04:17.338960 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 21
I1226 07:04:17.339013 89377 solver.cpp:333]     Train net output #0: accuracy = 0.390625
I1226 07:04:17.339095 89377 solver.cpp:333]     Train net output #1: loss = 3.10641 (* 1 = 3.10641 loss)
I1226 07:04:17.339223 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 22
I1226 07:04:17.409021 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 21
I1226 07:04:17.409112 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 21
I1226 07:04:17.409160 89451 solver.cpp:306] [2] Iteration 21, loss = 3.34672
I1226 07:04:17.409232 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 21
I1226 07:04:17.409279 89451 solver.cpp:333]     Train net output #0: accuracy = 0.390625
I1226 07:04:17.409361 89451 solver.cpp:333]     Train net output #1: loss = 3.34672 (* 1 = 3.34672 loss)
I1226 07:04:17.409440 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 22
I1226 07:04:17.407415 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 21
I1226 07:04:17.407507 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 21
I1226 07:04:17.407567 89170 solver.cpp:306] [3] Iteration 21, loss = 3.57734
I1226 07:04:17.407644 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 21
I1226 07:04:17.407691 89170 solver.cpp:333]     Train net output #0: accuracy = 0.265625
I1226 07:04:17.407771 89170 solver.cpp:333]     Train net output #1: loss = 3.57734 (* 1 = 3.57734 loss)
I1226 07:04:17.407877 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 22
I1226 07:04:17.410897 93507 solver.cpp:300] [7] PROFILING END[Forward] Iteration 14
I1226 07:04:17.410980 93507 solver.cpp:305] [7] PROFILING BEGIN[Other] Iteration 14
I1226 07:04:17.411018 93507 solver.cpp:306] [7] Iteration 14, loss = 3.07339
I1226 07:04:17.411105 93507 solver.cpp:309] [7] PROFILING END[Other] Iteration 14
I1226 07:04:17.411152 93507 solver.cpp:333]     Train net output #0: accuracy = 0.3125
I1226 07:04:17.411228 93507 solver.cpp:333]     Train net output #1: loss = 3.07339 (* 1 = 3.07339 loss)
I1226 07:04:17.411284 93507 solver.cpp:298] [7] PROFILING BEGIN[Forward] Iteration 15
I1226 07:04:17.554672 89165 solver.cpp:300] [4] PROFILING END[Forward] Iteration 15
I1226 07:04:17.554761 89165 solver.cpp:305] [4] PROFILING BEGIN[Other] Iteration 15
I1226 07:04:17.554805 89165 solver.cpp:306] [4] Iteration 15, loss = 3.03287
I1226 07:04:17.554874 89165 solver.cpp:309] [4] PROFILING END[Other] Iteration 15
I1226 07:04:17.554913 89165 solver.cpp:333]     Train net output #0: accuracy = 0.375
I1226 07:04:17.554983 89165 solver.cpp:333]     Train net output #1: loss = 3.03287 (* 1 = 3.03287 loss)
I1226 07:04:17.555047 89165 solver.cpp:298] [4] PROFILING BEGIN[Forward] Iteration 16
I1226 07:04:17.653826 51587 solver.cpp:300] [5] PROFILING END[Forward] Iteration 15
I1226 07:04:17.653913 51587 solver.cpp:305] [5] PROFILING BEGIN[Other] Iteration 15
I1226 07:04:17.653955 51587 solver.cpp:306] [5] Iteration 15, loss = 3.62011
I1226 07:04:17.654019 51587 solver.cpp:309] [5] PROFILING END[Other] Iteration 15
I1226 07:04:17.654057 51587 solver.cpp:333]     Train net output #0: accuracy = 0.296875
I1226 07:04:17.654170 51587 solver.cpp:333]     Train net output #1: loss = 3.62011 (* 1 = 3.62011 loss)
I1226 07:04:17.654237 51587 solver.cpp:298] [5] PROFILING BEGIN[Forward] Iteration 16
I1226 07:04:17.689972 88126 solver.cpp:300] [6] PROFILING END[Forward] Iteration 15
I1226 07:04:17.690064 88126 solver.cpp:305] [6] PROFILING BEGIN[Other] Iteration 15
I1226 07:04:17.690115 88126 solver.cpp:306] [6] Iteration 15, loss = 3.26176
I1226 07:04:17.690187 88126 solver.cpp:309] [6] PROFILING END[Other] Iteration 15
I1226 07:04:17.690233 88126 solver.cpp:333]     Train net output #0: accuracy = 0.34375
I1226 07:04:17.690315 88126 solver.cpp:333]     Train net output #1: loss = 3.26176 (* 1 = 3.26176 loss)
I1226 07:04:17.690431 88126 solver.cpp:298] [6] PROFILING BEGIN[Forward] Iteration 16
I1226 07:04:18.505941 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 22
I1226 07:04:18.506018 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 22
I1226 07:04:18.506050 90546 solver.cpp:306] [0] Iteration 22, loss = 2.86418
I1226 07:04:18.506163 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 22
I1226 07:04:18.506217 90546 solver.cpp:333]     Train net output #0: accuracy = 0.359375
I1226 07:04:18.506266 90546 solver.cpp:333]     Train net output #1: loss = 2.86418 (* 1 = 2.86418 loss)
I1226 07:04:18.506314 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 23
I1226 07:04:18.982972 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 22
I1226 07:04:18.983055 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 22
I1226 07:04:18.983095 89377 solver.cpp:306] [1] Iteration 22, loss = 3.03763
I1226 07:04:18.983196 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 22
I1226 07:04:18.983237 89377 solver.cpp:333]     Train net output #0: accuracy = 0.296875
I1226 07:04:18.983315 89377 solver.cpp:333]     Train net output #1: loss = 3.03763 (* 1 = 3.03763 loss)
I1226 07:04:18.983376 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 23
I1226 07:04:19.045796 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 22
I1226 07:04:19.045884 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 22
I1226 07:04:19.045933 89451 solver.cpp:306] [2] Iteration 22, loss = 3.35795
I1226 07:04:19.046005 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 22
I1226 07:04:19.046051 89451 solver.cpp:333]     Train net output #0: accuracy = 0.203125
I1226 07:04:19.046133 89451 solver.cpp:333]     Train net output #1: loss = 3.35795 (* 1 = 3.35795 loss)
I1226 07:04:19.046239 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 23
I1226 07:04:19.073644 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 22
I1226 07:04:19.073740 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 22
I1226 07:04:19.073794 89170 solver.cpp:306] [3] Iteration 22, loss = 3.57833
I1226 07:04:19.073868 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 22
I1226 07:04:19.073914 89170 solver.cpp:333]     Train net output #0: accuracy = 0.25
I1226 07:04:19.073997 89170 solver.cpp:333]     Train net output #1: loss = 3.57833 (* 1 = 3.57833 loss)
I1226 07:04:19.074106 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 23
I1226 07:04:19.283510 93507 solver.cpp:300] [7] PROFILING END[Forward] Iteration 15
I1226 07:04:19.283608 93507 solver.cpp:305] [7] PROFILING BEGIN[Other] Iteration 15
I1226 07:04:19.283655 93507 solver.cpp:306] [7] Iteration 15, loss = 3.11891
I1226 07:04:19.283728 93507 solver.cpp:309] [7] PROFILING END[Other] Iteration 15
I1226 07:04:19.283773 93507 solver.cpp:333]     Train net output #0: accuracy = 0.359375
I1226 07:04:19.283880 93507 solver.cpp:333]     Train net output #1: loss = 3.11891 (* 1 = 3.11891 loss)
I1226 07:04:19.284090 93507 solver.cpp:298] [7] PROFILING BEGIN[Forward] Iteration 16
I1226 07:04:19.602782 89165 solver.cpp:300] [4] PROFILING END[Forward] Iteration 16
I1226 07:04:19.602906 89165 solver.cpp:305] [4] PROFILING BEGIN[Other] Iteration 16
I1226 07:04:19.602952 89165 solver.cpp:306] [4] Iteration 16, loss = 3.05552
I1226 07:04:19.603020 89165 solver.cpp:309] [4] PROFILING END[Other] Iteration 16
I1226 07:04:19.603071 89165 solver.cpp:333]     Train net output #0: accuracy = 0.3125
I1226 07:04:19.603144 89165 solver.cpp:333]     Train net output #1: loss = 3.05552 (* 1 = 3.05552 loss)
I1226 07:04:19.603329 89165 solver.cpp:298] [4] PROFILING BEGIN[Forward] Iteration 17
I1226 07:04:19.865377 51587 solver.cpp:300] [5] PROFILING END[Forward] Iteration 16
I1226 07:04:19.865458 51587 solver.cpp:305] [5] PROFILING BEGIN[Other] Iteration 16
I1226 07:04:19.865496 51587 solver.cpp:306] [5] Iteration 16, loss = 3.30561
I1226 07:04:19.865608 51587 solver.cpp:309] [5] PROFILING END[Other] Iteration 16
I1226 07:04:19.865656 51587 solver.cpp:333]     Train net output #0: accuracy = 0.328125
I1226 07:04:19.865730 51587 solver.cpp:333]     Train net output #1: loss = 3.30561 (* 1 = 3.30561 loss)
I1226 07:04:19.865794 51587 solver.cpp:298] [5] PROFILING BEGIN[Forward] Iteration 17
I1226 07:04:19.917102 88126 solver.cpp:300] [6] PROFILING END[Forward] Iteration 16
I1226 07:04:19.917209 88126 solver.cpp:305] [6] PROFILING BEGIN[Other] Iteration 16
I1226 07:04:19.917270 88126 solver.cpp:306] [6] Iteration 16, loss = 3.42594
I1226 07:04:19.917358 88126 solver.cpp:309] [6] PROFILING END[Other] Iteration 16
I1226 07:04:19.917404 88126 solver.cpp:333]     Train net output #0: accuracy = 0.296875
I1226 07:04:19.917487 88126 solver.cpp:333]     Train net output #1: loss = 3.42594 (* 1 = 3.42594 loss)
I1226 07:04:19.917644 88126 solver.cpp:298] [6] PROFILING BEGIN[Forward] Iteration 17
I1226 07:04:20.166621 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 23
I1226 07:04:20.166694 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 23
I1226 07:04:20.166730 90546 solver.cpp:306] [0] Iteration 23, loss = 2.96828
I1226 07:04:20.166784 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 23
I1226 07:04:20.166813 90546 solver.cpp:333]     Train net output #0: accuracy = 0.3125
I1226 07:04:20.166863 90546 solver.cpp:333]     Train net output #1: loss = 2.96828 (* 1 = 2.96828 loss)
I1226 07:04:20.166961 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 24
I1226 07:04:20.645915 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 23
I1226 07:04:20.646013 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 23
I1226 07:04:20.646101 89377 solver.cpp:306] [1] Iteration 23, loss = 3.11851
I1226 07:04:20.646175 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 23
I1226 07:04:20.646215 89377 solver.cpp:333]     Train net output #0: accuracy = 0.328125
I1226 07:04:20.646286 89377 solver.cpp:333]     Train net output #1: loss = 3.11851 (* 1 = 3.11851 loss)
I1226 07:04:20.646368 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 24
I1226 07:04:20.700045 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 23
I1226 07:04:20.700134 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 23
I1226 07:04:20.700179 89451 solver.cpp:306] [2] Iteration 23, loss = 3.18812
I1226 07:04:20.701315 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 23
I1226 07:04:20.701369 89451 solver.cpp:333]     Train net output #0: accuracy = 0.234375
I1226 07:04:20.701596 89451 solver.cpp:333]     Train net output #1: loss = 3.18812 (* 1 = 3.18812 loss)
I1226 07:04:20.701715 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 24
I1226 07:04:20.725162 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 23
I1226 07:04:20.725273 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 23
I1226 07:04:20.725329 89170 solver.cpp:306] [3] Iteration 23, loss = 3.3574
I1226 07:04:20.725410 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 23
I1226 07:04:20.725467 89170 solver.cpp:333]     Train net output #0: accuracy = 0.375
I1226 07:04:20.725550 89170 solver.cpp:333]     Train net output #1: loss = 3.3574 (* 1 = 3.3574 loss)
I1226 07:04:20.725620 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 24
I1226 07:04:21.643877 93507 solver.cpp:300] [7] PROFILING END[Forward] Iteration 16
I1226 07:04:21.643971 93507 solver.cpp:305] [7] PROFILING BEGIN[Other] Iteration 16
I1226 07:04:21.644017 93507 solver.cpp:306] [7] Iteration 16, loss = 3.50821
I1226 07:04:21.644090 93507 solver.cpp:309] [7] PROFILING END[Other] Iteration 16
I1226 07:04:21.644135 93507 solver.cpp:333]     Train net output #0: accuracy = 0.28125
I1226 07:04:21.644220 93507 solver.cpp:333]     Train net output #1: loss = 3.50821 (* 1 = 3.50821 loss)
I1226 07:04:21.644285 93507 solver.cpp:298] [7] PROFILING BEGIN[Forward] Iteration 17
I1226 07:04:21.876117 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 24
I1226 07:04:21.876219 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 24
I1226 07:04:21.876251 90546 solver.cpp:306] [0] Iteration 24, loss = 3.69056
I1226 07:04:21.876335 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 24
I1226 07:04:21.876366 90546 solver.cpp:333]     Train net output #0: accuracy = 0.28125
I1226 07:04:21.876417 90546 solver.cpp:333]     Train net output #1: loss = 3.69056 (* 1 = 3.69056 loss)
I1226 07:04:21.876483 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 25
I1226 07:04:21.984958 89165 solver.cpp:300] [4] PROFILING END[Forward] Iteration 17
I1226 07:04:21.985081 89165 solver.cpp:305] [4] PROFILING BEGIN[Other] Iteration 17
I1226 07:04:21.985169 89165 solver.cpp:306] [4] Iteration 17, loss = 2.93792
I1226 07:04:21.985237 89165 solver.cpp:309] [4] PROFILING END[Other] Iteration 17
I1226 07:04:21.985314 89165 solver.cpp:333]     Train net output #0: accuracy = 0.359375
I1226 07:04:21.985383 89165 solver.cpp:333]     Train net output #1: loss = 2.93792 (* 1 = 2.93792 loss)
I1226 07:04:21.985440 89165 solver.cpp:298] [4] PROFILING BEGIN[Forward] Iteration 18
I1226 07:04:22.285897 51587 solver.cpp:300] [5] PROFILING END[Forward] Iteration 17
I1226 07:04:22.285981 51587 solver.cpp:305] [5] PROFILING BEGIN[Other] Iteration 17
I1226 07:04:22.286020 51587 solver.cpp:306] [5] Iteration 17, loss = 2.98772
I1226 07:04:22.286092 51587 solver.cpp:309] [5] PROFILING END[Other] Iteration 17
I1226 07:04:22.286161 51587 solver.cpp:333]     Train net output #0: accuracy = 0.328125
I1226 07:04:22.286229 51587 solver.cpp:333]     Train net output #1: loss = 2.98772 (* 1 = 2.98772 loss)
I1226 07:04:22.286332 51587 solver.cpp:298] [5] PROFILING BEGIN[Forward] Iteration 18
I1226 07:04:22.333206 88126 solver.cpp:300] [6] PROFILING END[Forward] Iteration 17
I1226 07:04:22.333298 88126 solver.cpp:305] [6] PROFILING BEGIN[Other] Iteration 17
I1226 07:04:22.333351 88126 solver.cpp:306] [6] Iteration 17, loss = 3.76236
I1226 07:04:22.333425 88126 solver.cpp:309] [6] PROFILING END[Other] Iteration 17
I1226 07:04:22.333470 88126 solver.cpp:333]     Train net output #0: accuracy = 0.203125
I1226 07:04:22.333556 88126 solver.cpp:333]     Train net output #1: loss = 3.76236 (* 1 = 3.76236 loss)
I1226 07:04:22.333693 88126 solver.cpp:298] [6] PROFILING BEGIN[Forward] Iteration 18
I1226 07:04:22.354351 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 24
I1226 07:04:22.354441 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 24
I1226 07:04:22.354490 89377 solver.cpp:306] [1] Iteration 24, loss = 3.403
I1226 07:04:22.354564 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 24
I1226 07:04:22.354611 89377 solver.cpp:333]     Train net output #0: accuracy = 0.25
I1226 07:04:22.354698 89377 solver.cpp:333]     Train net output #1: loss = 3.403 (* 1 = 3.403 loss)
I1226 07:04:22.354770 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 25
I1226 07:04:22.416378 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 24
I1226 07:04:22.416465 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 24
I1226 07:04:22.416541 89451 solver.cpp:306] [2] Iteration 24, loss = 4.12477
I1226 07:04:22.416616 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 24
I1226 07:04:22.416662 89451 solver.cpp:333]     Train net output #0: accuracy = 0.203125
I1226 07:04:22.416749 89451 solver.cpp:333]     Train net output #1: loss = 4.12477 (* 1 = 4.12477 loss)
I1226 07:04:22.416815 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 25
I1226 07:04:22.415774 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 24
I1226 07:04:22.415871 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 24
I1226 07:04:22.415921 89170 solver.cpp:306] [3] Iteration 24, loss = 3.36486
I1226 07:04:22.415997 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 24
I1226 07:04:22.416043 89170 solver.cpp:333]     Train net output #0: accuracy = 0.3125
I1226 07:04:22.416126 89170 solver.cpp:333]     Train net output #1: loss = 3.36486 (* 1 = 3.36486 loss)
I1226 07:04:22.416254 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 25
I1226 07:04:23.514055 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 25
I1226 07:04:23.514132 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 25
I1226 07:04:23.514197 90546 solver.cpp:306] [0] Iteration 25, loss = 3.6996
I1226 07:04:23.514259 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 25
I1226 07:04:23.514317 90546 solver.cpp:333]     Train net output #0: accuracy = 0.21875
I1226 07:04:23.514386 90546 solver.cpp:333]     Train net output #1: loss = 3.6996 (* 1 = 3.6996 loss)
I1226 07:04:23.514432 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 26
I1226 07:04:23.657191 93507 solver.cpp:300] [7] PROFILING END[Forward] Iteration 17
I1226 07:04:23.657912 93507 solver.cpp:305] [7] PROFILING BEGIN[Other] Iteration 17
I1226 07:04:23.657977 93507 solver.cpp:306] [7] Iteration 17, loss = 2.99514
I1226 07:04:23.658047 93507 solver.cpp:309] [7] PROFILING END[Other] Iteration 17
I1226 07:04:23.658102 93507 solver.cpp:333]     Train net output #0: accuracy = 0.375
I1226 07:04:23.658175 93507 solver.cpp:333]     Train net output #1: loss = 2.99514 (* 1 = 2.99514 loss)
I1226 07:04:23.658243 93507 solver.cpp:298] [7] PROFILING BEGIN[Forward] Iteration 18
I1226 07:04:23.974548 89165 solver.cpp:300] [4] PROFILING END[Forward] Iteration 18
I1226 07:04:23.974632 89165 solver.cpp:305] [4] PROFILING BEGIN[Other] Iteration 18
I1226 07:04:23.974720 89165 solver.cpp:306] [4] Iteration 18, loss = 2.86508
I1226 07:04:23.974818 89165 solver.cpp:309] [4] PROFILING END[Other] Iteration 18
I1226 07:04:23.974864 89165 solver.cpp:333]     Train net output #0: accuracy = 0.40625
I1226 07:04:23.974932 89165 solver.cpp:333]     Train net output #1: loss = 2.86508 (* 1 = 2.86508 loss)
I1226 07:04:23.975013 89165 solver.cpp:298] [4] PROFILING BEGIN[Forward] Iteration 19
I1226 07:04:24.003136 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 25
I1226 07:04:24.003227 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 25
I1226 07:04:24.003316 89377 solver.cpp:306] [1] Iteration 25, loss = 3.24541
I1226 07:04:24.003389 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 25
I1226 07:04:24.003612 89377 solver.cpp:333]     Train net output #0: accuracy = 0.28125
I1226 07:04:24.003700 89377 solver.cpp:333]     Train net output #1: loss = 3.24541 (* 1 = 3.24541 loss)
I1226 07:04:24.003839 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 26
I1226 07:04:24.069779 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 25
I1226 07:04:24.069872 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 25
I1226 07:04:24.069918 89451 solver.cpp:306] [2] Iteration 25, loss = 3.54162
I1226 07:04:24.070022 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 25
I1226 07:04:24.070070 89451 solver.cpp:333]     Train net output #0: accuracy = 0.28125
I1226 07:04:24.070294 89451 solver.cpp:333]     Train net output #1: loss = 3.54162 (* 1 = 3.54162 loss)
I1226 07:04:24.070380 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 26
I1226 07:04:24.062960 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 25
I1226 07:04:24.063050 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 25
I1226 07:04:24.063102 89170 solver.cpp:306] [3] Iteration 25, loss = 2.91664
I1226 07:04:24.063177 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 25
I1226 07:04:24.063262 89170 solver.cpp:333]     Train net output #0: accuracy = 0.328125
I1226 07:04:24.063491 89170 solver.cpp:333]     Train net output #1: loss = 2.91664 (* 1 = 2.91664 loss)
I1226 07:04:24.063583 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 26
I1226 07:04:24.221329 51587 solver.cpp:300] [5] PROFILING END[Forward] Iteration 18
I1226 07:04:24.221412 51587 solver.cpp:305] [5] PROFILING BEGIN[Other] Iteration 18
I1226 07:04:24.221456 51587 solver.cpp:306] [5] Iteration 18, loss = 3.27619
I1226 07:04:24.221550 51587 solver.cpp:309] [5] PROFILING END[Other] Iteration 18
I1226 07:04:24.221593 51587 solver.cpp:333]     Train net output #0: accuracy = 0.296875
I1226 07:04:24.221662 51587 solver.cpp:333]     Train net output #1: loss = 3.27619 (* 1 = 3.27619 loss)
I1226 07:04:24.221735 51587 solver.cpp:298] [5] PROFILING BEGIN[Forward] Iteration 19
I1226 07:04:24.273049 88126 solver.cpp:300] [6] PROFILING END[Forward] Iteration 18
I1226 07:04:24.273138 88126 solver.cpp:305] [6] PROFILING BEGIN[Other] Iteration 18
I1226 07:04:24.273187 88126 solver.cpp:306] [6] Iteration 18, loss = 2.81044
I1226 07:04:24.273262 88126 solver.cpp:309] [6] PROFILING END[Other] Iteration 18
I1226 07:04:24.273308 88126 solver.cpp:333]     Train net output #0: accuracy = 0.40625
I1226 07:04:24.273389 88126 solver.cpp:333]     Train net output #1: loss = 2.81044 (* 1 = 2.81044 loss)
I1226 07:04:24.273454 88126 solver.cpp:298] [6] PROFILING BEGIN[Forward] Iteration 19
I1226 07:04:25.164930 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 26
I1226 07:04:25.165005 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 26
I1226 07:04:25.165038 90546 solver.cpp:306] [0] Iteration 26, loss = 3.40185
I1226 07:04:25.165093 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 26
I1226 07:04:25.165122 90546 solver.cpp:333]     Train net output #0: accuracy = 0.28125
I1226 07:04:25.165197 90546 solver.cpp:333]     Train net output #1: loss = 3.40185 (* 1 = 3.40185 loss)
I1226 07:04:25.165244 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 27
I1226 07:04:25.639194 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 26
I1226 07:04:25.639282 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 26
I1226 07:04:25.639324 89377 solver.cpp:306] [1] Iteration 26, loss = 3.06339
I1226 07:04:25.639389 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 26
I1226 07:04:25.639426 89377 solver.cpp:333]     Train net output #0: accuracy = 0.34375
I1226 07:04:25.639492 89377 solver.cpp:333]     Train net output #1: loss = 3.06339 (* 1 = 3.06339 loss)
I1226 07:04:25.639554 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 27
I1226 07:04:25.702972 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 26
I1226 07:04:25.703058 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 26
I1226 07:04:25.703111 89451 solver.cpp:306] [2] Iteration 26, loss = 3.13216
I1226 07:04:25.703183 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 26
I1226 07:04:25.703229 89451 solver.cpp:333]     Train net output #0: accuracy = 0.265625
I1226 07:04:25.703315 89451 solver.cpp:333]     Train net output #1: loss = 3.13216 (* 1 = 3.13216 loss)
I1226 07:04:25.703392 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 27
I1226 07:04:25.717342 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 26
I1226 07:04:25.717432 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 26
I1226 07:04:25.717483 89170 solver.cpp:306] [3] Iteration 26, loss = 3.27678
I1226 07:04:25.717566 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 26
I1226 07:04:25.717612 89170 solver.cpp:333]     Train net output #0: accuracy = 0.28125
I1226 07:04:25.717690 89170 solver.cpp:333]     Train net output #1: loss = 3.27678 (* 1 = 3.27678 loss)
I1226 07:04:25.717761 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 27
I1226 07:04:26.017118 93507 solver.cpp:300] [7] PROFILING END[Forward] Iteration 18
I1226 07:04:26.017215 93507 solver.cpp:305] [7] PROFILING BEGIN[Other] Iteration 18
I1226 07:04:26.017261 93507 solver.cpp:306] [7] Iteration 18, loss = 3.19632
I1226 07:04:26.017335 93507 solver.cpp:309] [7] PROFILING END[Other] Iteration 18
I1226 07:04:26.017397 93507 solver.cpp:333]     Train net output #0: accuracy = 0.34375
I1226 07:04:26.017470 93507 solver.cpp:333]     Train net output #1: loss = 3.19632 (* 1 = 3.19632 loss)
I1226 07:04:26.017544 93507 solver.cpp:298] [7] PROFILING BEGIN[Forward] Iteration 19
I1226 07:04:26.336416 89165 solver.cpp:300] [4] PROFILING END[Forward] Iteration 19
I1226 07:04:26.336503 89165 solver.cpp:305] [4] PROFILING BEGIN[Other] Iteration 19
I1226 07:04:26.336581 89165 solver.cpp:306] [4] Iteration 19, loss = 3.38594
I1226 07:04:26.336650 89165 solver.cpp:309] [4] PROFILING END[Other] Iteration 19
I1226 07:04:26.336701 89165 solver.cpp:333]     Train net output #0: accuracy = 0.265625
I1226 07:04:26.336776 89165 solver.cpp:333]     Train net output #1: loss = 3.38594 (* 1 = 3.38594 loss)
I1226 07:04:26.336865 89165 solver.cpp:298] [4] PROFILING BEGIN[Forward] Iteration 20
I1226 07:04:26.573487 51587 solver.cpp:300] [5] PROFILING END[Forward] Iteration 19
I1226 07:04:26.573572 51587 solver.cpp:305] [5] PROFILING BEGIN[Other] Iteration 19
I1226 07:04:26.573616 51587 solver.cpp:306] [5] Iteration 19, loss = 3.13778
I1226 07:04:26.573681 51587 solver.cpp:309] [5] PROFILING END[Other] Iteration 19
I1226 07:04:26.573719 51587 solver.cpp:333]     Train net output #0: accuracy = 0.34375
I1226 07:04:26.573794 51587 solver.cpp:333]     Train net output #1: loss = 3.13778 (* 1 = 3.13778 loss)
I1226 07:04:26.573904 51587 solver.cpp:298] [5] PROFILING BEGIN[Forward] Iteration 20
I1226 07:04:26.628679 88126 solver.cpp:300] [6] PROFILING END[Forward] Iteration 19
I1226 07:04:26.628769 88126 solver.cpp:305] [6] PROFILING BEGIN[Other] Iteration 19
I1226 07:04:26.628825 88126 solver.cpp:306] [6] Iteration 19, loss = 3.36306
I1226 07:04:26.628903 88126 solver.cpp:309] [6] PROFILING END[Other] Iteration 19
I1226 07:04:26.628948 88126 solver.cpp:333]     Train net output #0: accuracy = 0.3125
I1226 07:04:26.629029 88126 solver.cpp:333]     Train net output #1: loss = 3.36306 (* 1 = 3.36306 loss)
I1226 07:04:26.629103 88126 solver.cpp:298] [6] PROFILING BEGIN[Forward] Iteration 20
I1226 07:04:26.819308 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 27
I1226 07:04:26.819380 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 27
I1226 07:04:26.819412 90546 solver.cpp:306] [0] Iteration 27, loss = 3.21817
I1226 07:04:26.819464 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 27
I1226 07:04:26.819494 90546 solver.cpp:333]     Train net output #0: accuracy = 0.34375
I1226 07:04:26.819543 90546 solver.cpp:333]     Train net output #1: loss = 3.21817 (* 1 = 3.21817 loss)
I1226 07:04:26.819633 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 28
I1226 07:04:27.302480 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 27
I1226 07:04:27.302566 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 27
I1226 07:04:27.302606 89377 solver.cpp:306] [1] Iteration 27, loss = 3.47941
I1226 07:04:27.302672 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 27
I1226 07:04:27.302709 89377 solver.cpp:333]     Train net output #0: accuracy = 0.328125
I1226 07:04:27.302791 89377 solver.cpp:333]     Train net output #1: loss = 3.47941 (* 1 = 3.47941 loss)
I1226 07:04:27.302917 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 28
I1226 07:04:27.365110 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 27
I1226 07:04:27.365200 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 27
I1226 07:04:27.365247 89451 solver.cpp:306] [2] Iteration 27, loss = 3.34216
I1226 07:04:27.365320 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 27
I1226 07:04:27.365367 89451 solver.cpp:333]     Train net output #0: accuracy = 0.265625
I1226 07:04:27.365449 89451 solver.cpp:333]     Train net output #1: loss = 3.34216 (* 1 = 3.34216 loss)
I1226 07:04:27.365561 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 28
I1226 07:04:27.375306 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 27
I1226 07:04:27.375403 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 27
I1226 07:04:27.375486 89170 solver.cpp:306] [3] Iteration 27, loss = 3.15402
I1226 07:04:27.375560 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 27
I1226 07:04:27.375612 89170 solver.cpp:333]     Train net output #0: accuracy = 0.28125
I1226 07:04:27.375699 89170 solver.cpp:333]     Train net output #1: loss = 3.15402 (* 1 = 3.15402 loss)
I1226 07:04:27.375771 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 28
I1226 07:04:28.376672 93507 solver.cpp:300] [7] PROFILING END[Forward] Iteration 19
I1226 07:04:28.376766 93507 solver.cpp:305] [7] PROFILING BEGIN[Other] Iteration 19
I1226 07:04:28.376852 93507 solver.cpp:306] [7] Iteration 19, loss = 3.051
I1226 07:04:28.376926 93507 solver.cpp:309] [7] PROFILING END[Other] Iteration 19
I1226 07:04:28.376972 93507 solver.cpp:333]     Train net output #0: accuracy = 0.34375
I1226 07:04:28.377058 93507 solver.cpp:333]     Train net output #1: loss = 3.051 (* 1 = 3.051 loss)
I1226 07:04:28.377147 93507 solver.cpp:298] [7] PROFILING BEGIN[Forward] Iteration 20
I1226 07:04:28.599203 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 28
I1226 07:04:28.599280 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 28
I1226 07:04:28.599315 90546 solver.cpp:306] [0] Iteration 28, loss = 3.3669
I1226 07:04:28.599369 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 28
I1226 07:04:28.599398 90546 solver.cpp:333]     Train net output #0: accuracy = 0.1875
I1226 07:04:28.599448 90546 solver.cpp:333]     Train net output #1: loss = 3.3669 (* 1 = 3.3669 loss)
I1226 07:04:28.599534 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 29
I1226 07:04:28.694330 89165 solver.cpp:300] [4] PROFILING END[Forward] Iteration 20
I1226 07:04:28.694411 89165 solver.cpp:305] [4] PROFILING BEGIN[Other] Iteration 20
I1226 07:04:28.694479 89165 solver.cpp:306] [4] Iteration 20, loss = 3.26369
I1226 07:04:28.694615 89165 solver.cpp:309] [4] PROFILING END[Other] Iteration 20
I1226 07:04:28.694656 89165 solver.cpp:333]     Train net output #0: accuracy = 0.3125
I1226 07:04:28.694725 89165 solver.cpp:333]     Train net output #1: loss = 3.26369 (* 1 = 3.26369 loss)
I1226 07:04:28.694783 89165 solver.cpp:298] [4] PROFILING BEGIN[Forward] Iteration 21
I1226 07:04:28.996716 51587 solver.cpp:300] [5] PROFILING END[Forward] Iteration 20
I1226 07:04:28.996800 51587 solver.cpp:305] [5] PROFILING BEGIN[Other] Iteration 20
I1226 07:04:28.996843 51587 solver.cpp:306] [5] Iteration 20, loss = 3.58555
I1226 07:04:28.996909 51587 solver.cpp:309] [5] PROFILING END[Other] Iteration 20
I1226 07:04:28.996947 51587 solver.cpp:333]     Train net output #0: accuracy = 0.265625
I1226 07:04:28.997025 51587 solver.cpp:333]     Train net output #1: loss = 3.58555 (* 1 = 3.58555 loss)
I1226 07:04:28.997105 51587 solver.cpp:298] [5] PROFILING BEGIN[Forward] Iteration 21
I1226 07:04:29.045655 88126 solver.cpp:300] [6] PROFILING END[Forward] Iteration 20
I1226 07:04:29.045749 88126 solver.cpp:305] [6] PROFILING BEGIN[Other] Iteration 20
I1226 07:04:29.045800 88126 solver.cpp:306] [6] Iteration 20, loss = 3.38264
I1226 07:04:29.045874 88126 solver.cpp:309] [6] PROFILING END[Other] Iteration 20
I1226 07:04:29.045920 88126 solver.cpp:333]     Train net output #0: accuracy = 0.3125
I1226 07:04:29.046007 88126 solver.cpp:333]     Train net output #1: loss = 3.38264 (* 1 = 3.38264 loss)
I1226 07:04:29.046087 88126 solver.cpp:298] [6] PROFILING BEGIN[Forward] Iteration 21
I1226 07:04:29.101703 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 28
I1226 07:04:29.101789 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 28
I1226 07:04:29.101869 89377 solver.cpp:306] [1] Iteration 28, loss = 3.30553
I1226 07:04:29.101970 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 28
I1226 07:04:29.102015 89377 solver.cpp:333]     Train net output #0: accuracy = 0.296875
I1226 07:04:29.102092 89377 solver.cpp:333]     Train net output #1: loss = 3.30553 (* 1 = 3.30553 loss)
I1226 07:04:29.102152 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 29
I1226 07:04:29.156893 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 28
I1226 07:04:29.156980 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 28
I1226 07:04:29.157034 89451 solver.cpp:306] [2] Iteration 28, loss = 3.2023
I1226 07:04:29.157109 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 28
I1226 07:04:29.157155 89451 solver.cpp:333]     Train net output #0: accuracy = 0.28125
I1226 07:04:29.157234 89451 solver.cpp:333]     Train net output #1: loss = 3.2023 (* 1 = 3.2023 loss)
I1226 07:04:29.157359 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 29
I1226 07:04:29.170991 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 28
I1226 07:04:29.171090 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 28
I1226 07:04:29.171140 89170 solver.cpp:306] [3] Iteration 28, loss = 3.53878
I1226 07:04:29.171262 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 28
I1226 07:04:29.171308 89170 solver.cpp:333]     Train net output #0: accuracy = 0.296875
I1226 07:04:29.171382 89170 solver.cpp:333]     Train net output #1: loss = 3.53878 (* 1 = 3.53878 loss)
I1226 07:04:29.171448 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 29
I1226 07:04:30.332135 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 29
I1226 07:04:30.332304 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 29
I1226 07:04:30.332382 90546 solver.cpp:306] [0] Iteration 29, loss = 3.42853
I1226 07:04:30.332480 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 29
I1226 07:04:30.332510 90546 solver.cpp:333]     Train net output #0: accuracy = 0.234375
I1226 07:04:30.332562 90546 solver.cpp:333]     Train net output #1: loss = 3.42853 (* 1 = 3.42853 loss)
I1226 07:04:30.332608 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 30
I1226 07:04:30.637413 93507 solver.cpp:300] [7] PROFILING END[Forward] Iteration 20
I1226 07:04:30.637509 93507 solver.cpp:305] [7] PROFILING BEGIN[Other] Iteration 20
I1226 07:04:30.637557 93507 solver.cpp:306] [7] Iteration 20, loss = 2.94212
I1226 07:04:30.637630 93507 solver.cpp:309] [7] PROFILING END[Other] Iteration 20
I1226 07:04:30.637678 93507 solver.cpp:333]     Train net output #0: accuracy = 0.359375
I1226 07:04:30.637763 93507 solver.cpp:333]     Train net output #1: loss = 2.94212 (* 1 = 2.94212 loss)
I1226 07:04:30.637867 93507 solver.cpp:298] [7] PROFILING BEGIN[Forward] Iteration 21
I1226 07:04:30.772701 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 29
I1226 07:04:30.772789 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 29
I1226 07:04:30.772868 89377 solver.cpp:306] [1] Iteration 29, loss = 3.23682
I1226 07:04:30.772933 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 29
I1226 07:04:30.772972 89377 solver.cpp:333]     Train net output #0: accuracy = 0.28125
I1226 07:04:30.773053 89377 solver.cpp:333]     Train net output #1: loss = 3.23682 (* 1 = 3.23682 loss)
I1226 07:04:30.773119 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 30
I1226 07:04:30.844552 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 29
I1226 07:04:30.844640 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 29
I1226 07:04:30.844692 89451 solver.cpp:306] [2] Iteration 29, loss = 3.23756
I1226 07:04:30.844769 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 29
I1226 07:04:30.844815 89451 solver.cpp:333]     Train net output #0: accuracy = 0.34375
I1226 07:04:30.844898 89451 solver.cpp:333]     Train net output #1: loss = 3.23756 (* 1 = 3.23756 loss)
I1226 07:04:30.844988 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 30
I1226 07:04:30.842638 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 29
I1226 07:04:30.842727 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 29
I1226 07:04:30.842775 89170 solver.cpp:306] [3] Iteration 29, loss = 3.24912
I1226 07:04:30.842859 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 29
I1226 07:04:30.842905 89170 solver.cpp:333]     Train net output #0: accuracy = 0.21875
I1226 07:04:30.842988 89170 solver.cpp:333]     Train net output #1: loss = 3.24912 (* 1 = 3.24912 loss)
I1226 07:04:30.843060 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 30
I1226 07:04:30.954892 89165 solver.cpp:300] [4] PROFILING END[Forward] Iteration 21
I1226 07:04:30.954980 89165 solver.cpp:305] [4] PROFILING BEGIN[Other] Iteration 21
I1226 07:04:30.955023 89165 solver.cpp:306] [4] Iteration 21, loss = 3.44535
I1226 07:04:30.955126 89165 solver.cpp:309] [4] PROFILING END[Other] Iteration 21
I1226 07:04:30.955170 89165 solver.cpp:333]     Train net output #0: accuracy = 0.3125
I1226 07:04:30.955240 89165 solver.cpp:333]     Train net output #1: loss = 3.44535 (* 1 = 3.44535 loss)
I1226 07:04:30.955368 89165 solver.cpp:298] [4] PROFILING BEGIN[Forward] Iteration 22
I1226 07:04:31.203604 51587 solver.cpp:300] [5] PROFILING END[Forward] Iteration 21
I1226 07:04:31.203725 51587 solver.cpp:305] [5] PROFILING BEGIN[Other] Iteration 21
I1226 07:04:31.203769 51587 solver.cpp:306] [5] Iteration 21, loss = 3.25992
I1226 07:04:31.203836 51587 solver.cpp:309] [5] PROFILING END[Other] Iteration 21
I1226 07:04:31.203873 51587 solver.cpp:333]     Train net output #0: accuracy = 0.3125
I1226 07:04:31.204077 51587 solver.cpp:333]     Train net output #1: loss = 3.25992 (* 1 = 3.25992 loss)
I1226 07:04:31.204233 51587 solver.cpp:298] [5] PROFILING BEGIN[Forward] Iteration 22
I1226 07:04:31.252279 88126 solver.cpp:300] [6] PROFILING END[Forward] Iteration 21
I1226 07:04:31.252369 88126 solver.cpp:305] [6] PROFILING BEGIN[Other] Iteration 21
I1226 07:04:31.252423 88126 solver.cpp:306] [6] Iteration 21, loss = 2.85753
I1226 07:04:31.252498 88126 solver.cpp:309] [6] PROFILING END[Other] Iteration 21
I1226 07:04:31.252545 88126 solver.cpp:333]     Train net output #0: accuracy = 0.421875
I1226 07:04:31.252774 88126 solver.cpp:333]     Train net output #1: loss = 2.85753 (* 1 = 2.85753 loss)
I1226 07:04:31.252892 88126 solver.cpp:298] [6] PROFILING BEGIN[Forward] Iteration 22
I1226 07:04:31.981468 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 30
I1226 07:04:31.981546 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 30
I1226 07:04:31.981580 90546 solver.cpp:306] [0] Iteration 30, loss = 3.1919
I1226 07:04:31.981631 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 30
I1226 07:04:31.981660 90546 solver.cpp:333]     Train net output #0: accuracy = 0.390625
I1226 07:04:31.981710 90546 solver.cpp:333]     Train net output #1: loss = 3.1919 (* 1 = 3.1919 loss)
I1226 07:04:31.981786 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 31
I1226 07:04:32.478652 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 30
I1226 07:04:32.478735 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 30
I1226 07:04:32.478863 89377 solver.cpp:306] [1] Iteration 30, loss = 3.19677
I1226 07:04:32.478937 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 30
I1226 07:04:32.478976 89377 solver.cpp:333]     Train net output #0: accuracy = 0.3125
I1226 07:04:32.479049 89377 solver.cpp:333]     Train net output #1: loss = 3.19677 (* 1 = 3.19677 loss)
I1226 07:04:32.479105 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 31
I1226 07:04:32.532441 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 30
I1226 07:04:32.532559 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 30
I1226 07:04:32.532608 89451 solver.cpp:306] [2] Iteration 30, loss = 3.3975
I1226 07:04:32.532680 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 30
I1226 07:04:32.532727 89451 solver.cpp:333]     Train net output #0: accuracy = 0.34375
I1226 07:04:32.532806 89451 solver.cpp:333]     Train net output #1: loss = 3.3975 (* 1 = 3.3975 loss)
I1226 07:04:32.532929 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 31
I1226 07:04:32.556097 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 30
I1226 07:04:32.556186 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 30
I1226 07:04:32.556274 89170 solver.cpp:306] [3] Iteration 30, loss = 3.20317
I1226 07:04:32.556349 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 30
I1226 07:04:32.556396 89170 solver.cpp:333]     Train net output #0: accuracy = 0.3125
I1226 07:04:32.556480 89170 solver.cpp:333]     Train net output #1: loss = 3.20317 (* 1 = 3.20317 loss)
I1226 07:04:32.556569 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 31
I1226 07:04:32.998656 93507 solver.cpp:300] [7] PROFILING END[Forward] Iteration 21
I1226 07:04:32.998752 93507 solver.cpp:305] [7] PROFILING BEGIN[Other] Iteration 21
I1226 07:04:32.998828 93507 solver.cpp:306] [7] Iteration 21, loss = 3.08308
I1226 07:04:32.998904 93507 solver.cpp:309] [7] PROFILING END[Other] Iteration 21
I1226 07:04:32.998951 93507 solver.cpp:333]     Train net output #0: accuracy = 0.375
I1226 07:04:32.999034 93507 solver.cpp:333]     Train net output #1: loss = 3.08308 (* 1 = 3.08308 loss)
I1226 07:04:32.999106 93507 solver.cpp:298] [7] PROFILING BEGIN[Forward] Iteration 22
I1226 07:04:33.319528 89165 solver.cpp:300] [4] PROFILING END[Forward] Iteration 22
I1226 07:04:33.319619 89165 solver.cpp:305] [4] PROFILING BEGIN[Other] Iteration 22
I1226 07:04:33.319725 89165 solver.cpp:306] [4] Iteration 22, loss = 3.11027
I1226 07:04:33.319983 89165 solver.cpp:309] [4] PROFILING END[Other] Iteration 22
I1226 07:04:33.320160 89165 solver.cpp:333]     Train net output #0: accuracy = 0.453125
I1226 07:04:33.320266 89165 solver.cpp:333]     Train net output #1: loss = 3.11027 (* 1 = 3.11027 loss)
I1226 07:04:33.320399 89165 solver.cpp:298] [4] PROFILING BEGIN[Forward] Iteration 23
I1226 07:04:33.574448 51587 solver.cpp:300] [5] PROFILING END[Forward] Iteration 22
I1226 07:04:33.574568 51587 solver.cpp:305] [5] PROFILING BEGIN[Other] Iteration 22
I1226 07:04:33.574614 51587 solver.cpp:306] [5] Iteration 22, loss = 2.99096
I1226 07:04:33.574687 51587 solver.cpp:309] [5] PROFILING END[Other] Iteration 22
I1226 07:04:33.574725 51587 solver.cpp:333]     Train net output #0: accuracy = 0.296875
I1226 07:04:33.574798 51587 solver.cpp:333]     Train net output #1: loss = 2.99096 (* 1 = 2.99096 loss)
I1226 07:04:33.574867 51587 solver.cpp:298] [5] PROFILING BEGIN[Forward] Iteration 23
I1226 07:04:33.620277 88126 solver.cpp:300] [6] PROFILING END[Forward] Iteration 22
I1226 07:04:33.620367 88126 solver.cpp:305] [6] PROFILING BEGIN[Other] Iteration 22
I1226 07:04:33.620414 88126 solver.cpp:306] [6] Iteration 22, loss = 3.66263
I1226 07:04:33.620488 88126 solver.cpp:309] [6] PROFILING END[Other] Iteration 22
I1226 07:04:33.620535 88126 solver.cpp:333]     Train net output #0: accuracy = 0.265625
I1226 07:04:33.620647 88126 solver.cpp:333]     Train net output #1: loss = 3.66263 (* 1 = 3.66263 loss)
I1226 07:04:33.620760 88126 solver.cpp:298] [6] PROFILING BEGIN[Forward] Iteration 23
I1226 07:04:33.647354 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 31
I1226 07:04:33.647428 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 31
I1226 07:04:33.647460 90546 solver.cpp:306] [0] Iteration 31, loss = 3.46918
I1226 07:04:33.647512 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 31
I1226 07:04:33.647542 90546 solver.cpp:333]     Train net output #0: accuracy = 0.34375
I1226 07:04:33.647593 90546 solver.cpp:333]     Train net output #1: loss = 3.46918 (* 1 = 3.46918 loss)
I1226 07:04:33.647667 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 32
I1226 07:04:34.123612 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 31
I1226 07:04:34.123699 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 31
I1226 07:04:34.123741 89377 solver.cpp:306] [1] Iteration 31, loss = 3.15907
I1226 07:04:34.123805 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 31
I1226 07:04:34.123883 89377 solver.cpp:333]     Train net output #0: accuracy = 0.3125
I1226 07:04:34.124038 89377 solver.cpp:333]     Train net output #1: loss = 3.15907 (* 1 = 3.15907 loss)
I1226 07:04:34.124104 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 32
I1226 07:04:34.176697 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 31
I1226 07:04:34.176786 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 31
I1226 07:04:34.176833 89451 solver.cpp:306] [2] Iteration 31, loss = 3.68516
I1226 07:04:34.176908 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 31
I1226 07:04:34.176955 89451 solver.cpp:333]     Train net output #0: accuracy = 0.21875
I1226 07:04:34.177124 89451 solver.cpp:333]     Train net output #1: loss = 3.68516 (* 1 = 3.68516 loss)
I1226 07:04:34.177217 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 32
I1226 07:04:34.202293 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 31
I1226 07:04:34.202388 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 31
I1226 07:04:34.202440 89170 solver.cpp:306] [3] Iteration 31, loss = 3.05133
I1226 07:04:34.202514 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 31
I1226 07:04:34.202559 89170 solver.cpp:333]     Train net output #0: accuracy = 0.328125
I1226 07:04:34.202728 89170 solver.cpp:333]     Train net output #1: loss = 3.05133 (* 1 = 3.05133 loss)
I1226 07:04:34.202816 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 32
I1226 07:04:35.294867 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 32
I1226 07:04:35.294942 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 32
I1226 07:04:35.294977 90546 solver.cpp:306] [0] Iteration 32, loss = 3.21339
I1226 07:04:35.295071 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 32
I1226 07:04:35.295101 90546 solver.cpp:333]     Train net output #0: accuracy = 0.359375
I1226 07:04:35.295269 90546 solver.cpp:333]     Train net output #1: loss = 3.21339 (* 1 = 3.21339 loss)
I1226 07:04:35.295356 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 33
I1226 07:04:35.363847 93507 solver.cpp:300] [7] PROFILING END[Forward] Iteration 22
I1226 07:04:35.363943 93507 solver.cpp:305] [7] PROFILING BEGIN[Other] Iteration 22
I1226 07:04:35.363991 93507 solver.cpp:306] [7] Iteration 22, loss = 3.12973
I1226 07:04:35.364063 93507 solver.cpp:309] [7] PROFILING END[Other] Iteration 22
I1226 07:04:35.364109 93507 solver.cpp:333]     Train net output #0: accuracy = 0.328125
I1226 07:04:35.364193 93507 solver.cpp:333]     Train net output #1: loss = 3.12973 (* 1 = 3.12973 loss)
I1226 07:04:35.364259 93507 solver.cpp:298] [7] PROFILING BEGIN[Forward] Iteration 23
I1226 07:04:35.678452 89165 solver.cpp:300] [4] PROFILING END[Forward] Iteration 23
I1226 07:04:35.678535 89165 solver.cpp:305] [4] PROFILING BEGIN[Other] Iteration 23
I1226 07:04:35.678573 89165 solver.cpp:306] [4] Iteration 23, loss = 3.31209
I1226 07:04:35.678640 89165 solver.cpp:309] [4] PROFILING END[Other] Iteration 23
I1226 07:04:35.678678 89165 solver.cpp:333]     Train net output #0: accuracy = 0.359375
I1226 07:04:35.678746 89165 solver.cpp:333]     Train net output #1: loss = 3.31209 (* 1 = 3.31209 loss)
I1226 07:04:35.678808 89165 solver.cpp:298] [4] PROFILING BEGIN[Forward] Iteration 24
I1226 07:04:35.780452 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 32
I1226 07:04:35.780531 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 32
I1226 07:04:35.780571 89377 solver.cpp:306] [1] Iteration 32, loss = 3.13181
I1226 07:04:35.780637 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 32
I1226 07:04:35.780686 89377 solver.cpp:333]     Train net output #0: accuracy = 0.3125
I1226 07:04:35.780764 89377 solver.cpp:333]     Train net output #1: loss = 3.13181 (* 1 = 3.13181 loss)
I1226 07:04:35.780851 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 33
I1226 07:04:35.828706 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 32
I1226 07:04:35.828794 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 32
I1226 07:04:35.828843 89451 solver.cpp:306] [2] Iteration 32, loss = 3.13929
I1226 07:04:35.828917 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 32
I1226 07:04:35.828964 89451 solver.cpp:333]     Train net output #0: accuracy = 0.34375
I1226 07:04:35.829046 89451 solver.cpp:333]     Train net output #1: loss = 3.13929 (* 1 = 3.13929 loss)
I1226 07:04:35.829154 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 33
I1226 07:04:35.863734 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 32
I1226 07:04:35.863826 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 32
I1226 07:04:35.863875 89170 solver.cpp:306] [3] Iteration 32, loss = 3.42435
I1226 07:04:35.863950 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 32
I1226 07:04:35.863998 89170 solver.cpp:333]     Train net output #0: accuracy = 0.296875
I1226 07:04:35.864079 89170 solver.cpp:333]     Train net output #1: loss = 3.42435 (* 1 = 3.42435 loss)
I1226 07:04:35.864154 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 33
I1226 07:04:35.911734 51587 solver.cpp:300] [5] PROFILING END[Forward] Iteration 23
I1226 07:04:35.911818 51587 solver.cpp:305] [5] PROFILING BEGIN[Other] Iteration 23
I1226 07:04:35.911859 51587 solver.cpp:306] [5] Iteration 23, loss = 3.61448
I1226 07:04:35.911932 51587 solver.cpp:309] [5] PROFILING END[Other] Iteration 23
I1226 07:04:35.911972 51587 solver.cpp:333]     Train net output #0: accuracy = 0.234375
I1226 07:04:35.912050 51587 solver.cpp:333]     Train net output #1: loss = 3.61448 (* 1 = 3.61448 loss)
I1226 07:04:35.912209 51587 solver.cpp:298] [5] PROFILING BEGIN[Forward] Iteration 24
I1226 07:04:35.961447 88126 solver.cpp:300] [6] PROFILING END[Forward] Iteration 23
I1226 07:04:35.961537 88126 solver.cpp:305] [6] PROFILING BEGIN[Other] Iteration 23
I1226 07:04:35.961612 88126 solver.cpp:306] [6] Iteration 23, loss = 2.79911
I1226 07:04:35.961695 88126 solver.cpp:309] [6] PROFILING END[Other] Iteration 23
I1226 07:04:35.961750 88126 solver.cpp:333]     Train net output #0: accuracy = 0.375
I1226 07:04:35.961832 88126 solver.cpp:333]     Train net output #1: loss = 2.79911 (* 1 = 2.79911 loss)
I1226 07:04:35.961959 88126 solver.cpp:298] [6] PROFILING BEGIN[Forward] Iteration 24
I1226 07:04:36.913972 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 33
I1226 07:04:36.914064 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 33
I1226 07:04:36.914098 90546 solver.cpp:306] [0] Iteration 33, loss = 3.27827
I1226 07:04:36.914201 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 33
I1226 07:04:36.914233 90546 solver.cpp:333]     Train net output #0: accuracy = 0.296875
I1226 07:04:36.914284 90546 solver.cpp:333]     Train net output #1: loss = 3.27827 (* 1 = 3.27827 loss)
I1226 07:04:36.914335 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 34
I1226 07:04:37.398635 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 33
I1226 07:04:37.398723 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 33
I1226 07:04:37.398764 89377 solver.cpp:306] [1] Iteration 33, loss = 3.20876
I1226 07:04:37.398910 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 33
I1226 07:04:37.398958 89377 solver.cpp:333]     Train net output #0: accuracy = 0.375
I1226 07:04:37.399029 89377 solver.cpp:333]     Train net output #1: loss = 3.20876 (* 1 = 3.20876 loss)
I1226 07:04:37.399144 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 34
I1226 07:04:37.461316 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 33
I1226 07:04:37.461403 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 33
I1226 07:04:37.461452 89451 solver.cpp:306] [2] Iteration 33, loss = 2.7558
I1226 07:04:37.461565 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 33
I1226 07:04:37.461617 89451 solver.cpp:333]     Train net output #0: accuracy = 0.390625
I1226 07:04:37.461699 89451 solver.cpp:333]     Train net output #1: loss = 2.7558 (* 1 = 2.7558 loss)
I1226 07:04:37.461778 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 34
I1226 07:04:37.474048 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 33
I1226 07:04:37.474144 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 33
I1226 07:04:37.474194 89170 solver.cpp:306] [3] Iteration 33, loss = 3.24826
I1226 07:04:37.474308 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 33
I1226 07:04:37.474360 89170 solver.cpp:333]     Train net output #0: accuracy = 0.25
I1226 07:04:37.474436 89170 solver.cpp:333]     Train net output #1: loss = 3.24826 (* 1 = 3.24826 loss)
I1226 07:04:37.474509 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 34
I1226 07:04:37.725069 93507 solver.cpp:300] [7] PROFILING END[Forward] Iteration 23
I1226 07:04:37.725164 93507 solver.cpp:305] [7] PROFILING BEGIN[Other] Iteration 23
I1226 07:04:37.725210 93507 solver.cpp:306] [7] Iteration 23, loss = 3.27342
I1226 07:04:37.725286 93507 solver.cpp:309] [7] PROFILING END[Other] Iteration 23
I1226 07:04:37.725332 93507 solver.cpp:333]     Train net output #0: accuracy = 0.28125
I1226 07:04:37.725416 93507 solver.cpp:333]     Train net output #1: loss = 3.27342 (* 1 = 3.27342 loss)
I1226 07:04:37.725491 93507 solver.cpp:298] [7] PROFILING BEGIN[Forward] Iteration 24
I1226 07:04:38.043159 89165 solver.cpp:300] [4] PROFILING END[Forward] Iteration 24
I1226 07:04:38.043242 89165 solver.cpp:305] [4] PROFILING BEGIN[Other] Iteration 24
I1226 07:04:38.043349 89165 solver.cpp:306] [4] Iteration 24, loss = 3.25386
I1226 07:04:38.043416 89165 solver.cpp:309] [4] PROFILING END[Other] Iteration 24
I1226 07:04:38.043628 89165 solver.cpp:333]     Train net output #0: accuracy = 0.296875
I1226 07:04:38.043705 89165 solver.cpp:333]     Train net output #1: loss = 3.25386 (* 1 = 3.25386 loss)
I1226 07:04:38.043771 89165 solver.cpp:298] [4] PROFILING BEGIN[Forward] Iteration 25
I1226 07:04:38.296926 51587 solver.cpp:300] [5] PROFILING END[Forward] Iteration 24
I1226 07:04:38.297015 51587 solver.cpp:305] [5] PROFILING BEGIN[Other] Iteration 24
I1226 07:04:38.297056 51587 solver.cpp:306] [5] Iteration 24, loss = 3.20641
I1226 07:04:38.297157 51587 solver.cpp:309] [5] PROFILING END[Other] Iteration 24
I1226 07:04:38.297196 51587 solver.cpp:333]     Train net output #0: accuracy = 0.265625
I1226 07:04:38.297408 51587 solver.cpp:333]     Train net output #1: loss = 3.20641 (* 1 = 3.20641 loss)
I1226 07:04:38.297515 51587 solver.cpp:298] [5] PROFILING BEGIN[Forward] Iteration 25
I1226 07:04:38.348932 88126 solver.cpp:300] [6] PROFILING END[Forward] Iteration 24
I1226 07:04:38.349027 88126 solver.cpp:305] [6] PROFILING BEGIN[Other] Iteration 24
I1226 07:04:38.349079 88126 solver.cpp:306] [6] Iteration 24, loss = 3.51842
I1226 07:04:38.349154 88126 solver.cpp:309] [6] PROFILING END[Other] Iteration 24
I1226 07:04:38.349200 88126 solver.cpp:333]     Train net output #0: accuracy = 0.359375
I1226 07:04:38.349274 88126 solver.cpp:333]     Train net output #1: loss = 3.51842 (* 1 = 3.51842 loss)
I1226 07:04:38.349503 88126 solver.cpp:298] [6] PROFILING BEGIN[Forward] Iteration 25
I1226 07:04:38.574087 90546 solver.cpp:300] [0] PROFILING END[Forward] Iteration 34
I1226 07:04:38.574198 90546 solver.cpp:305] [0] PROFILING BEGIN[Other] Iteration 34
I1226 07:04:38.574296 90546 solver.cpp:306] [0] Iteration 34, loss = 3.15526
I1226 07:04:38.574349 90546 solver.cpp:309] [0] PROFILING END[Other] Iteration 34
I1226 07:04:38.574379 90546 solver.cpp:333]     Train net output #0: accuracy = 0.328125
I1226 07:04:38.574429 90546 solver.cpp:333]     Train net output #1: loss = 3.15526 (* 1 = 3.15526 loss)
I1226 07:04:38.574542 90546 solver.cpp:298] [0] PROFILING BEGIN[Forward] Iteration 35
I1226 07:04:39.050424 89377 solver.cpp:300] [1] PROFILING END[Forward] Iteration 34
I1226 07:04:39.050510 89377 solver.cpp:305] [1] PROFILING BEGIN[Other] Iteration 34
I1226 07:04:39.050554 89377 solver.cpp:306] [1] Iteration 34, loss = 3.49743
I1226 07:04:39.050621 89377 solver.cpp:309] [1] PROFILING END[Other] Iteration 34
I1226 07:04:39.050659 89377 solver.cpp:333]     Train net output #0: accuracy = 0.25
I1226 07:04:39.050737 89377 solver.cpp:333]     Train net output #1: loss = 3.49743 (* 1 = 3.49743 loss)
I1226 07:04:39.050895 89377 solver.cpp:298] [1] PROFILING BEGIN[Forward] Iteration 35
I1226 07:04:39.101101 89451 solver.cpp:300] [2] PROFILING END[Forward] Iteration 34
I1226 07:04:39.101192 89451 solver.cpp:305] [2] PROFILING BEGIN[Other] Iteration 34
I1226 07:04:39.101248 89451 solver.cpp:306] [2] Iteration 34, loss = 3.20051
I1226 07:04:39.101323 89451 solver.cpp:309] [2] PROFILING END[Other] Iteration 34
I1226 07:04:39.101371 89451 solver.cpp:333]     Train net output #0: accuracy = 0.3125
I1226 07:04:39.101457 89451 solver.cpp:333]     Train net output #1: loss = 3.20051 (* 1 = 3.20051 loss)
I1226 07:04:39.101588 89451 solver.cpp:298] [2] PROFILING BEGIN[Forward] Iteration 35
I1226 07:04:39.130018 89170 solver.cpp:300] [3] PROFILING END[Forward] Iteration 34
I1226 07:04:39.130108 89170 solver.cpp:305] [3] PROFILING BEGIN[Other] Iteration 34
I1226 07:04:39.130156 89170 solver.cpp:306] [3] Iteration 34, loss = 3.26435
I1226 07:04:39.130266 89170 solver.cpp:309] [3] PROFILING END[Other] Iteration 34
I1226 07:04:39.130313 89170 solver.cpp:333]     Train net output #0: accuracy = 0.328125
I1226 07:04:39.130388 89170 solver.cpp:333]     Train net output #1: loss = 3.26435 (* 1 = 3.26435 loss)
I1226 07:04:39.130511 89170 solver.cpp:298] [3] PROFILING BEGIN[Forward] Iteration 35
I1226 07:04:40.088263 93507 solver.cpp:300] [7] PROFILING END[Forward] Iteration 24
I1226 07:04:40.088358 93507 solver.cpp:305] [7] PROFILING BEGIN[Other] Iteration 24
I1226 07:04:40.088409 93507 solver.cpp:306] [7] Iteration 24, loss = 3.05201
I1226 07:04:40.088488 93507 solver.cpp:309] [7] PROFILING END[Other] Iteration 24
I1226 07:04:40.088532 93507 solver.cpp:333]     Train net output #0: accuracy = 0.390625
I1226 07:04:40.088618 93507 solver.cpp:333]     Train net output #1: loss = 3.05201 (* 1 = 3.05201 loss)
I1226 07:04:40.088685 93507 solver.cpp:298] [7] PROFILING BEGIN[Forward] Iteration 25
User defined signal 2
